<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch快速入门]]></title>
    <url>%2F2019%2F01%2F29%2FElasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Elasticsearch介绍和安装简介ElasticElastic官网：https://www.elastic.co/cn/ Elastic有一条完整的产品线：Elasticsearch、Kibana、Logstash等，前面说的三个就是大家常说的ELK技术栈。 ElasticsearchElasticsearch官网：https://www.elastic.co/cn/products/elasticsearch 如上所述，Elasticsearch具备以下特点： 分布式，无需人工搭建集群（solr就需要人为配置，使用Zookeeper作为注册中心） Restful风格，一切API都遵循Rest原则，容易上手 近实时搜索，数据更新在Elasticsearch中几乎是完全同步的。 版本目前Elasticsearch最新的版本是6.5.4，我们就使用这个版本 需要虚拟机JDK1.8及以上 CentOS7安装和配置新建一个用户1useradd esearch 设置密码： 1passwd esearch 出于安全考虑，elasticsearch默认不允许以root账号运行。 切换用户： 1su - esearch 上传安装包,并解压我们将安装包上传到：/home/esearch目录 解压缩： 1tar xvf elasticsearch-6.5.4.tar.gz 我们把目录重命名： 1mv elasticsearch-6.5.4 elasticsearch 进入，查看目录结构： 修改配置我们进入config目录：cd config 需要修改的配置文件有两个： 修改jvm配置 Elasticsearch基于Lucene的，而Lucene底层是java实现，因此我们需要配置jvm参数 1vim jvm.options 默认配置如下： 12-Xms1g-Xmx1g 内存占用太多了，我们调小一些： 12-Xms512m-Xmx512m 修改elasticsearch.yml 1vim elasticsearch.yml 修改数据和日志目录： 12path.data: /home/esearch/elasticsearch/data # 数据目录位置path.logs: /home/esearch/elasticsearch/logs # 日志目录位置 修改绑定的ip： 1network.host: 0.0.0.0 # 绑定到0.0.0.0，允许任何ip来访问 默认只允许本机访问，修改为0.0.0.0后则可以远程访问 目前我们是做的单机安装，如果要做集群，只需要在这个配置文件中添加其它节点信息即可。 elasticsearch.yml的其它可配置信息： 属性名 说明 cluster.name 配置elasticsearch的集群名称，默认是elasticsearch。建议修改成一个有意义的名称。 node.name 节点名，es会默认随机指定一个名字，建议指定一个有意义的名称，方便管理 path.conf 设置配置文件的存储路径，tar或zip包安装默认在es根目录下的config文件夹，rpm安装默认在/etc/ elasticsearch path.data 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开 path.logs 设置日志文件的存储路径，默认是es根目录下的logs文件夹 path.plugins 设置插件的存放路径，默认是es根目录下的plugins文件夹 bootstrap.memory_lock 设置为true可以锁住ES使用的内存，避免内存进行swap network.host 设置bind_host和publish_host，设置为0.0.0.0允许外网访问 http.port 设置对外服务的http端口，默认为9200。 transport.tcp.port 集群结点之间通信端口 discovery.zen.ping.timeout 设置ES自动发现节点连接超时的时间，默认为3秒，如果网络延迟高可设置大些 discovery.zen.minimum_master_nodes 主结点数量的最少值 ,此值的公式为：(master_eligible_nodes / 2) + 1 ，比如：有3个符合要求的主结点，那么这里要设置为2 创建data和logs目录刚才我们修改配置，把data和logs目录修改指向了elasticsearch的安装目录。但是这两个目录并不存在，因此我们需要创建出来： 进入elasticsearch的根目录，然后创建： 12mkdir datamkdir logs 运行进入elasticsearch/bin目录，可以看到下面的执行文件： 然后输入命令： 1./elasticsearch 发现报错了，启动失败. 错误1:1[1]: max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536] 我们用的是esearch用户，而不是root，所以文件权限不足。 首先用root用户登录。 然后修改配置文件: 1vim /etc/security/limits.conf 添加下面的内容： 1234567* soft nofile 65536* hard nofile 131072* soft nproc 4096* hard nproc 4096 错误2：1[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 继续修改配置文件： 1vim /etc/sysctl.conf 添加下面内容： 1vm.max_map_count=655360 然后执行命令： 1sysctl -p 重启终端窗口所有错误修改完毕，一定要重启你的 Xshell终端，否则配置无效。 启动再次启动，终于成功了！ 可以看到绑定了两个端口: 9300：集群节点间通讯接口 9200：客户端访问接口 我们在浏览器中访问(由于博主使用的是云服务器，访问需要使用公网IP访问):http://119.23.208.179:9200 安装kibana什么是Kibana？ Kibana是一个基于Node.js的Elasticsearch索引库数据统计工具，可以利用Elasticsearch的聚合功能，生成各种图表，如柱形图，线状图，饼图等。 而且还提供了操作Elasticsearch索引数据的控制台，并且提供了一定的API提示，非常有利于我们学习Elasticsearch的语法。 安装因为Kibana依赖于node，我的虚拟机没有安装node，而window中安装过。所以我们选择在window下使用kibana。 最新版本与elasticsearch保持一致，也是6.5.4 解压即可： 配置运行 配置 进入安装目录下的config目录，修改kibana.yml文件： 修改elasticsearch服务器的地址： 1elasticsearch.url: &quot;http://119.23.208.179:9200&quot; 运行 进入安装目录下的bin目录： 双击运行kibana.bat： 发现kibana的监听端口是5601 我们访问：http://127.0.0.1:5601 控制台选择左侧的DevTools菜单，即可进入控制台页面： 在页面右侧，我们就可以输入请求，访问Elasticsearch了。 安装ik分词器Lucene的IK分词器早在2012年已经没有维护了，现在我们要使用的是在其基础上维护升级的版本，并且开发为Elasticsearch的集成插件了，与Elasticsearch一起维护升级，版本也保持一致，最新版本：6.5.4 安装下载并上传elasticsearch-analysis-ik-6.5.4.zip包，在/home/esearch/elasticsearch/plugins中，将elasticsearch-analysis-ik-6.5.4.zip解压到ik-analyzer目录中： 使用unzip命令解压： 1unzip elasticsearch-analysis-ik-6.5.4.zip -d ik-analyzer 删除elasticsearch-analysis-ik-6.5.4.zip,然后重启elasticsearch： 测试大家先不管语法，我们先测试一波。 在kibana控制台输入下面的请求： 12345POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我是中国人&quot;&#125; 运行得到结果： 123456789101112131415161718192021222324252627282930313233343536373839&#123; "tokens" : [ &#123; "token" : "我", "start_offset" : 0, "end_offset" : 1, "type" : "CN_CHAR", "position" : 0 &#125;, &#123; "token" : "是", "start_offset" : 1, "end_offset" : 2, "type" : "CN_CHAR", "position" : 1 &#125;, &#123; "token" : "中国人", "start_offset" : 2, "end_offset" : 5, "type" : "CN_WORD", "position" : 2 &#125;, &#123; "token" : "中国", "start_offset" : 2, "end_offset" : 4, "type" : "CN_WORD", "position" : 3 &#125;, &#123; "token" : "国人", "start_offset" : 3, "end_offset" : 5, "type" : "CN_WORD", "position" : 4 &#125; ]&#125; APIElasticsearch提供了Rest风格的API，即http请求接口，而且也提供了各种语言的客户端API Rest风格API文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html 客户端APIElasticsearch支持的客户端非常多：https://www.elastic.co/guide/en/elasticsearch/client/index.html 点击Java Rest Client后，你会发现又有两个： Low Level Rest Client是低级别封装，提供一些基础功能，但更灵活 High Level Rest Client，是在Low Level Rest Client基础上进行的高级别封装，功能更丰富和完善，而且API会变的简单 如何学习建议先学习Rest风格API，了解发起请求的底层实现，请求体格式等。 操作索引基本概念Elasticsearch也是基于Lucene的全文检索库，本质也是存储数据，很多概念与MySQL类似的。 对比关系： 索引（indices）——————————–Databases 数据库 ​ 类型（type）—————————–Table 数据表 ​ 文档（Document）—————-Row 行 ​ 字段（Field）——————-Columns 列 详细说明： 概念 说明 索引库（indices) indices是index的复数，代表许多的索引， 类型（type） 类型是模拟mysql中的table概念，一个索引库下可以有不同类型的索引，比如商品索引，订单索引，其数据格式不同。不过这会导致索引库混乱，因此未来版本中会移除这个概念 文档（document） 存入索引库原始的数据。比如每一条商品信息，就是一个文档 字段（field） 文档中的属性 映射配置（mappings） 字段的数据类型、属性、是否索引、是否存储等特性 是不是与Lucene和solr中的概念类似。 另外，在SolrCloud中，有一些集群相关的概念，在Elasticsearch也有类似的： 索引集（Indices，index的复数）：逻辑上的完整索引 分片（shard）：数据拆分后的各个部分 副本（replica）：每个分片的复制 要注意的是：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。 创建索引语法Elasticsearch采用Rest风格API，因此其API就是一次http请求，你可以用任何工具发起http请求 创建索引的请求格式： 请求方式：PUT 请求路径：/索引库名 请求参数：json格式： 123456&#123; "settings": &#123; "number_of_shards": 3, "number_of_replicas": 2 &#125;&#125; settings：索引库的设置 number_of_shards：分片数量 number_of_replicas：副本数量 测试我们先用Insomnia来试试 响应： 可以看到索引创建成功了。 使用kibana创建kibana的控制台，可以对http请求进行简化，示例： 相当于是省去了elasticsearch的服务器地址 而且还有语法提示，非常舒服。 查看索引设置 语法 Get请求可以帮我们查看索引信息，格式： 1GET /索引库名 或者，我们可以使用*来查询所有索引库配置： 删除索引删除索引使用DELETE请求 语法 1DELETE /索引库名 示例 再次查看heima2： 当然，我们也可以用HEAD请求，查看索引是否存在： 映射配置索引有了，接下来肯定是添加数据。不过数据存储到索引库中，必须指定一些相关属性，在学习Lucene中我们都见到过，包括到不限于： 字段的数据类型 是否要存储 是否要索引 是否分词 分词器是什么 只有配置清楚，Elasticsearch才会帮我们进行索引库的创建（不一定） 创建映射字段 语法 请求方式依然是PUT 1234567891011PUT /索引库名/_mapping/类型名称&#123; &quot;properties&quot;: &#123; &quot;字段名&quot;: &#123; &quot;type&quot;: &quot;类型&quot;, &quot;index&quot;: true， &quot;store&quot;: true， &quot;analyzer&quot;: &quot;分词器&quot; &#125; &#125;&#125; 类型名称：就是前面将的type的概念，类似于数据库中的不同表字段名：任意填写 ，可以指定许多属性，例如： type：类型，可以是text、long、short、date、integer、object等 index：是否索引，默认为true store：是否存储，默认为false analyzer：分词器，这里的ik_max_word即使用ik分词器 示例 发起请求： 12345678910111213141516PUT test/_mapping/goods&#123; "properties": &#123; "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125;, "images": &#123; "type": "keyword", "index": "false" &#125;, "price": &#123; "type": "float" &#125; &#125;&#125; 响应结果： 123&#123; "acknowledged" : true&#125; 查看映射关系 语法： 1GET /索引库名/_mapping 示例： 1GET /heima/_mapping 响应： 123456789101112131415161718192021&#123; "test" : &#123; "mappings" : &#123; "goods" : &#123; "properties" : &#123; "images" : &#123; "type" : "keyword", "index" : false &#125;, "price" : &#123; "type" : "float" &#125;, "title" : &#123; "type" : "text", "analyzer" : "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125; 字段属性详解 type Elasticsearch中支持的数据类型非常丰富： 我们说几个关键的： String类型，又分两种： text：可分词，不可参与聚合 keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合 Numerical：数值类型，分两类 基本数据类型：long、interger、short、byte、double、float、half_float 浮点数的高精度类型：scaled_float 需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。 Date：日期类型 elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。 index index影响字段的索引情况。 true：字段会被索引，则可以用来进行搜索。默认值就是true false：字段不会被索引，不能用来搜索 index的默认值就是true，也就是说你不进行任何配置，所有字段都会被索引。 但是有些字段是我们不希望被索引的，比如商品的图片信息，就需要手动设置index为false。 store 是否将数据进行额外存储。 在学习lucene和solr时，我们知道如果一个字段的store设置为false，那么在文档列表中就不会有这个字段的值，用户的搜索结果中不会显示出来。 但是在Elasticsearch中，即便store设置为false，也可以搜索到结果。 原因是Elasticsearch在创建文档索引时，会将文档中的原始数据备份，保存到一个叫做_source的属性中。而且我们可以通过过滤_source来选择哪些要显示，哪些不显示。 而如果设置store为true，就会在_source以外额外存储一份数据，多余，因此一般我们都会将store设置为false，事实上，store的默认值就是false。 boost 激励因子，这个与lucene中一样 其它的不再一一讲解，用的不多，大家参考官方文档： 新增数据随机生成id通过POST请求，可以向一个已经存在的索引库中添加数据。 语法： 1234POST /索引库名/类型名&#123; &quot;key&quot;:&quot;value&quot;&#125; 示例： 123456POST /test/goods/&#123; "title":"小米手机", "images":"https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price":3299.00&#125; 响应： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 0, "_primary_term" : 1&#125; 通过kibana查看数据： 123456get _search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;&#125; 1234567891011&#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 1.0, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125;&#125; _source：源文档信息，所有的数据都在里面。 _id：这条文档的唯一标示，与文档自己的id字段没有关联 自定义id如果我们想要自己新增的时候指定id，可以这么做： 1234POST /索引库名/类型/id值&#123; ...&#125; 示例： 123456POST /test/goods/2&#123; &quot;title&quot;:&quot;大米手机&quot;, &quot;images&quot;:&quot;http://image.codeopen.club/12479122.jpg&quot;, &quot;price&quot;:2899.00&#125; 响应结果: 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 0, "_primary_term" : 1&#125; 智能判断在学习Solr时我们发现，我们在新增数据时，只能使用提前配置好映射属性的字段，否则就会报错。 不过在Elasticsearch中并没有这样的规定。 事实上Elasticsearch非常智能，你不需要给索引库设置任何mapping映射，它也可以根据你输入的数据来判断类型，动态添加数据映射。 测试一下： 12345678POST /test/goods/3&#123; "title":"超米手机", "images":"http://image.codeopen.club/12479122.jpg", "price":2899.00, "stock": 200, "saleable":true&#125; 我们额外添加了stock库存，和saleable是否上架两个字段。 来看结果： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 1, "_primary_term" : 1&#125; 在看下索引库的映射关系GET test/_mapping: 123456789101112131415161718192021222324252627&#123; "test" : &#123; "mappings" : &#123; "goods" : &#123; "properties" : &#123; "images" : &#123; "type" : "keyword", "index" : false &#125;, "price" : &#123; "type" : "float" &#125;, "saleable" : &#123; "type" : "boolean" &#125;, "stock" : &#123; "type" : "long" &#125;, "title" : &#123; "type" : "text", "analyzer" : "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125; stock和saleable都被成功映射了。 修改数据把刚才新增的请求方式改为PUT，就是修改了。不过修改必须指定id， id对应文档存在，则修改 id对应文档不存在，则新增 比如，我们把id为3的数据进行修改： 12345678PUT /test/goods/3&#123; "title":"超大米手机", "images":"http://image.codeopen.club/12479122.jpg", "price":4899.00, "stock": 300, "saleable":true&#125; 结果： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_version" : 2, "result" : "updated", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 2, "_primary_term" : 1&#125; 删除数据删除使用DELETE请求，同样，需要根据id进行删除： 语法 1DELETE /索引库名/类型名/id值 示例： 查询我们从4块来讲查询： 基本查询 _source过滤 结果过滤 高级查询 排序 基本查询： 基本语法 12345678GET /索引库名/_search&#123; "query":&#123; "查询类型":&#123; "查询条件":"查询条件值" &#125; &#125;&#125; 这里的query代表一个查询对象，里面可以有不同的查询属性 查询类型： 例如：match_all， match，term ， range 等等 查询条件：查询条件会根据类型的不同，写法也有差异，后面详细讲解 查询所有（match_all) 示例： 123456GET /test/_search&#123; "query":&#123; "match_all": &#123;&#125; &#125;&#125; query：代表查询对象 match_all：代表查询所有 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 1.0, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125; ] &#125;&#125; took：查询花费时间，单位是毫秒 time_out：是否超时 _shards：分片信息 hits：搜索结果总览对象 total：搜索到的总条数 max_score：所有结果中文档得分的最高分 hits：搜索结果的文档对象数组，每个元素是一条搜索到的文档信息 _index：索引库 _type：文档类型 _id：文档id _score：文档得分 _source：文档的源数据 匹配查询（match）我们先加入一条数据，便于测试： 123456PUT /test/goods/3&#123; "title":"小米电视4S", "images":"https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price":7999.00&#125; 现在，索引库中有2部手机，1台电视： or关系 match类型查询，会把查询条件进行分词，然后进行查询,多个词条之间是or的关系 12345678GET /test/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;title&quot;:&quot;小米电视&quot; &#125; &#125;&#125; 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 10, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 0.22108285, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125; ] &#125;&#125; 在上面的案例中，不仅会查询到电视，而且与小米相关的都会查询到，多个词之间是or的关系。 and关系 某些情况下，我们需要更精确查找，我们希望这个关系变成and，可以这样做： 12345678GET /test/_search&#123; "query":&#123; "match":&#123; "title":&#123;"query":"小米电视","operator":"and"&#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 20, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 本例中，只有同时包含小米和电视的词条才会被搜索到。 or和and之间？ 在 or 与 and 间二选一有点过于非黑即白。 如果用户给定的条件分词后有 5 个查询词项，想查找只包含其中 4 个词的文档，该如何处理？将 operator 操作符参数设置成 and 只会将此文档排除。 有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。 match 查询支持 minimum_should_match 最小匹配参数， 这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量： 1234567891011GET /test/_search&#123; "query":&#123; "match":&#123; "title":&#123; "query":"小米曲面电视", "minimum_should_match": "75%" &#125; &#125; &#125;&#125; 本例中，搜索语句可以分为3个词，如果使用and关系，需要同时满足3个词才会被搜索到。这里我们采用最小品牌数：75%，那么也就是说只要匹配到总词条数量的75%即可，这里3*75% 约等于2。所以只要包含2个词条就算满足条件了。 结果： 123456789101112131415161718192021222324252627&#123; "took" : 4, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 多字段查询（multi_match）multi_match与match类似，不同的是它可以在多个字段中查询 123456789GET /test/_search&#123; "query":&#123; "multi_match": &#123; "query": "小米", "fields": [ "title", "subTitle" ] &#125; &#125;&#125; 本例中，我们会在title字段和subtitle字段中查询小米这个词 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 4, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 0.22108285, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 0.22108285, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.15512443, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 词条匹配(term)term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字 12345678GET /test/_search&#123; "query":&#123; "term":&#123; "price":7999.00 &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 1.0, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 多词条精确匹配(terms)terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件： 12345678GET /test/_search&#123; "query":&#123; "terms":&#123; "price":[2899.00,3299.00,7999.00] &#125; &#125;&#125; 结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; &quot;took&quot; : 3, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 3, &quot;successful&quot; : 3, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 3, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;大米手机&quot;, &quot;images&quot; : &quot;http://image.codeopen.club/12479122.jpg&quot;, &quot;price&quot; : 2899.0 &#125; &#125;, &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;iDZznGgB-wYBfzEzkJGx&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;小米手机&quot;, &quot;images&quot; : &quot;https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png&quot;, &quot;price&quot; : 3299.0 &#125; &#125;, &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;小米电视4S&quot;, &quot;images&quot; : &quot;https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png&quot;, &quot;price&quot; : 7999.0 &#125; &#125; ] &#125;&#125; 结果过滤默认情况下，elasticsearch在搜索的结果中，会把文档中保存在_source的所有字段都返回。 如果我们只想获取其中的部分字段，我们可以添加_source的过滤 直接指定字段示例： 123456789GET /test/_search&#123; "_source": ["title","price"], "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 返回的结果： 1234567891011121314151617181920212223242526&#123; "took" : 2, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "price" : 2899.0, "title" : "大米手机" &#125; &#125; ] &#125;&#125; 指定includes和excludes我们也可以通过： includes：来指定想要显示的字段 excludes：来指定不想要显示的字段 二者都是可选的。 示例： 1234567891011GET /test/_search&#123; "_source": &#123; "includes":["title","price"] &#125;, "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 与下面的结果将是一样的： 1234567891011GET /test/_search&#123; "_source": &#123; "excludes": ["images"] &#125;, "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 高级查询布尔组合（bool)bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合 12345678910GET /test/_search&#123; "query":&#123; "bool":&#123; "must": &#123; "match": &#123; "title": "大米" &#125;&#125;, "must_not": &#123; "match": &#123; "title": "电视" &#125;&#125;, "should": &#123; "match": &#123; "title": "手机" &#125;&#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.5753642, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 0.5753642, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125; ] &#125;&#125; 范围查询(range)range 查询找出那些落在指定区间内的数字或者时间 1234567891011GET /test/_search&#123; "query":&#123; "range": &#123; "price": &#123; "gte": 1000.0, "lt": 3000.00 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125; ] &#125;&#125; range查询允许以下字符： 操作符 说明 gt 大于 gte 大于等于 lt 小于 lte 小于等于 模糊查询(fuzzy)我们新增一个商品： 123456POST /test/goods/4&#123; "title":"apple手机", "images":"https://img.pconline.com.cn/images/product/5700/570024/iPhone6plus.jpg", "price":6899.00&#125; fuzzy 查询是 term 查询的模糊等价。它允许用户搜索词条与实际词条的拼写出现偏差，但是偏差的编辑距离不得超过2： 12345678GET /test/_search&#123; "query": &#123; "fuzzy": &#123; "title": "appla" &#125; &#125;&#125; 上面的查询，也能查询到apple手机 我们可以通过fuzziness来指定允许的编辑距离： 1234567891011GET /test/_search&#123; "query": &#123; "fuzzy": &#123; "title": &#123; "value":"appla", "fuzziness":1 &#125; &#125; &#125;&#125; 过滤(filter) 条件查询中进行过滤 所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式： 1234567891011GET /test/_search&#123; "query":&#123; "bool":&#123; "must":&#123; "match": &#123; "title": "小米手机" &#125;&#125;, "filter":&#123; "range":&#123;"price":&#123;"gt":2000.00,"lt":3800.00&#125;&#125; &#125; &#125; &#125;&#125; 注意：filter中还可以再次进行bool组合条件过滤。 无查询条件，直接过滤 如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。 123456789GET /test/_search&#123; "query":&#123; "constant_score": &#123; "filter": &#123; "range":&#123;"price":&#123;"gt":2000.00,"lt":3000.00&#125;&#125; &#125; &#125;&#125; 排序单字段排序sort 可以让我们按照不同的字段进行排序，并且通过order指定排序的方式 123456789101112131415GET /test/_search&#123; "query": &#123; "match": &#123; "title": "小米手机" &#125; &#125;, "sort": [ &#123; "price": &#123; "order": "desc" &#125; &#125; ]&#125; 多字段排序假定我们想要结合使用 price和 _score（得分） 进行查询，并且匹配的结果首先按照价格排序，然后按照相关性得分排序： 123456789101112131415GET /goods/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;小米手机&quot; &#125;&#125;, &quot;filter&quot;:&#123; &quot;range&quot;:&#123;&quot;price&quot;:&#123;&quot;gt&quot;:200000,&quot;lt&quot;:300000&#125;&#125; &#125; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;price&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125;, &#123; &quot;_score&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; ]&#125; 聚合aggregations聚合可以让我们极其方便的实现对数据的统计、分析。例如： 什么品牌的手机最受欢迎？ 这些手机的平均价格、最高价格、最低价格？ 这些手机每月的销售情况如何？ 实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现近实时搜索效果。 基本概念Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量： 桶（bucket） 桶的作用，是按照某种方式对数据进行分组，每一组数据在ES中称为一个桶，例如我们根据国籍对人划分，可以得到中国桶、英国桶，日本桶……或者我们按照年龄段对人进行划分：0~10,10~20,20~30,30~40等。 Elasticsearch中提供的划分桶的方式有很多： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 …… 综上所述，我们发现bucket aggregations 只负责对数据进行分组，并不进行计算，因此往往bucket中往往会嵌套另一种聚合：metrics aggregations即度量 度量（metrics） 分组完成以后，我们一般会对组中的数据进行聚合运算，例如求平均值、最大、最小、求和等，这些在ES中称为度量 比较常用的一些度量聚合方式： Avg Aggregation：求平均值 Max Aggregation：求最大值 Min Aggregation：求最小值 Percentiles Aggregation：求百分比 Stats Aggregation：同时返回avg、max、min、sum、count等 Sum Aggregation：求和 Top hits Aggregation：求前几 Value Count Aggregation：求总数 …… 为了测试聚合，我们先批量导入一些数据 创建索引： 12345678910111213141516171819PUT /cars&#123; "settings": &#123; "number_of_shards": 1, "number_of_replicas": 0 &#125;, "mappings": &#123; "transactions": &#123; "properties": &#123; "color": &#123; "type": "keyword" &#125;, "make": &#123; "type": "keyword" &#125; &#125; &#125; &#125;&#125; 注意：在ES中，需要进行聚合、排序、过滤的字段其处理方式比较特殊，因此不能被分词。这里我们将color和make这两个文字类型的字段设置为keyword类型，这个类型不会被分词，将来就可以参与聚合 导入数据 1234567891011121314151617POST /cars/transactions/_bulk&#123; "index": &#123;&#125;&#125;&#123; "price" : 10000, "color" : "red", "make" : "honda", "sold" : "2014-10-28" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 30000, "color" : "green", "make" : "ford", "sold" : "2014-05-18" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 15000, "color" : "blue", "make" : "toyota", "sold" : "2014-07-02" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 12000, "color" : "green", "make" : "toyota", "sold" : "2014-08-19" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 80000, "color" : "red", "make" : "bmw", "sold" : "2014-01-01" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 25000, "color" : "blue", "make" : "ford", "sold" : "2014-02-12" &#125; 聚合为桶首先，我们按照 汽车的颜色color来划分桶 1234567891011GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125; &#125; &#125;&#125; size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率 aggs：声明这是一个聚合查询，是aggregations的缩写 popular_colors：给这次聚合起一个名字，任意。 terms：划分桶的方式，这里是根据词条划分 field：划分桶的字段 结果： 1234567891011121314151617181920212223242526272829303132333435&#123; "took" : 8, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4 &#125;, &#123; "key" : "blue", "doc_count" : 2 &#125;, &#123; "key" : "green", "doc_count" : 2 &#125; ] &#125; &#125;&#125; hits：查询结果为空，因为我们设置了size为0 aggregations：聚合的结果 popular_colors：我们定义的聚合名称 buckets：查找到的桶，每个不同的color字段值都会形成一个桶 key：这个桶对应的color字段的值 doc_count：这个桶中的文档数量 通过聚合的结果我们发现，目前红色的小车比较畅销！ 桶内度量前面的例子告诉我们每个桶里面的文档数量，这很有用。 但通常，我们的应用需要提供更复杂的文档度量。 例如，每种颜色汽车的平均价格是多少？ 因此，我们需要告诉Elasticsearch使用哪个字段，使用何种度量方式进行运算，这些信息要嵌套在桶内，度量的运算会基于桶内的文档进行 现在，我们为刚刚的聚合结果添加 求价格平均值的度量： 123456789101112131415161718GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125; &#125; &#125; &#125;&#125; aggs：我们在上一个aggs(popular_colors)中添加新的aggs。可见度量也是一个聚合 avg_price：聚合的名称 avg：度量的类型，这里是求平均值 field：度量运算的字段 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&#123; "took" : 10, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4, "avg_price" : &#123; "value" : 32500.0 &#125; &#125;, &#123; "key" : "blue", "doc_count" : 2, "avg_price" : &#123; "value" : 20000.0 &#125; &#125;, &#123; "key" : "green", "doc_count" : 2, "avg_price" : &#123; "value" : 21000.0 &#125; &#125; ] &#125; &#125;&#125; 可以看到每个桶中都有自己的avg_price字段，这是度量聚合的结果 桶内嵌套桶刚刚的案例中，我们在桶内嵌套度量运算。事实上桶不仅可以嵌套运算， 还可以再嵌套其它桶。也就是说在每个分组中，再分更多组。 比如：我们想统计每种颜色的汽车中，分别属于哪个制造商，按照make字段再进行分桶 1234567891011121314151617181920212223GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125;, "maker":&#123; "terms":&#123; "field":"make" &#125; &#125; &#125; &#125; &#125;&#125; 原来的color桶和avg计算我们不变 maker：在嵌套的aggs下新添一个桶，叫做maker terms：桶的划分类型依然是词条 filed：这里根据make字段进行划分 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "honda", "doc_count" : 3 &#125;, &#123; "key" : "bmw", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 32500.0 &#125; &#125;, &#123; "key" : "blue", "doc_count" : 2, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "ford", "doc_count" : 1 &#125;, &#123; "key" : "toyota", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 20000.0 &#125; &#125;, &#123; "key" : "green", "doc_count" : 2, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "ford", "doc_count" : 1 &#125;, &#123; "key" : "toyota", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 21000.0 &#125; &#125; ] &#125; &#125;&#125; 我们可以看到，新的聚合maker被嵌套在原来每一个color的桶中。 每个颜色下面都根据 make字段进行了分组 我们能读取到的信息： 红色车共有4辆 红色车的平均售价是 $32，500 美元。 其中3辆是 Honda 本田制造，1辆是 BMW 宝马制造。 划分桶的其它方式前面讲了，划分桶的方式有很多，例如： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 刚刚的案例中，我们采用的是Terms Aggregation，即根据词条划分桶。 接下来，我们再学习几个比较实用的： 阶梯分桶Histogram 原理： histogram是把数值类型的字段，按照一定的阶梯大小进行分组。你需要指定一个阶梯值（interval）来划分阶梯大小。 举例： 比如你有价格字段，如果你设定interval的值为200，那么阶梯就会是这样的： 0，200，400，600，… 上面列出的是每个阶梯的key，也是区间的启点。 如果一件商品的价格是450，会落入哪个阶梯区间呢？计算公式如下： 1bucket_key = Math.floor((value - offset) / interval) * interval + offset value：就是当前数据的值，本例中是450 offset：起始偏移量，默认为0 interval：阶梯间隔，比如200 因此你得到的key = Math.floor((450 - 0) / 200) * 200 + 0 = 400 操作一下： 比如，我们对汽车的价格进行分组，指定间隔interval为5000： 123456789101112GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&#123; "took" : 5, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "price" : &#123; "buckets" : [ &#123; "key" : 10000.0, "doc_count" : 2 &#125;, &#123; "key" : 15000.0, "doc_count" : 1 &#125;, &#123; "key" : 20000.0, "doc_count" : 2 &#125;, &#123; "key" : 25000.0, "doc_count" : 1 &#125;, &#123; "key" : 30000.0, "doc_count" : 1 &#125;, &#123; "key" : 35000.0, "doc_count" : 0 &#125;, &#123; "key" : 40000.0, "doc_count" : 0 &#125;, &#123; "key" : 45000.0, "doc_count" : 0 &#125;, &#123; "key" : 50000.0, "doc_count" : 0 &#125;, &#123; "key" : 55000.0, "doc_count" : 0 &#125;, &#123; "key" : 60000.0, "doc_count" : 0 &#125;, &#123; "key" : 65000.0, "doc_count" : 0 &#125;, &#123; "key" : 70000.0, "doc_count" : 0 &#125;, &#123; "key" : 75000.0, "doc_count" : 0 &#125;, &#123; "key" : 80000.0, "doc_count" : 1 &#125; ] &#125; &#125;&#125; 你会发现，中间有大量的文档数量为0 的桶，看起来很丑。 我们可以增加一个参数min_doc_count为1，来约束最少文档数量为1，这样文档数量为0的桶会被过滤 示例： 12345678910111213GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000, "min_doc_count": 1 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "price" : &#123; "buckets" : [ &#123; "key" : 10000.0, "doc_count" : 2 &#125;, &#123; "key" : 15000.0, "doc_count" : 1 &#125;, &#123; "key" : 20000.0, "doc_count" : 2 &#125;, &#123; "key" : 25000.0, "doc_count" : 1 &#125;, &#123; "key" : 30000.0, "doc_count" : 1 &#125;, &#123; "key" : 80000.0, "doc_count" : 1 &#125; ] &#125; &#125;&#125; 完美，！ 如果你用kibana将结果变为柱形图，会更好看： 范围分桶range范围分桶与阶梯分桶类似，也是把数字按照阶段进行分组，只不过range方式需要你自己指定每一组的起始和结束大小。 Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方： 很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的 需要自己把对象序列化为json存储 查询到结果也需要自己反序列化为对象 因此，我们这里就不讲解原生的Elasticsearch客户端API了。 而是学习Spring提供的套件：Spring Data Elasticsearch 简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。 查看 Spring Data的官网：http://projects.spring.io/spring-data/ Spring Data 是的使命是给各种数据访问提供统一的编程接口，不管是关系型数据库（如MySQL），还是非关系数据库（如Redis），或者类似Elasticsearch这样的索引数据库。从而简化开发人员的代码，提高开发效率。 包含很多不同数据操作的模块： Spring Data Elasticsearch的页面：https://projects.spring.io/spring-data-elasticsearch/ 特征： 支持Spring的基于@Configuration的java配置方式，或者XML配置方式 提供了用于操作ES的便捷工具类ElasticsearchTemplate。包括实现文档到POJO之间的自动智能映射。 利用Spring的数据转换服务实现的功能丰富的对象映射 基于注解的元数据映射方式，而且可扩展以支持更多不同的数据格式 根据持久层接口自动生成对应实现方法，无需人工编写基本操作代码（类似mybatis，根据接口自动得到实现）。当然，也支持人工定制查询 创建Demo工程我们新建一个Maven项目，学习Elasticsearch pom依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.study.demo&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;elasticsearch&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml文件配置： 12345spring: data: elasticsearch: cluster-name: elasticsearch cluster-nodes: 119.23.208.179:9300 索引操作创建索引和映射 实体类 首先我们准备好实体类： 12345678public class Item &#123; Long id; String title; //标题 String category;// 分类 String brand; // 品牌 Double price; // 价格 String images; // 图片地址&#125; 映射 Spring Data通过注解来声明字段的映射属性，有下面的三个注解： @Document 作用在类，标记实体类为文档对象，一般有两个属性 indexName：对应索引库名称 type：对应在索引库中的类型 shards：分片数量，默认5 replicas：副本数量，默认1 @Id 作用在成员变量，标记一个字段作为id主键 @Field 作用在成员变量，标记为文档的字段，并指定字段映射属性： type：字段类型，是是枚举：FieldType index：是否索引，布尔类型，默认是true store：是否存储，布尔类型，默认是false analyzer：分词器名称 示例： 1234567891011121314151617181920@Document(indexName = "item",type = "docs", shards = 1, replicas = 0)public class Item &#123; @Id private Long id; @Field(type = FieldType.Text, analyzer = "ik_max_word") private String title; //标题 @Field(type = FieldType.Keyword) private String category;// 分类 @Field(type = FieldType.Keyword) private String brand; // 品牌 @Field(type = FieldType.Double) private Double price; // 价格 @Field(index = false, type = FieldType.Keyword) private String images; // 图片地址&#125; 创建索引 ElasticsearchTemplate中提供了创建索引的API： 可以根据类的信息自动生成，也可以手动指定indexName和Settings 映射 映射相关的API： 一样，可以根据类的字节码信息（注解配置）来生成映射，或者手动编写映射 我们这里采用类的字节码信息创建索引并映射： 1234567@Testpublic void createIndex() &#123; // 创建索引，会根据Item类的@Document注解信息来创建 esTemplate.createIndex(Item.class); // 配置映射，会根据Item类中的id、Field等字段来自动完成映射 esTemplate.putMapping(Item.class);&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445GET /item&#123; "item": &#123; "aliases": &#123;&#125;, "mappings": &#123; "docs": &#123; "properties": &#123; "brand": &#123; "type": "keyword" &#125;, "category": &#123; "type": "keyword" &#125;, "images": &#123; "type": "keyword", "index": false &#125;, "price": &#123; "type": "double" &#125;, "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125; &#125; &#125; &#125;, "settings": &#123; "index": &#123; "refresh_interval": "1s", "number_of_shards": "1", "provided_name": "item", "creation_date": "1525405022589", "store": &#123; "type": "fs" &#125;, "number_of_replicas": "0", "uuid": "4sE9SAw3Sqq1aAPz5F6OEg", "version": &#123; "created": "6020499" &#125; &#125; &#125; &#125;&#125; 删除索引删除索引的API： 可以根据类名或索引名删除。 示例： 1234@Testpublic void deleteIndex() &#123; esTemplate.deleteIndex("test");&#125; 结果： 新增文档数据Repository接口Spring Data 的强大之处，就在于你不用写任何DAO处理，自动根据方法名或类的信息进行CRUD操作。只要你定义一个接口，然后继承Repository提供的一些子接口，就能具备各种基本的CRUD功能。 来看下Repository的继承关系： 我们看到有一个ElasticsearchCrudRepository接口： 所以，我们只需要定义接口，然后继承它就OK了。 12public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; &#123;&#125; 接下来，我们测试新增数据： 一个对象123456789@Autowiredprivate ItemRepository itemRepository;@Testpublic void index() &#123; Item item = new Item(1L, "小米手机7", " 手机", "小米", 3499.00, "http://image.codeopen.club/13123.jpg"); itemRepository.save(item);&#125; 去页面查询看看： 12345678910111213141516171819202122232425262728293031&#123; "took": 0, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 1, "max_score": 1, "hits": [ &#123; "_index": "item", "_type": "docs", "_id": "1", "_score": 1, "_source": &#123; "id": 1, "title": "小米手机7", "category": " 手机", "brand": "小米", "price": 3499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125; &#125; ] &#125;&#125; 批量新增代码： 12345678@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(2L, "坚果手机R1", " 手机", "锤子", 3699.00, "http://image.codeopen.club/123.jpg")); list.add(new Item(3L, "华为META10", " 手机", "华为", 4499.00, "http://image.codeopen.club/3.jpg")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 再次去页面查询： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#123; "took": 5, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 3, "max_score": 1, "hits": [ &#123; "_index": "item", "_type": "docs", "_id": "2", "_score": 1, "_source": &#123; "id": 2, "title": "坚果手机R1", "category": " 手机", "brand": "锤子", "price": 3699, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125;, &#123; "_index": "item", "_type": "docs", "_id": "3", "_score": 1, "_source": &#123; "id": 3, "title": "华为META10", "category": " 手机", "brand": "华为", "price": 4499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125;, &#123; "_index": "item", "_type": "docs", "_id": "1", "_score": 1, "_source": &#123; "id": 1, "title": "小米手机7", "category": " 手机", "brand": "小米", "price": 3499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125; ] &#125;&#125; 修改修改和新增是同一个接口，区分的依据就是id，这一点跟我们在页面发起PUT请求是类似的。 查询基本查询ElasticsearchRepository提供了一些基本的查询方法： 我们来试试查询所有： 12345678@Testpublic void query()&#123; // 查询全部，并安装价格降序排序 Iterable&lt;Item&gt; items = this.itemRepository.findAll(Sort.by("price").descending()); for (Item item : items) &#123; System.out.println("item = " + item); &#125;&#125; 结果： 自定义方法Spring Data 的另一个强大功能，是根据方法名称自动实现功能。 比如：你的方法名叫做：findByTitle，那么它就知道你是根据title查询，然后自动帮你完成，无需写实现类。 当然，方法名称要符合一定的约定： Keyword Sample Elasticsearch Query String And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 例如，我们来按照价格区间查询，定义这样的一个方法： 12345678910public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; &#123; /** * 根据价格区间查询 * @param price1 * @param price2 * @return */ List&lt;Item&gt; findByPriceBetween(double price1, double price2);&#125; 然后添加一些测试数据： 1234567891011@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1L, "小米手机7", "手机", "小米", 3299.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(2L, "坚果手机R1", "手机", "锤子", 3699.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(3L, "华为META10", "手机", "华为", 4499.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(4L, "小米Mix2S", "手机", "小米", 4299.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(5L, "荣耀V10", "手机", "华为", 2799.00, "http://image.leyou.com/13123.jpg")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 不需要写实现类，然后我们直接去运行： 1234567@Testpublic void queryByPriceBetween()&#123; List&lt;Item&gt; list = this.itemRepository.findByPriceBetween(2000.00, 3500.00); for (Item item : list) &#123; System.out.println("item = " + item); &#125;&#125; 结果： 自定义查询先来看最基本的match query： 123456789101112131415@Testpublic void search()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.matchQuery("title", "小米手机")); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("total = " + total); for (Item item : items) &#123; System.out.println(item); &#125;&#125; NativeSearchQueryBuilder：Spring提供的一个查询条件构建器，帮助构建json格式的请求体 QueryBuilders.matchQuery(“title”, “小米手机”)：利用QueryBuilders来生成一个查询。QueryBuilders提供了大量的静态方法，用于生成各种不同类型的查询： Page&lt;item&gt;：默认是分页查询，因此返回的是一个分页的结果对象，包含属性： totalElements：总条数 totalPages：总页数 Iterator：迭代器，本身实现了Iterator接口，因此可直接迭代得到当前页的数据 其它属性： 结果： 分页查询利用NativeSearchQueryBuilder可以方便的实现分页： 123456789101112131415161718192021222324252627@Testpublic void searchByPage()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.termQuery("category", "手机")); // 分页： int page = 0; int size = 2; queryBuilder.withPageable(PageRequest.of(page,size)); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("总条数 = " + total); // 总页数 System.out.println("总页数 = " + items.getTotalPages()); // 当前页 System.out.println("当前页：" + items.getNumber()); // 每页大小 System.out.println("每页大小：" + items.getSize()); for (Item item : items) &#123; System.out.println(item); &#125;&#125; 可以发现，Elasticsearch中的分页是从第0页开始。 排序排序也通用通过NativeSearchQueryBuilder完成： 1234567891011121314151617181920@Testpublic void searchAndSort()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.termQuery("category", "手机")); // 排序 queryBuilder.withSort(SortBuilders.fieldSort("price").order(SortOrder.ASC)); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("总条数 = " + total); for (Item item : items) &#123; System.out.println(item); &#125;&#125; 结果： 聚合聚合为桶桶就是分组，比如这里我们按照品牌brand进行分组： 12345678910111213141516171819202122232425@Testpublic void testAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms("brands").field("brand")); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("brands"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即品牌名称 System.out.println(bucket.getKeyAsString()); // 3.5、获取桶中的文档数量 System.out.println(bucket.getDocCount()); &#125;&#125; 显示的结果： 关键API： AggregationBuilders：聚合的构建工厂类。所有聚合都由这个类来构建，看看他的静态方法： AggregatedPage：聚合查询的结果类。它是Page&lt;T&gt;的子接口： AggregatedPage在Page功能的基础上，拓展了与聚合相关的功能，它其实就是对聚合结果的一种封装，大家可以对照聚合结果的JSON结构来看。 而返回的结果都是Aggregation类型对象，不过根据字段类型不同，又有不同的子类表示 我们看下页面的查询的JSON结果与Java类的对照关系： 嵌套聚合，求平均值代码： 1234567891011121314151617181920212223242526272829@Testpublic void testSubAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms("brands").field("brand") .subAggregation(AggregationBuilders.avg("priceAvg").field("price")) // 在品牌聚合桶内进行嵌套聚合，求平均值 ); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("brands"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即品牌名称 3.5、获取桶中的文档数量 System.out.println(bucket.getKeyAsString() + "，共" + bucket.getDocCount() + "台"); // 3.6.获取子聚合结果： InternalAvg avg = (InternalAvg) bucket.getAggregations().asMap().get("priceAvg"); System.out.println("平均售价：" + avg.getValue()); &#125;&#125; 结果：]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Docker 安装 FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2F%E5%9F%BA%E4%BA%8E%20Docker%20%E5%AE%89%E8%A3%85%20FastDFS%2F</url>
    <content type="text"><![CDATA[环境准备所需全部环境配置文件及安装包 libfastcommon.tar.gz fastdfs-5.11.tar.gz nginx-1.13.6.tar.gz fastdfs-nginx-module_v1.16.tar.gz 创建工作目录在 Linux 服务器上创建 /usr/local/docker/fastdfs/environmen 目录 说明： /usr/local/docker/fastdfs：用于存放 docker-compose.yml 配置文件及 FastDFS 的数据卷 /usr/local/docker/fastdfs/environmen：用于存放 Dockerfile 镜像配置文件及 FastDFS 所需环境 docker-compose.yml123456789version: '3.1'services: fastdfs: build: environment restart: always container_name: fastdfs volumes: - ./storage:/fastdfs/storage network_mode: host Dockerfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960FROM ubuntu:xenialMAINTAINER topsale@vip.qq.com# 更新数据源WORKDIR /etc/aptRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiverse&apos; &gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse&apos; &gt;&gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse&apos; &gt;&gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse&apos; &gt;&gt; sources.listRUN apt-get update# 安装依赖RUN apt-get install make gcc libpcre3-dev zlib1g-dev --assume-yes# 复制工具包ADD fastdfs-5.11.tar.gz /usr/local/srcADD fastdfs-nginx-module_v1.16.tar.gz /usr/local/srcADD libfastcommon.tar.gz /usr/local/srcADD nginx-1.13.6.tar.gz /usr/local/src# 安装 libfastcommonWORKDIR /usr/local/src/libfastcommonRUN ./make.sh &amp;&amp; ./make.sh install# 安装 FastDFSWORKDIR /usr/local/src/fastdfs-5.11RUN ./make.sh &amp;&amp; ./make.sh install# 配置 FastDFS 跟踪器ADD tracker.conf /etc/fdfsRUN mkdir -p /fastdfs/tracker# 配置 FastDFS 存储ADD storage.conf /etc/fdfsRUN mkdir -p /fastdfs/storage# 配置 FastDFS 客户端ADD client.conf /etc/fdfs# 配置 fastdfs-nginx-moduleADD config /usr/local/src/fastdfs-nginx-module/src# FastDFS 与 Nginx 集成WORKDIR /usr/local/src/nginx-1.13.6RUN ./configure --add-module=/usr/local/src/fastdfs-nginx-module/srcRUN make &amp;&amp; make installADD mod_fastdfs.conf /etc/fdfsWORKDIR /usr/local/src/fastdfs-5.11/confRUN cp http.conf mime.types /etc/fdfs/# 配置 NginxADD nginx.conf /usr/local/nginx/confCOPY entrypoint.sh /usr/local/bin/ENTRYPOINT [&quot;/usr/local/bin/entrypoint.sh&quot;]WORKDIR /EXPOSE 8888CMD [&quot;/bin/bash&quot;] entrypoint.sh1234#!/bin/sh/etc/init.d/fdfs_trackerd start/etc/init.d/fdfs_storaged start/usr/local/nginx/sbin/nginx -g &apos;daemon off;&apos; 注：Shell 创建后是无法直接使用的，需要赋予执行的权限，使用 chmod +x entrypoint.sh 命令 各种配置文件说明tracker.confFastDFS 跟踪器配置，容器中路径为：/etc/fdfs，修改为： 1base_path=/fastdfs/tracker storage.confFastDFS 存储配置，容器中路径为：/etc/fdfs，修改为： 1234base_path=/fastdfs/storagestore_path0=/fastdfs/storagetracker_server=192.168.75.128:22122http.server_port=8888 client.confFastDFS 客户端配置，容器中路径为：/etc/fdfs，修改为： 12base_path=/fastdfs/trackertracker_server=192.168.75.128:22122 configfastdfs-nginx-module 配置文件，容器中路径为：/usr/local/src/fastdfs-nginx-module/src，修改为： 1234567# 修改前CORE_INCS=&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot;CORE_LIBS=&quot;$CORE_LIBS -L/usr/local/lib -lfastcommon -lfdfsclient&quot;# 修改后CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot;CORE_LIBS=&quot;$CORE_LIBS -L/usr/lib -lfastcommon -lfdfsclient&quot; mod_fastdfs.conffastdfs-nginx-module 配置文件，容器中路径为：/usr/local/src/fastdfs-nginx-module/src，修改为： 1234connect_timeout=10tracker_server=192.168.75.128:22122url_have_group_name = truestore_path0=/fastdfs/storage nginx.confNginx 配置文件，容器中路径为：/usr/local/src/nginx-1.13.6/conf，修改为： 1234567891011121314151617181920212223242526272829user root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 8888; server_name localhost; location ~/group([0-9])/M00 &#123; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 启动容器1docker-compose up -d 测试上传交互式进入容器1docker exec -it fastdfs /bin/bash 测试文件上传1/usr/bin/fdfs_upload_file /etc/fdfs/client.conf /usr/local/src/fastdfs-5.11/INSTALL 服务器反馈上传地址1group1/M00/00/00/wKhLi1oHVMCAT2vrAAAeSwu9hgM3976341 测试 Nginx 访问1http://192.168.0.128:8888/group1/M00/00/00/wKhLi1oHVMCAT2vrAAAeSwu9hgM3976341]]></content>
      <categories>
        <category>FastDFS</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下安装FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2FUbuntu%E4%B8%8B%E5%AE%89%E8%A3%85FastDFS%2F</url>
    <content type="text"><![CDATA[Ubuntu安装FastDFS安装依赖安装libevent1234567891011121314防火墙ufw enableufw disable自启动管理：apt-get install sysv-rc-confapt-get install makeapt-get install unzipapt-get install gccapt-get install libevent-dev 安装libfastcommon通过git下载即可： https://github.com/happyfish100/libfastcommon.git 12apt install unzipapt install gcc nginx依赖12345678910111213安装gcc g++的依赖库sudo apt-get install build-essentialsudo apt-get install libtool安装pcre依赖库（http://www.pcre.org/）sudo apt-get updatesudo apt-get install libpcre3 libpcre3-dev安装zlib依赖库（http://www.zlib.net）sudo apt-get install zlib1g-dev安装SSL依赖库（16.04默认已经安装了）sudo apt-get install openssl]]></content>
      <categories>
        <category>FastDFS</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下安装FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2FCentos%E4%B8%8B%E5%AE%89%E8%A3%85FastDFS%2F</url>
    <content type="text"><![CDATA[Centos下安装FastDFS安装依赖FastDFS运行需要一些依赖，在课前资料提供的虚拟中已经安装好了这些依赖，如果大家想要从头学习，可以按下面方式安装： 安装GCC依赖GCC用来对C语言代码进行编译运行，使用yum命令安装： 1sudo yum -y install gcc 安装unzip工具unzip工具可以帮我们对压缩包进行解压 1sudo yum install -y unzip zip 安装libevent1sudo yum -y install libevent 安装Nginx所需依赖1sudo yum -y install pcre pcre-devel zlib zlib-devel openssl openssl-devel 安装libfastcommon-master这个没有yum包，只能通过编译安装： 解压刚刚上传的libfastcommon-master.zip 1unzip libfastcommon-master.zip 进入解压完成的目录： 1cd libfastcommon-master 编译并且安装： 12sudo ./make.sh sudo ./make.sh install 到这里为止，所有依赖都已经安装完毕，接下来我们安装FastDFS： 安装FastDFS编译安装这里我们也采用编译安装，步骤与刚才的编译安装方式一样： 解压 1tar -xvf FastDFS_v5.08.tar.gz 进入目录 1cd FastDFS 编译并安装 12sudo ./make.sh sudo ./make.sh install 校验安装结果 1）安装完成，我们应该能在/etc/init.d/目录，通过命令ll /etc/init.d/ | grep fdfs看到FastDFS提供的启动脚本： 其中： fdfs_trackerd 是tracker启动脚本 fdfs_storaged 是storage启动脚本 2）我们可以在 /etc/fdfs目录，通过命令查看到以下配置文件模板： 其中： tarcker.conf.sample 是tracker的配置文件模板 storage.conf.sample 是storage的配置文件模板 client.conf.sample 是客户端的配置文件模板 启动trackercdFastDFS的tracker和storage在刚刚的安装过程中，都已经被安装了，因此我们安装这两种角色的方式是一样的。不同的是，两种需要不同的配置文件。 我们要启动tracker，就修改刚刚看到的tarcker.conf，并且启动fdfs_trackerd脚本即可。 编辑tracker配置 首先我们将模板文件进行赋值和重命名： 12sudo cp tracker.conf.sample tracker.confsudo vim tracker.conf 打开tracker.conf，修改base_path配置： 1base_path=/leyou/fdfs/tracker # tracker的数据和日志存放目录 创建目录 刚刚配置的目录可能不存在，我们创建出来 1sudo mkdir -p /leyou/fdfs/tracker 启动tracker 我们可以使用 sh /etc/init.d/fdfs_trackerd 启动，不过安装过程中，fdfs已经被设置为系统服务，我们可以采用熟悉的服务启动方式： 1sudo service fdfs_trackerd start # 启动fdfs_trackerd服务，停止用stop 另外，我们可以通过以下命令，设置tracker开机启动： 1sudo chkconfig fdfs_trackerd on 启动storage我们要启动tracker，就修改刚刚看到的tarcker.conf，并且启动fdfs_trackerd脚本即可。 编辑storage配置 首先我们将模板文件进行赋值和重命名： 12sudo cp storage.conf.sample storage.confsudo vim storage.conf 打开storage.conf，修改base_path配置： 123base_path=/leyou/fdfs/storage # storage的数据和日志存放目录store_path0=/leyou/fdfs/storage # storage的上传文件存放路径tracker_server=192.168.56.101:22122 # tracker的地址 创建目录 刚刚配置的目录可能不存在，我们创建出来 1sudo mkdir -p /leyou/fdfs/storage 启动storage 我们可以使用 sh /etc/init.d/fdfs_storaged 启动，同样我们可以用服务启动方式： 1sudo service fdfs_storaged start # 启动fdfs_storaged服务，停止用stop 另外，我们可以通过以下命令，设置tracker开机启动： 1sudo chkconfig fdfs_storaged on 最后，通过ps -ef | grep fdfs 查看进程： 安装Nginx及FastDFS模块FastDFS的Nginx模块 解压 1tar -xvf fastdfs-nginx-module_v1.16.tar.gz ​ 配置config文件 123456# 进入配置目录cd /home/leyou/fdfs/fastdfs-nginx-module/src/# 修改配置vim config# 执行下面命令（将配置中的/usr/local改为/usr）：:%s+/usr/local/+/usr/+g ​ 配置mod_fastdfs.conf 1234# 将src目录下的mod_fastdfs.conf复制到 /etc/fdfs目录：sudo cp mod_fastdfs.conf /etc/fdfs/# 编辑该文件sudo vim /etc/fdfs/mod_fastdfs.conf 修改一下配置： 1234connect_timeout=10 # 客户端访问文件连接超时时长（单位：秒）tracker_server=192.168.56.101:22122 # tracker服务IP和端口url_have_group_name=true # 访问链接前缀加上组名store_path0=/leyou/fdfs/storage # 文件存储路径 复制 FastDFS的部分配置文件到/etc/fdfs目录 12cd /home/leyou/fdfs/FastDFS/conf/cp http.conf mime.types /etc/fdfs/ ​ 安装Nginx 解压 1tar -xvf nginx-1.10.0.tar.gz ​ 配置 1sudo ./configure --prefix=/opt/nginx --sbin-path=/usr/bin/nginx --add-module=/home/leyou/fdfs/fastdfs-nginx-module/src ​ 编译安装 1sudo make &amp;&amp; sudo make install ​ 配置nginx整合fastdfs-module模块 我们需要修改nginx配置文件，在/opt/nginx/config/nginx.conf文件中： 1sudo vim /opt/nginx/conf/nginx.conf 将文件中，原来的server 80{ ...} 部分代码替换为如下代码： 12345678910111213141516171819server &#123; listen 80; server_name image.leyou.com; # 监听域名中带有group的，交给FastDFS模块处理 location ~/group([0-9])/ &#123; ngx_fastdfs_module; &#125; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动 123nginx # 启动nginx -s stop # 停止nginx -s reload # 重新加载配置 设置nginx开机启动 创建一个开机启动的脚本： 1vim /etc/init.d/nginx 添加以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: NGINX is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0nginx="/usr/bin/nginx"prog=$(basename $nginx)NGINX_CONF_FILE="/opt/nginx/conf/nginx.conf"[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginxmake_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep "configure arguments:.*--user=" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` if [ -n "$user" ]; then if [ -z "`grep $user /etc/passwd`" ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done fi&#125;start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest || return $? stop sleep 1 start&#125;reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125;force_reload() &#123; restart&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 修改文件权限，并加入服务列表 1234# 修改权限chmod 777 /etc/init.d/nginx # 添加到服务列表chkconfig --add /etc/init.d/nginx 设置开机启动 1systemctl enable nginx]]></content>
      <categories>
        <category>FastDFS</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS快速入门]]></title>
    <url>%2F2019%2F01%2F28%2FFastDFS%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是FastDFSFastDFS是由淘宝的余庆先生所开发的一个轻量级、高性能的开源分布式文件系统。用纯C语言开发，功能丰富： 文件存储 文件同步 文件访问（上传、下载） 存取负载均衡 在线扩容 适合有大容量存储需求的应用或系统。同类的分布式文件系统有谷歌的GFS、HDFS（Hadoop）、TFS（淘宝）等。 FastDFS的架构架构图先上图： FastDFS两个主要的角色：Tracker Server 和 Storage Server 。 Tracker Server：跟踪服务器，主要负责调度storage节点与client通信，在访问上起负载均衡的作用，和记录storage节点的运行状态，是连接client和storage节点的枢纽。 Storage Server：存储服务器，保存文件和文件的meta data（元数据），每个storage server会启动一个单独的线程主动向Tracker cluster中每个tracker server报告其状态信息，包括磁盘使用情况，文件同步情况及文件上传下载次数统计等信息 Group：文件组，多台Storage Server的集群。上传一个文件到同组内的一台机器上后，FastDFS会将该文件即时同步到同组内的其它所有机器上，起到备份的作用。不同组的服务器，保存的数据不同，而且相互独立，不进行通信。 Tracker Cluster：跟踪服务器的集群，有一组Tracker Server（跟踪服务器）组成。 Storage Cluster ：存储集群，有多个Group组成。 上传和下载流程 上传 Client通过Tracker server查找可用的Storage server。 Tracker server向Client返回一台可用的Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并进行文件上传。 上传完成，Storage server返回Client一个文件ID，文件上传结束。 下载 Client通过Tracker server查找要下载文件所在的的Storage server。 Tracker server向Client返回包含指定文件的某个Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并指定要下载文件。 下载文件成功。 安装和使用安装资源准备，将如下文件下载 百度云盘资源下载地址 Centos安装：站内搜索Centos下安装FastDFSUbuntu安装：站内搜索``java客户端余庆先生提供了一个Java客户端，但是作为一个C程序员，写的java代码可想而知。而且已经很久不维护了。 这里推荐一个开源的FastDFS客户端，支持最新的SpringBoot2.0。 配置使用极为简单，支持连接池，支持自动生成缩略图，狂拽酷炫吊炸天啊，有木有。 地址：tobato/FastDFS_client 引入依赖在父工程中，我们已经管理了依赖，版本为： 1&lt;fastDFS.client.version&gt;1.26.2&lt;/fastDFS.client.version&gt; 因此，这里我们直接引入坐标即可： 1234&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;&lt;/dependency&gt; 引入配置类纯java配置： 123456@Configuration@Import(FdfsClientConfig.class)// 解决jmx重复注册bean的问题@EnableMBeanExport(registration = RegistrationPolicy.IGNORE_EXISTING)public class FastClientImporter &#123;&#125; 编写FastDFS属性12345678fdfs: so-timeout: 1501 connect-timeout: 601 thumb-image: # 缩略图 width: 60 height: 60 tracker-list: # tracker地址 - FastDFS主机IP:22122 测试12345678910111213141516171819202122232425262728293031323334353637@RunWith(SpringRunner.class)@SpringBootTest(classes = UploadService.class)public class FdfsTest &#123; @Autowired private FastFileStorageClient storageClient; @Autowired private ThumbImageConfig thumbImageConfig; @Test public void testUpload() throws FileNotFoundException &#123; File file = new File("D:\\test\\baby.png"); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadFile( new FileInputStream(file), file.length(), "png", null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); &#125; @Test public void testUploadAndCreateThumb() throws FileNotFoundException &#123; File file = new File("D:\\test\\baby.png"); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadImageAndCrtThumbImage( new FileInputStream(file), file.length(), "png", null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); // 获取缩略图路径 String path = thumbImageConfig.getThumbImagePath(storePath.getPath()); System.out.println(path); &#125;&#125;]]></content>
      <categories>
        <category>FastDFS</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Mybatis分页助手pagehelper]]></title>
    <url>%2F2019%2F01%2F28%2FSpringBoot%E6%95%B4%E5%90%88Mybatis%E5%88%86%E9%A1%B5%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[文档 github地址 使用案例 快速上手在 pom.xml 中添加如下依赖：123456789101112131415161718&lt;!--mybatis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--mapper--&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;!--pagehelper--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.10&lt;/version&gt;&lt;/dependency&gt; 在service中使用分页助手1234567891011121314151617181920212223242526272829@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; public PageResult&lt;User&gt; queryUserByPageAndSort( Integer page, Integer rows, String sortBy, Boolean desc, String key) &#123; // 开始分页 PageHelper.startPage(page, rows); // 过滤 Example example = new Example(User.class); if (StringUtils.isNotBlank(key)) &#123; example.createCriteria().andLike("name", "%" + key + "%") .orEqualTo("letter", key.toUpperCase()); &#125; if (StringUtils.isNotBlank(sortBy)) &#123; // 排序 String orderByClause = sortBy + (desc ? " DESC" : " ASC"); example.setOrderByClause(orderByClause); &#125; // 查询 List&lt;User&gt; list = (Page&lt;User&gt;) brandMapper.selectByExample(example); // 解析分页结果 PageInfo&lt;User&gt; info = new PageInfo&lt;&gt;(list); // 返回结果 return new PageResult&lt;&gt;(info.getTotal(),list); &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
        <category>pagehelper</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>pagehelper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通用异常处理]]></title>
    <url>%2F2019%2F01%2F26%2F%E9%80%9A%E7%94%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[在项目中出现异常是在所难免的，但是出现异常后怎么处理，这就是很有学问了。 场景预设场景我们预设这样一个场景，假如我们做新增商品，需要接受下面的参数： 12price: 价格name: 名称 然后对数据做简单校验 价格不能为空 新增时，自动形成ID，然后随商品对象一起返回 代码为了操作方便，使用假数据，不涉及持久层 实体类： 123456@Data // lombokpublic class Item&#123; private Integer id; private String name; private Long price;&#125; service： 12345678910@Servicepublic class ItemService &#123; // 商品新增 public Item saveItem(Item item)&#123; int id = new Random().nextInt(100); item.setId(id); return item; &#125;&#125; controller： 12345678910111213141516@RestController@RequestMapping("item")public class ItemController &#123; @Autowired private ItemService itemService; @PostMapping public ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(null); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item)); &#125;&#125; 响应状态码： Code HTTP Operation Body Contents Description 200 GET,PUT 资源 操作成功 201 POST 资源，元数据 对象创建成功 202 POST,PUT,DELETE,PATCH N/A 请求已经被接受 204 PUT,DELETE,PATCH N/A 操作已经执行成功，但是没有返回数据 301 GET link 资源已被移除 303 GET link 重定向 304 GET N/A 资源没有被修改 400 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 参数列表错误(缺少，格式不匹配) 401 GET,POST,PUT,DELETE,PATCH 错误提示(消息) w未授权 403 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 访问受限，授权过期 404 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 资源，服务未找到 405 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 不允许的http方法 409 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 资源冲突，或者资源被锁定 415 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 不支持的数据(媒体)类型 429 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 请求过多被限制 500 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 系统内部错误 501 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 接口未实现 统一异常处理rest客户端：https://insomnia.rest/ 初步测试现在我们启动项目，做下测试： 通过insomnia去访问： 发现参数不正确时，返回了400。看起来没问题 统一异常处理我们先修改controller的代码，把异常抛出： 12345678@PostMappingpublic ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; throw new RuntimeException("价格不能为空"); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item));&#125; 接下来，我们使用SpringMVC提供的统一异常拦截器，因为时统一处理，我们放到common项目中： 新建一个类CommonExceptionHandler: 123456789@ControllerAdvice@Slf4jpublic class CommonExceptionHandler &#123; @ExceptionHandler(RuntimeException.class) public ResponseEntity&lt;String&gt; handleException(RuntimeException e)&#123; return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(e.getMessage()); &#125;&#125; 解读： @ControllerAdvice：默认情况下，会拦截所有加了@Controller注解的类 @ExceptionHandler(RuntimeException.class)：作用在方法上，声明要处理的异常类型，可以有多个，这里指定的时RuntimeException，被声明的方法可以看做是一个SPringMVC的Handler： 参数是要处理的异常，类型必须要匹配 返回结果可以是ModelAndView、ResponseEntity等，基本与handler类似 这里等于是从新定义了返回结果，我们可以随意指定想要的返回类型。此处使用了String 然后在service项目中引入common 12345&lt;dependency&gt; &lt;groupId&gt;com.study.common&lt;/groupId&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 重启项目测试： 发现成功获取了提示信息 但是，发现状态码和提示信息被写死了 自定义通用异常处理自定义通用异常消息枚举123456789@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; PRICE_CANNOT_BE_NULL(400,"价格不能为空") ; private int code; private String msg;&#125; 自定义异常返回结果类123456789101112@Datapublic class ExceptionResult &#123; private int status; private String message; private Long timestamp; public ExceptionResult(ExceptionEnum em) &#123; this.status = em.getCode(); this.message = em.getMsg(); this.timestamp = System.currentTimeMillis(); &#125;&#125; 自定义通用异常类123456@NoArgsConstructor@AllArgsConstructor@Getterpublic class CustomException extends RuntimeException &#123; private ExceptionEnum exceptionEnum;&#125; 自定义通用异常处理类12345678910@ControllerAdvice@Slf4jpublic class CommonExceptionHandler &#123; @ExceptionHandler(CustomException.class) public ResponseEntity&lt;ExceptionResult&gt; handleException(CustomException e)&#123; return ResponseEntity.status(e.getExceptionEnum().getCode()) .body(new ExceptionResult(e.getExceptionEnum())); &#125;&#125; 使用通用异常处理12345678910111213141516@RestController@RequestMapping("item")public class ItemController &#123; @Autowired private ItemService itemService; @PostMapping public ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; throw new CustomException(ExceptionEnum.PRICE_CANNOT_BE_NULL); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item)); &#125;&#125; 启动项目，查看结果]]></content>
      <categories>
        <category>通用异常处理</category>
      </categories>
      <tags>
        <tag>通用异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue-cli 快速上手]]></title>
    <url>%2F2019%2F01%2F26%2Fvue-cli%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[介绍和安装在开发中，需要打包的东西不止是js、css、html。还有更多的东西要处理，这些插件和加载器如果我们一一去添加就会比较麻烦。 幸好，vue官方提供了一个快速搭建vue项目的脚手架：vue-cli 使用它能快速的构建一个web工程模板。 官网：https://github.com/vuejs/vue-cli 安装命令： 1npm install -g vue-cli 快速上手我们新建一个文件夹hello-vue-cli,打开终端并进入目录. 用vue-cli命令，快速搭建一个webpack的项目： 1vue init webpack 前面几项都走默认或yes 下面这些我们选no 最后，再选yes，使用 npm安装 项目结构安装好的项目结构： 入口文件： 单文件组件： 每一个.vue文件，就是一个独立的vue组件。类似于我们刚才写的loginForm.js和registerForm.js 只不过，我们在js中编写 html模板和样式非常的不友好，而且没有语法提示和高亮。 而单文件组件中包含三部分内容： template：模板，支持html语法高亮和提示 script：js脚本，这里编写的就是vue的组件对象，看到上面的data(){}了吧 style：样式，支持CSS语法高亮和提示 每个组件都有自己独立的html、JS、CSS，互不干扰，真正做到可独立复用 运行看生成的package.json： 可以看到这引入了非常多的依赖，绝大多数都是开发期依赖，比如大量的加载器。 运行时依赖只有vue和vue-router 脚本有三个： dev：使用了webpack-dev-server命令，开发时热部署使用 start：使用了npm run dev命令，与上面的dev效果完全一样 build：等同于webpack的打包功能，会打包到dist目录下。 我们执行npm run dev 或者 npm start 都可以启动项目： 页面：]]></content>
      <categories>
        <category>vue-cli</category>
      </categories>
      <tags>
        <tag>vue-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue父子组件通信]]></title>
    <url>%2F2019%2F01%2F25%2FVue%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[父组件向子组件传值 组件实例定义方式，注意：一定要使用props属性来定义父组件传递过来的数据 123456789101112131415&lt;script&gt; // 创建 Vue 实例，得到 ViewModel var vm = new Vue(&#123; el: '#app', data: &#123; msg: '这是父组件中的消息' &#125;, components: &#123; son: &#123; template: '&lt;h1&gt;这是子组件 --- &#123;&#123;finfo&#125;&#125;&lt;/h1&gt;', props: ['finfo'] &#125; &#125; &#125;); &lt;/script&gt; 使用v-bind或简化指令，将数据传递到子组件中： 123&lt;div id="app"&gt; &lt;son :finfo="msg"&gt;&lt;/son&gt; &lt;/div&gt; 子组件向父组件传值 原理：父组件将方法的引用，传递到子组件内部，子组件在内部调用父组件传递过来的方法，同时把要发送给父组件的数据，在调用方法的时候当作参数传递进去； 父组件将方法的引用传递给子组件，其中，getMsg是父组件中methods中定义的方法名称，func是子组件调用传递过来方法时候的方法名称 1&lt;son @func=&quot;getMsg&quot;&gt;&lt;/son&gt; 子组件内部通过this.$emit(&#39;方法名&#39;, 要传递的数据)方式，来调用父组件中的方法，同时把数据传递给父组件使用 12345678910111213141516171819202122232425262728293031323334&lt;div id="app"&gt; &lt;!-- 引用父组件 --&gt; &lt;son @func="getMsg"&gt;&lt;/son&gt; &lt;!-- 组件模板定义 --&gt; &lt;script type="x-template" id="son"&gt; &lt;div&gt; &lt;input type="button" value="向父组件传值" @click="sendMsg" /&gt; &lt;/div&gt; &lt;/script&gt; &lt;/div&gt; &lt;script&gt; // 子组件的定义方式 Vue.component('son', &#123; template: '#son', // 组件模板Id methods: &#123; sendMsg() &#123; // 按钮的点击事件 this.$emit('func', 'OK'); // 调用父组件传递过来的方法，同时把数据传递出去 &#125; &#125; &#125;); // 创建 Vue 实例，得到 ViewModel var vm = new Vue(&#123; el: '#app', data: &#123;&#125;, methods: &#123; getMsg(val)&#123; // 子组件中，通过 this.$emit() 实际调用的方法，在此进行定义 alert(val); &#125; &#125; &#125;); &lt;/script&gt;]]></content>
      <categories>
        <category>Vuejs</category>
      </categories>
      <tags>
        <tag>Vuejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运用Swagger编写API文档]]></title>
    <url>%2F2019%2F01%2F25%2FSwagger%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是Swagger随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、先后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。 前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要，`swagger`就是一款让你更好的书写API文档的框架。 SwaggerEditor安装与启动（1） 下载 （2）解压swagger-editor, （3）全局安装http-server(http-server是一个简单的零配置命令行http服务器) 1npm install -g http-server （4）启动swagger-editor 1http-server swagger-editor （5）浏览器打开： http://localhost:8080 语法规则（1）固定字段 字段名 类型 描述 swagger string 必需的。使用指定的规范版本。 info Info Object 必需的。提供元数据API。 host string 主机名或ip服务API。 basePath string API的基本路径 schemes [string] API的传输协议。 值必须从列表中:”http”,”https”,”ws”,”wss”。 consumes [string] 一个MIME类型的api可以使用列表。值必须是所描述的Mime类型。 produces [string] MIME类型的api可以产生的列表。 值必须是所描述的Mime类型。 paths 路径对象 必需的。可用的路径和操作的API。 definitions 定义对象 一个对象数据类型生产和使用操作。 parameters 参数定义对象 一个对象来保存参数,可以使用在操作。 这个属性不为所有操作定义全局参数。 responses 反应定义对象 一个对象响应,可以跨操作使用。 这个属性不为所有操作定义全球响应。 externalDocs 外部文档对象 额外的外部文档。 summary string 什么操作的一个简短的总结。 最大swagger-ui可读性,这一领域应小于120个字符。 description string 详细解释操作的行为。GFM语法可用于富文本表示。 operationId string 独特的字符串用于识别操作。 id必须是唯一的在所有业务中所描述的API。 工具和库可以使用operationId来唯一地标识一个操作,因此,建议遵循通用的编程的命名约定。 deprecated boolean 声明该操作被弃用。 使用声明的操作应该没有。 默认值是false。 （2）字段类型与格式定义 普通的名字 type format 说明 integer integer int32 签署了32位 long integer int64 签署了64位 float number float double number double string string byte string byte base64编码的字符 binary string binary 任何的八位字节序列 boolean boolean date string date 所定义的full-date- - - - - -RFC3339 dateTime string date-time 所定义的date-time- - - - - -RFC3339 password string password 用来提示用户界面输入需要模糊。 基础模块-城市API文档新增城市编写新增城市的API , post提交城市实体 URL： /city Method: post 编写后的文档内容如下： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748swagger: '2.0'info: version: "1.0.0" title: 基础模块-城市APIbasePath: /basehost: api.tensquare.compaths: /city: post: summary: 新增城市 parameters: - name: "body" in: "body" description: 城市实体类 required: true schema: $ref: '#/definitions/City' responses: 200: description: 成功 schema: $ref: '#/definitions/ApiResponse'definitions: City: type: object properties: id: type: string description: "ID" name: type: string description: "名称" ishot: type: string description: 是否热门 ApiResponse: type: object properties: flag: type: boolean description: 是否成功 code: type: integer format: int32 description: 返回码 message: type: string description: 返回信息 编辑后可以在右侧窗口看到显示的效果 修改城市URL： /city/{cityId} Method: put 编写后的文档内容如下： 代码如下： 12345678910111213141516171819/city/&#123;cityId&#125;: put: summary: 修改城市 parameters: - name: cityId in: path description: 城市ID required: true type: string - name: body in: body description: 城市 schema: $ref: '#/definitions/City' responses: 200: description: 成功响应 schema: $ref: '#/definitions/ApiResponse' 删除城市删除城市地址为/city/{cityId} ，与修改城市的地址相同，区别在于使用delete方法提交请求 代码如下： （/city/{cityId} 下增加delete） 1234567891011121314delete: summary: 根据ID删除 description: 返回是否成功 parameters: - name: cityId in: path description: 城市ID required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ApiResponse' 根据ID查询城市URL: /city/{cityId} Method: get 返回的内容结构为： {flag:true,code:20000, message:”查询成功”,data: {…..} } data属性返回的是city的实体类型 代码实现如下： （1）在definitions下定义城市对象的响应对象 123456789101112ApiCityResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: $ref: '#/definitions/City' （2）/city/{cityId} 下新增get方法API 1234567891011121314get: summary: 根据ID查询 description: 返回一个城市 parameters: - name: cityId in: path description: 城市ID required: true type: string responses: '200': description: 操作成功 schema: $ref: '#/definitions/ApiCityResponse' 城市列表URL: /city Method: get 返回的内容结构为： {flag:true,code:20000, message:”查询成功”,data:[{…..},{…..},{…..}] } data属性返回的是city的实体数组 实现步骤如下： （1）在definitions下定义城市列表对象以及相应对象 12345678910111213141516CityList: type: "array" items: $ref: '#/definitions/City'ApiCityListResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: $ref: '#/definitions/CityList' （2）在/city增加get 12345678get: summary: "城市全部列表" description: "返回城市全部列表" responses: 200: description: "成功查询到数据" schema: $ref: '#/definitions/ApiCityListResponse' 根据条件查询城市列表实现API效果如下: 代码如下： 123456789101112131415/city/search: post: summary: 城市列表(条件查询) parameters: - name: body in: body description: 查询条件 required: true schema: $ref: "#/definitions/City" responses: 200: description: 查询成功 schema: $ref: '#/definitions/ApiCityListResponse' 城市分页列表实现API效果如下： 实现如下： （1）在definitions下定义城市分页列表响应对象 1234567891011121314151617ApiCityPageResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: properties: total: type: "integer" format: "int32" rows: $ref: '#/definitions/CityList' （2）新增节点 123456789101112131415161718192021222324252627/city/search/&#123;page&#125;/&#123;size&#125;: post: summary: 城市分页列表 parameters: - name: page in: path description: 页码 required: true type: integer format: int32 - name: size in: path description: 页大小 required: true type: integer format: int32 - name: body in: body description: 查询条件 required: true schema: $ref: "#/definitions/City" responses: 200: description: 查询成功 schema: $ref: '#/definitions/ApiCityPageResponse' SwaggerUISwaggerUI是用来展示Swagger文档的界面，以下为安装步骤 （1）在本地安装nginx （2）下载SwaggerUI源码 https://swagger.io/download-swagger-ui/ （3）解压，将dist文件夹下的全部文件拷贝至 nginx的html目录 （4）启动nginx （5）浏览器打开页面 http://localhost即可看到文档页面 （6）我们将编写好的yml文件也拷贝至nginx的html目录，这样我们就可以加载我们的swagger文档了]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES6 语法指南]]></title>
    <url>%2F2019%2F01%2F25%2FES6%20%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[什么是ECMAScript来看下前端的发展历程： web1.0时代： 最初的网页以HTML为主，是纯静态的网页。网页是只读的，信息流只能从服务的到客户端单向流通。开发人员也只关心页面的样式和内容即可。 web2.0时代： 1995年，网景工程师Brendan Eich 花了10天时间设计了JavaScript语言。 1996年，微软发布了JScript，其实是JavaScript的逆向工程实现。 1997年，为了统一各种不同script脚本语言，ECMA（欧洲计算机制造商协会）以JavaScript为基础，制定了ECMAscript标准规范。JavaScript和JScript都是ECMAScript的标准实现者，随后各大浏览器厂商纷纷实现了ECMAScript标准。 所以，ECMAScript是浏览器脚本语言的规范，而各种我们熟知的js语言，如JavaScript则是规范的具体实现。 ECMAScript的快速发展而后，ECMAScript就进入了快速发展期。 1998年6月，ECMAScript 2.0 发布。 1999年12月，ECMAScript 3.0 发布。这时，ECMAScript 规范本身也相对比较完善和稳定了，但是接下来的事情，就比较悲剧了。 2007年10月。。。。ECMAScript 4.0 草案发布。 这次的新规范，历时颇久，规范的新内容也有了很多争议。在制定ES4的时候，是分成了两个工作组同时工作的。 一边是以 Adobe, Mozilla, Opera 和 Google为主的 ECMAScript 4 工作组。 一边是以 Microsoft 和 Yahoo 为主的 ECMAScript 3.1 工作组。 ECMAScript 4 的很多主张比较激进，改动较大。而 ECMAScript 3.1 则主张小幅更新。最终经过 TC39 的会议，决定将一部分不那么激进的改动保留发布为 ECMAScript 3.1，而ES4的内容，则延续到了后来的ECMAScript5和6版本中 2009年12月，ECMAScript 5 发布。 2011年6月，ECMAScript 5.1 发布。 2015年6月，ECMAScript 6，也就是 ECMAScript 2015 发布了。 并且从 ECMAScript 6 开始，开始采用年号来做版本。即 ECMAScript 2015，就是ECMAScript6。 ES5和6的一些新特性我们这里只把一些常用的进行学习，更详细的大家参考：阮一峰的ES6教程 let 和 const 命令 var 之前，js定义变量只有一个关键字：var var有一个问题，就是定义的变量有时会莫名奇妙的成为全局变量。 例如这样的一段代码： 1234for(var i = 0; i &lt; 5; i++)&#123; console.log(i);&#125;console.log("循环外：" + i) 你猜下打印的结果是什么？ let let所声明的变量，只在let命令所在的代码块内有效。 我们把刚才的var改成let试试： 1234for(let i = 0; i &lt; 5; i++)&#123; console.log(i);&#125;console.log("循环外：" + i) 结果： const const声明的变量是常量，不能被修改 字符串扩展 新的API ES6为字符串扩展了几个新的API： includes()：返回布尔值，表示是否找到了参数字符串。 startsWith()：返回布尔值，表示参数字符串是否在原字符串的头部。 endsWith()：返回布尔值，表示参数字符串是否在原字符串的尾部。 实验一下： 字符串模板 ES6中提供了`来作为字符串模板标记。我们可以这么玩： 在两个`之间的部分都会被作为字符串的值，不管你任意换行，甚至加入js脚本 键盘是的1的左侧，tab的上侧，esc的正下方 解构表达式 数组解构 比如有一个数组： 1let arr = [1,2,3] 我想获取其中的值，只能通过角标。ES6可以这样： 123const [x,y,z] = arr;// x，y，z将与arr中的每个位置对应来取值// 然后打印console.log(x,y,z); 结果： 对象解构 例如有个person对象： 12345const person = &#123; name:"jack", age:21, language: ['java','js','css']&#125; 我们可以这么做： 123456// 解构表达式获取值const &#123;name,age,language&#125; = person;// 打印console.log(name);console.log(age);console.log(language); 结果： 如过想要用其它变量接收，需要额外指定别名： {name:n}：name是person中的属性名，冒号后面的n是解构后要赋值给的变量。 函数优化 函数参数默认值 在ES6以前，我们无法给一个函数参数设置默认值，只能采用变通写法： 1234567function add(a , b) &#123; // 判断b是否为空，为空就给默认值1 b = b || 1; return a + b;&#125;// 传一个参数console.log(add(10)); 现在可以这么写： 12345function add(a , b = 1) &#123; return a + b;&#125;// 传一个参数console.log(add(10)); 箭头函数 ES6中定义函数的简写方式： 一个参数时： 12345var print = function (obj) &#123; console.log(obj);&#125;// 简写为：var print2 = obj =&gt; console.log(obj); 多个参数： 123456// 两个参数的情况：var sum = function (a , b) &#123; return a + b;&#125;// 简写为：var sum2 = (a,b) =&gt; a+b; 代码不止一行，可以用{}括起来 123var sum3 = (a,b) =&gt; &#123; return a + b;&#125; 对象的函数属性简写 比如一个Person对象，里面有eat方法： 12345678910111213let person = &#123; name: "jack", // 以前： eat: function (food) &#123; console.log(this.name + "在吃" + food); &#125;, // 箭头函数版： eat2: food =&gt; console.log(person.name + "在吃" + food),// 这里拿不到this // 简写版： eat3(food)&#123; console.log(this.name + "在吃" + food); &#125;&#125; 箭头函数结合解构表达式 比如有一个函数： 123456789const person = &#123; name:"jack", age:21, language: ['java','js','css']&#125;function hello(person) &#123; console.log("hello," + person.name)&#125; 如果用箭头函数和解构表达式 1var hi = (&#123;name&#125;) =&gt; console.log("hello," + name); map和reducemap()`：接收一个函数，将原数组中的所有元素用这个函数处理后放入新数组返回。 举例：有一个字符串数组，我们希望转为int数组 123456let arr = ['1','20','-5','3'];console.log(arr)arr = arr.map(s =&gt; parseInt(s));console.log(arr) reduce reduce()：接收一个函数（必须）和一个初始值（可选），该函数接收两个参数： 第一个参数是上一次reduce处理的结果 第二个参数是数组中要处理的下一个元素 reduce()会从左到右依次把数组中的元素用reduce处理，并把处理的结果作为下次reduce的第一个参数。如果是第一次，会把前两个元素作为计算参数，或者把用户指定的初始值作为起始参数 举例： 1const arr = [1,20,-5,3] 没有初始值： 指定初始值： promise所谓Promise，简单说就是一个容器，里面保存着某个未来才会结束的事件（通常是一个异步操作）的结果。从语法上说，Promise 是一个对象，从它可以获取异步操作的消息。Promise 提供统一的 API，各种异步操作都可以用同样的方法进行处理。 感觉跟java的Future类很像啊，有木有！ 我们可以通过Promise的构造函数来创建Promise对象，并在内部封装一个异步执行的结果。 语法： 123456789const promise = new Promise(function(resolve, reject) &#123; // ... 执行异步操作 if (/* 异步操作成功 */)&#123; resolve(value);// 调用resolve，代表Promise将返回成功的结果 &#125; else &#123; reject(error);// 调用reject，代表Promise会返回失败结果 &#125;&#125;); 这样，在promise中就封装了一段异步执行的结果。 如果我们想要等待异步执行完成，做一些事情，我们可以通过promise的then方法来实现,语法： 123promise.then(function(value)&#123; // 异步执行成功后的回调&#125;); 如果想要处理promise异步执行失败的事件，还可以跟上catch： 12345promise.then(function(value)&#123; // 异步执行成功后的回调&#125;).catch(function(error)&#123; // 异步执行失败后的回调&#125;) 示例： 12345678910111213141516171819const p = new Promise(function (resolve, reject) &#123; // 这里我们用定时任务模拟异步 setTimeout(() =&gt; &#123; const num = Math.random(); // 随机返回成功或失败 if (num &lt; 0.5) &#123; resolve(&quot;成功！num:&quot; + num) &#125; else &#123; reject(&quot;出错了！num:&quot; + num) &#125; &#125;, 300)&#125;)// 调用promisep.then(function (msg) &#123; console.log(msg);&#125;).catch(function (msg) &#123; console.log(msg);&#125;) 结果： set和map（了解）ES6提供了Set和Map的数据结构。 Set，本质与数组类似。不同在于Set中只能保存不同元素，如果元素相同会被忽略。跟java很像吧。 构造函数： 12345// Set构造函数可以接收一个数组或空let set = new Set();set.add(1);// [1]// 接收数组let set2 = new Set([2,3,4,5,5]);// 得到[2,3,4,5] 普通方法： 123456789set.add(1);// 添加set.clear();// 清空set.delete(2);// 删除指定元素set.has(2); // 判断是否存在set.keys();// 返回所有keyset.values();// 返回所有值set.entries();// 返回键值对集合// 因为set没有键值对，所有其keys、values、entries方法返回值一样的。set.size; // 元素个数。是属性，不是方法。 map，本质是与Object类似的结构。不同在于，Object强制规定key只能是字符串。而Map结构的key可以是任意对象。即： object是 &lt;string,object&gt;集合 map是&lt;object,object&gt;集合 构造函数： 12345678910111213// map接收一个数组，数组中的元素是键值对数组const map = new Map([ ['key1','value1'], ['key2','value2'],])// 或者接收一个setconst set = new Set([ ['key1','value1'], ['key2','value2'],])const map2 = new Map(set)// 或者其它mapconst map3 = new Map(map); 方法： 模块化什么是模块化模块化就是把代码进行拆分，方便重复利用。类似java中的导包：要使用一个包，必须先导包。 而JS中没有包的概念，换来的是 模块。 模块功能主要由两个命令构成：export和import。 export命令用于规定模块的对外接口， import命令用于导入其他模块提供的功能。 export比如我定义一个js文件:hello.js，里面有一个对象： 12345const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125; 我可以使用export将这个对象导出： 123456const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125;export util; 当然，也可以简写为： 12345export const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125; export不仅可以导出对象，一切JS变量都可以导出。比如：基本类型变量、函数、数组、对象。 当要导出多个值时，还可以简写。比如我有一个文件：user.js： 123var name = "jack"var age = 21export &#123;name,age&#125; 省略名称 上面的导出代码中，都明确指定了导出的变量名，这样其它人在导入使用时就必须准确写出变量名，否则就会出错。 因此js提供了default关键字，可以对导出的变量名进行省略 例如： 123456// 无需声明对象的名字export default &#123; sum(a,b)&#123; return a + b; &#125;&#125; 这样，当使用者导入时，可以任意起名字 import使用export命令定义了模块的对外接口以后，其他 JS 文件就可以通过import命令加载这个模块。 例如我要使用上面导出的util： 1234// 导入utilimport util from 'hello.js'// 调用util中的属性util.sum(1,2) 要批量导入前面导出的name和age： 123import &#123;name, age&#125; from 'user.js'console.log(name + " , 今年"+ age +"岁了") 但是上面的代码暂时无法测试，因为浏览器目前还不支持ES6 的导入和导出功能。除非借助于工具，把ES6 的语法进行编译降级到ES5，比如Babel-cli工具 我们暂时不做测试，大家了解即可。 对象扩展ES6给Object拓展了许多新的方法，如： keys(obj)：获取对象的所有key形成的数组 values(obj)：获取对象的所有value形成的数组 entries(obj)：获取对象的所有key和value形成的二维数组。格式：[[k1,v1],[k2,v2],...] assian(dest, …src) ：将多个src对象的值 拷贝到 dest中（浅拷贝）。 数组扩展ES6给数组新增了许多方法： find(callback)：把数组中的元素逐个传递给函数callback执行，如果返回true，则返回该元素 findIndex(callback)：与find类似，不过返回的是品牌到的元素的索引 includes（callback）：与find类似，如果匹配到元素，则返回true，代表找到了。]]></content>
      <categories>
        <category>ES6</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置browser-sync浏览器同步测试工具]]></title>
    <url>%2F2019%2F01%2F23%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E5%90%8C%E6%AD%A5%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介 Time-saving synchronised browser testing. It’s wicked-fast and totally free. 官方网站 文档 起步 安装依赖12# 也可以 npm i -D browser-syncnpm install --save-dev browser-sync 配置package.json中script123456&#123; "scripts": &#123; "dev": "browser-sync start --server --files \"*.html, css/*.css, js/*.js\"", "start": "npm run dev" &#125;,&#125; 启动开发服务12# 或者 npm startnpm run dev]]></content>
      <categories>
        <category>browser-sync</category>
      </categories>
      <tags>
        <tag>browser-sync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba路由网关全局过滤功能]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%E7%9A%84%E5%85%A8%E5%B1%80%E8%BF%87%E6%BB%A4%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[概述全局过滤器作用于所有的路由，不需要单独配置，我们可以用它来实现很多统一化处理的业务需求，比如权限认证，IP 访问限制等等。 注意：截止博客发表时间 2019 年 01 月 10 日，Spring Cloud Gateway 正式版为 2.0.2 其文档并不完善，并且有些地方还要重新设计，这里仅提供一个基本的案例 详见：Spring Cloud Gateway Documentation 生命周期 Spring Cloud Gateway 基于 Project Reactor 和 WebFlux，采用响应式编程风格，打开它的 Filter 的接口 GlobalFilter 你会发现它只有一个方法 filter 创建全局过滤器实现 GlobalFilter, Ordered 接口并在类上增加 @Component 注解就可以使用过滤功能了，非常简单方便 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package club.codeopen.spring.cloud.gateway.filters;/** * @author by cheng * @Classname AuthFilter * @Description * @Date 2019/1/13 11:36 */import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.collect.Maps;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.http.HttpStatus;import org.springframework.http.server.reactive.ServerHttpResponse;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.Map;/** * 鉴权过滤器 */@Componentpublic class AuthFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst("token"); if (token == null || token.isEmpty()) &#123; ServerHttpResponse response = exchange.getResponse(); // 封装错误信息 Map&lt;String, Object&gt; responseData = Maps.newHashMap(); responseData.put("code", 401); responseData.put("message", "非法请求"); responseData.put("cause", "Token is empty"); try &#123; // 将信息转换为 JSON ObjectMapper objectMapper = new ObjectMapper(); byte[] data = objectMapper.writeValueAsBytes(responseData); // 输出错误信息到页面 DataBuffer buffer = response.bufferFactory().wrap(data); response.setStatusCode(HttpStatus.UNAUTHORIZED); response.getHeaders().add("Content-Type", "application/json;charset=UTF-8"); return response.writeWith(Mono.just(buffer)); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; &#125; return chain.filter(exchange); &#125; /** * 设置过滤器的执行顺序 * @return */ @Override public int getOrder() &#123; return Ordered.LOWEST_PRECEDENCE; &#125;&#125; 测试过滤器浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 网页显示 浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name?token=123456 网页显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 附：Spring Cloud Gateway BenchmarkSpring 官方人员提供的网关基准测试报告 GitHub Proxy Avg Latency Avg Req/Sec/Thread gateway 6.61ms 3.24k linkered 7.62ms 2.82k zuul 12.56ms 2.09k none 2.09ms 11.77k 说明 这里的 Zuul 为 1.x 版本，是一个基于阻塞 IO 的 API Gateway Zuul 已经发布了 Zuul 2.x，基于 Netty，非阻塞的，支持长连接，但 Spring Cloud 暂时还没有整合计划 Linkerd 基于 Scala 实现的、目前市面上仅有的生产级别的 Service Mesh（其他诸如 Istio、Conduit 暂时还不能用于生产）。]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba路由网关]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[什么是 Spring Cloud GatewaySpring Cloud Gateway 是 Spring 官方基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，Spring Cloud Gateway 旨在为微服务架构提供一种简单而有效的统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系中的网关，目标是替代 Netflix ZUUL，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 Spring Cloud Gateway 功能特征 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 Spring Cloud Gateway 工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑 POM1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-gateway&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.gateway.GatewayApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: application: # 应用名称 name: spring-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 127.0.0.1:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: localhost:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-gateway/2.0.x/single/spring-cloud-gateway.html#gateway-route-filters） - id: NACOS-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://nacos-consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: NACOS-CONSUMER-FEIGN uri: lb://nacos-consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 目前无效feign: sentinel: enabled: true# 目前无效management: endpoints: web: exposure: include: "*"# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 注意：请仔细阅读注释 测试访问依次运行 Nacos 服务、NacosProviderApplication、NacosConsumerApplication、NacosConsumerFeignApplication、GatewayApplication 打开浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 浏览器显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 1 打开浏览器访问：http://localhost:9000/nacos-consumer-feign/echo/hi 浏览器显示 1Hello Nacos Discovery Hi Feign i am from port 8082 1 注意：请求方式是 http://路由网关IP:路由网关Port/服务名/** 至此说明 Spring Cloud Gateway 的路由功能配置成功]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloud alibaba统一的依赖管理]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%BB%9F%E4%B8%80%E7%9A%84%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring Cloud Alibaba 项目都是基于 Spring Cloud，而 Spring Cloud 项目又是基于 Spring Boot 进行开发，并且都是使用 Maven 做项目管理工具。在实际开发中，我们一般都会创建一个依赖管理项目作为 Maven 的 Parent 项目使用，这样做可以极大的方便我们对 Jar 包版本的统一管理。 创建依赖管理项目创建一个工程名为 spring-cloud-alibaba-demo-dependencies 的项目，pom.xml 配置文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-dependencies&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- Java Document Generate --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- YUI Compressor (CSS/JS压缩) --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compress&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;jswarn&gt;false&lt;/jswarn&gt; &lt;nosuffix&gt;true&lt;/nosuffix&gt; &lt;linebreakpos&gt;30000&lt;/linebreakpos&gt; &lt;force&gt;true&lt;/force&gt; &lt;includes&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.min.js&lt;/exclude&gt; &lt;exclude&gt;**/*.min.css&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-alibaba-dependencies：在 properties 配置中预定义了版本号为 0.2.1.RELEASE ，表示我们的 Spring Cloud Alibaba 对应的是 Spring Cloud Finchley 版本 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 依赖版本说明项目的最新版本是 0.2.1.RELEASE 和 0.1.1.RELEASE，版本 0.2.1.RELEASE 对应的是 Spring Cloud Finchley 版本，版本 0.1.1.RELEASE 对应的是 Spring Cloud Edgware 版本]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba熔断器仪表盘]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%86%94%E6%96%AD%E5%99%A8%E4%BB%AA%E8%A1%A8%E7%9B%98%2F</url>
    <content type="text"><![CDATA[Sentinel 控制台Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 下载并打包 可以从最新版本的源码自行构建 Sentinel 控制台 12345# 下载源码git clone https://github.com/alibaba/Sentinel.git# 编译打包mvn clean package 注：下载依赖时间较长，请耐心等待… 也可以从 release 页面 下载最新版本的控制台 jar 包 启动控制台Sentinel 控制台是一个标准的 SpringBoot 应用，以 SpringBoot 的方式运行 jar 包即可。 12345# 自行构建Sentinel控制台，控制台jar包位置cd sentinel-dashboard\targe # 运行jar包java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 如若 8080 端口冲突，可使用 -Dserver.port=新端口 进行设置。 访问服务打开浏览器访问：http://localhost:8080/#/dashboard/home 测试 Sentinel使用之前的 Feign 客户端，application.yml 完整配置如下： 123456789101112131415161718192021222324spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: port: 8720 dashboard: localhost:8080server: port: 9092feign: sentinel: enabled: truemanagement: endpoints: web: exposure: include: "*" 注：由于 8719 端口已被 sentinel-dashboard 占用，故这里修改端口号为 8720；不修改也能注册，会自动帮你在端口号上 + 1； 打开浏览器访问：http://localhost:8080/#/dashboard/home 此时会多一个名为 nacos-consumer-feign 的服务]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba熔断器]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%86%94%E6%96%AD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用，在 Spring Cloud 中可以用 RestTemplate + LoadBalanceClient 和 Feign 来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 阿里巴巴开源了 Sentinel 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图： 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值。 什么是 Sentinel随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性Sentinel 的特征 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的 双十一大促流量 的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等 Feign 中使用 Sentinel如果要在您的项目中引入 Sentinel，使用 group ID 为 org.springframework.cloud 和 artifact ID 为 spring-cloud-starter-alibaba-sentinel 的 starter。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; Sentinel 适配了 Feign 组件。但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: sentinel: enabled: true 在 Service 中增加 fallback 指定类12345678910111213141516171819package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.fallback.EchoServiceFallback;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @author by cheng * @Classname EchoService * @Description * @Date 2019/1/13 9:52 */@FeignClient(value = "nacos-provider", fallback = EchoServiceFallback.class)public interface EchoService &#123; @GetMapping(value = "/echo/&#123;message&#125;") String echo(@PathVariable("message") String message);&#125; 创建熔断器类并实现对应的 Feign 接口123456789101112131415161718package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.fallback;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.stereotype.Component;/** * @author by cheng * @Classname EchoServiceFallback * @Description * @Date 2019/1/13 10:08 */@Componentpublic class EchoServiceFallback implements EchoService &#123; @Override public String echo(String message) &#123; return "echo fallback"; &#125;&#125; 测试熔断器此时我们关闭服务提供者，再次请求 http://localhost:9092/echo/hi 浏览器会显示： 1echo fallback]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务消费者（Feign）]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%88Feign%EF%BC%89%2F</url>
    <content type="text"><![CDATA[概述Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-consumer-feign 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-consumer-feign&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-consumer-feign&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.NacosConsumerFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-openfeign 依赖 application.yml12345678910111213141516spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9092management: endpoints: web: exposure: include: "*" Application通过 @EnableFeignClients 注解开启 Feign 功能 123456789101112131415161718192021package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;/** * @author by cheng * @Classname NacosConsumerFeignApplication * @Description * @Date 2019/1/13 9:51 */@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class NacosConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerFeignApplication.class, args); &#125;&#125; 创建 Feign 接口通过 @FeignClient(&quot;服务名&quot;) 注解来指定调用哪个服务。代码如下： 123456789101112131415161718package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @author by cheng * @Classname EchoService * @Description * @Date 2019/1/13 9:52 */@FeignClient(value = "nacos-provider")public interface EchoService &#123; @GetMapping(value = "/echo/&#123;message&#125;") String echo(@PathVariable("message") String message);&#125; Controller123456789101112131415161718192021222324package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.controller;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosConsumerFeignController * @Description * @Date 2019/1/13 9:52 */@RestControllerpublic class NacosConsumerFeignController &#123; @Autowired private EchoService echoService; @GetMapping(value = "/echo/hi") public String echo() &#123; return echoService.echo("Hi Feign"); &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer-feign 的服务 这时打开 http://localhost:9092/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery Hi Feign 测试负载均衡 启动多个 consumer-provider 实例，效果图如下： 修改 consumer-provider 项目中的 Controller 代码，用于确定负载均衡生效 12345678910111213141516171819202122232425262728293031323334package club.codeopen.spring.cloud.alibaba.nacos.provider;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosProviderApplication * @Description * @Date 2019/1/13 9:24 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class, args); &#125; @Value("$&#123;server.port&#125;") private String port; @RestController public class EchoController &#123; @GetMapping(value = "/echo/&#123;message&#125;") public String echo(@PathVariable String message) &#123; return "Hello Nacos Discovery " + message + " i am from port " + port; &#125; &#125;&#125; 在浏览器上多次访问 http://localhost:9092/echo/hi ，浏览器交替显示： 12Hello Nacos Discovery Hi Feign i am from port 8081Hello Nacos Discovery Hi Feign i am from port 8082]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Feign</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务消费者]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[概述服务消费者的创建与服务提供者大同小异，这里采用最原始的一种方式，即显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-consumer 的服务消费者项目，pom.xml 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-consumer&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.consumer.NacosConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml12345678910111213141516spring: application: name: nacos-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9091management: endpoints: web: exposure: include: "*" Application12345678910111213141516171819package club.codeopen.spring.cloud.alibaba.nacos.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * @author by cheng * @Classname NacosConsumerApplication * @Description * @Date 2019/1/13 9:38 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerApplication.class, args); &#125;&#125; Configuration创建一个名为 NacosConsumerConfiguration 的 Java 配置类，主要作用是为了注入 RestTemplate 1234567891011121314151617181920package club.codeopen.spring.cloud.alibaba.nacos.consumer.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @author by cheng * @Classname NacosConsumerConfiguration * @Description * @Date 2019/1/13 9:39 */@Configurationpublic class NacosConsumerConfiguration &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; Controller创建一个名为 NacosConsumerController 测试用的 Controller 123456789101112131415161718192021222324252627282930313233343536package club.codeopen.spring.cloud.alibaba.nacos.consumer.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;/** * @author by cheng * @Classname NacosConsumerController * @Description * @Date 2019/1/13 9:39 */@RestControllerpublic class NacosConsumerController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @Value("$&#123;spring.application.name&#125;") private String appName; @GetMapping(value = "/echo/app/name") public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 ServiceInstance serviceInstance = loadBalancerClient.choose("nacos-provider"); String url = String.format("http://%s:%s/echo/%s", serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer 的服务 这时打开 http://localhost:9091/echo/app/name ，你会在浏览器上看到： 1Hello Nacos Discovery nacos-consumer 服务的端点检查通过浏览器访问 http://localhost:9091/actuator/nacos-discovery 你会在浏览器上看到：]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务注册与发现之Nacos]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0%E4%B9%8BNacos%2F</url>
    <content type="text"><![CDATA[什么是 NacosNacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 基本架构及概念 服务 (Service)服务是指一个或一组软件功能（例如特定信息的检索或一组操作的执行），其目的是不同的客户端可以为不同的目的重用（例如通过跨进程的网络调用）。Nacos 支持主流的服务生态，如 Kubernetes Service、gRPC|Dubbo RPC Service 或者 Spring Cloud RESTful Service 服务注册中心 (Service Registry)服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求 服务元数据 (Service Metadata)服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据 服务提供方 (Service Provider)是指提供可复用和可调用服务的应用方 服务消费方 (Service Consumer)是指会发起对某个服务调用的应用方 配置 (Configuration)在系统开发过程中通常会将一些需要变更的参数、变量等从代码中分离出来独立管理，以独立的配置文件的形式存在。目的是让静态的系统工件或者交付物（如 WAR，JAR 包等）更好地和实际的物理运行环境进行适配。配置管理一般包含在系统部署的过程中，由系统管理员或者运维人员完成这个步骤。配置变更是调整系统运行时的行为的有效手段之一 配置管理 (Configuration Management)在数据中心中，系统中所有配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等所有与配置相关的活动统称为配置管理 名字服务 (Naming Service)提供分布式系统中所有对象(Object)、实体(Entity)的“名字”到关联的元数据之间的映射管理服务，例如 ServiceName -&gt; Endpoints Info, Distributed Lock Name -&gt; Lock Owner/Status Info, DNS Domain Name -&gt; IP List, 服务发现和 DNS 就是名字服务的2大场景 配置服务 (Configuration Service)在服务或者应用运行过程中，提供动态配置或者元数据以及配置管理的服务提供者 下载安装准备环境Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行 Nacos，还需要为此配置 Maven 环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+ Maven 3.2.x+ 下载并安装123456# 下载源码git clone https://github.com/alibaba/nacos.git# 安装到本地仓库cd nacos/mvn -Prelease-nacos clean install -U 注：下载依赖时间较长，请耐心等待… 启动服务1234567cd distribution/target/nacos-server-0.7.0/nacos/bin# Linux./startup.sh -m standalone# Windowsstartup.cmd 访问服务打开浏览器访问：http://localhost:8848/nacos/index.html]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务提供者]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E8%80%85%2F</url>
    <content type="text"><![CDATA[概述通过一个简单的示例来感受一下如何将服务注册到 Nacos，其实和 Eureka 没有太大差别 POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-provider 的服务提供者项目，pom.xml 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml12345678910111213141516spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 8081management: endpoints: web: exposure: include: "*" Application通过 @EnableDiscoveryClient 注解表明是一个 Nacos 客户端，该注解是 Spring Cloud 提供的原生注解 123456789101112131415161718192021222324252627282930package club.codeopen.spring.cloud.alibaba.nacos.provider;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosProviderApplication * @Description * @Date 2019/1/13 9:24 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class, args); &#125; @RestController public class EchoController &#123; @GetMapping(value = "/echo/&#123;message&#125;") public String echo(@PathVariable String message) &#123; return "Hello Nacos Discovery " + message; &#125; &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现一个服务已经注册在服务中了，服务名为 nacos-provider 这时打开 http://localhost:8081/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery hi 服务的端点检查spring-cloud-starter-alibaba-nacos-discovery 在实现的时候提供了一个 EndPoint, EndPoint 的访问地址为 http://ip:port/actuator/nacos-discovery。 EndPoint 的信息主要提供了两类: 121、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 12 通过浏览器访问 http://localhost:8081/actuator/nacos-discovery 你会在浏览器上看到： 附：Nacos Starter 更多配置项信息 配置项 Key 默认值 说明 服务端地址 spring.cloud.nacos.discovery.server-addr 无 Nacos Server 启动监听的ip地址和端口 服务名 spring.cloud.nacos.discovery.service ${spring.application.name} 给当前的服务命名 权重 spring.cloud.nacos.discovery.weight 1 取值范围 1 到 100，数值越大，权重越大 网卡名 spring.cloud.nacos.discovery.network-interface 无 当IP未配置时，注册的IP为此网卡所对应的IP地址，如果此项也未配置，则默认取第一块网卡的地址 注册的IP地址 spring.cloud.nacos.discovery.ip 无 优先级最高 注册的端口 spring.cloud.nacos.discovery.port -1 默认情况下不用配置，会自动探测 命名空间 spring.cloud.nacos.discovery.namespace 无 常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 AccessKey spring.cloud.nacos.discovery.access-key 无 当要上阿里云时，阿里云上面的一个云账号名 SecretKey spring.cloud.nacos.discovery.secret-key 无 当要上阿里云时，阿里云上面的一个云账号密码 Metadata spring.cloud.nacos.discovery.metadata 无 使用 Map 格式配置，用户可以根据自己的需要自定义一些和服务相关的元数据信息 日志文件名 spring.cloud.nacos.discovery.log-name 无 接入点 spring.cloud.nacos.discovery.enpoint UTF-8 地域的某个服务的入口域名，通过此域名可以动态地拿到服务端地址 是否集成 Ribbon ribbon.nacos.enabled true]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%2F</url>
    <content type="text"><![CDATA[Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。 参考文档 请查看 WIKI 主要功能 服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 更多功能请参考 Roadmap。 组件Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 更多组件请参考 Roadmap。 如何构建 master 分支对应的是 Spring Cloud Finchley，最低支持 JDK 1.8。 1.x 分支对应的是 Spring Cloud Edgware，最低支持 JDK 1.7。 Spring Cloud 使用 Maven 来构建，最快的使用方式是将本项目clone到本地，然后执行以下命令： 1./mvnw install 执行完毕后，项目将被安装到本地 Maven 仓库。 如何使用如何引入依赖项目的最新版本是 0.2.1.RELEASE 和 0.1.1.RELEASE，版本 0.2.1.RELEASE 对应的是 Spring Cloud Finchley 版本，版本 0.1.1.RELEASE 对应的是 Spring Cloud Edgware 版本。 如果需要使用已发布的版本，在 dependencyManagement 中添加如下配置。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 然后再 dependencies 中添加自己所需使用的依赖即可使用。 如果您想体验最新的 BUILD-SNAPSHOT 的新功能，则可以将版本换成最新的版本，但是需要在 pom.xml 中配置 Spring BUILDSNAPSHOT 仓库，注意: SNAPSHOT 版本随时可能更新 12345678910&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot Repository&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 演示 Demo为了演示如何使用，Spring Cloud Alibaba 项目包含了一个子模块spring-cloud-alibaba-examples。此模块中提供了演示用的 example ，您可以阅读对应的 example 工程下的 readme 文档，根据里面的步骤来体验。 Example 列表： Sentinel Example Nacos Config Example Nacos Discovery Example RocketMQ Example Alibaba Cloud OSS Example Alibaba Cloud ANS Example Alibaba Cloud ACM Example Alibaba Cloud SchedulerX Example 版本管理规范项目的版本号格式为 x.x.x 的形式，其中 x 的数值类型为数字，从0开始取值，且不限于 0~9 这个范围。项目处于孵化器阶段时，第一位版本号固定使用0，即版本号为 0.x.x 的格式。 由于 Spring Boot 1 和 Spring Boot 2 在 Actuator 模块的接口和注解有很大的变更，且 spring-cloud-commons 从 1.x.x 版本升级到 2.0.0 版本也有较大的变更，因此我们使用了两个不同分支来分别支持 Spring Boot 1 和 Spring Boot 2: 0.1.x 版本适用于 Spring Boot 1 0.2.x 版本适用于 Spring Boot 2 项目孵化阶段，项目版本升级机制如下： 功能改动的升级会增加第三位版本号的数值，例如 0.1.0 的下一个版本为0.1.1。]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba 服务配置]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%20%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nacos Config 服务端初始化分布式配置中心在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。 Nacos ConfigNacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，您可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Spring Cloud Alibaba Nacos Config 是 Spring Cloud Config Server 和 Client 的替代方案，客户端和服务器上的概念与 Spring Environment 和 PropertySource 有着一致的抽象，在特殊的 bootstrap 阶段，配置被加载到 Spring 环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容 创建配置文件需要在 Nacos Server 中创建配置文件，我们依然采用 YAML 的方式部署配置文件，操作流程如下： 浏览器打开 http://localhost:8848/nacos ，访问 Nacos Server 新建配置文件，此处我们以之前创建的 服务提供者 项目为例 注意：Data ID 的默认扩展名为 .properties ，希望使用 YAML 配置，此处必须指明是 .yaml 发布成功后在 “配置列表” 一栏即可看到刚才创建的配置项 Nacos Config 客户端的使用POM此处我们以之前创建的 服务提供者 项目为例 在 pom.xml 中增加 org.springframework.cloud:spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 完整的 pom.xml 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; bootstrap.properties创建名为 bootstrap.properties 的配置文件并删除之前创建的 application.yml 配置文件，由于已经在服务端配置，此处不再赘述 123456# 这里的应用名对应 Nacos Config 中的 Data ID，实际应用名称以配置中心的配置为准spring.application.name=nacos-provider-config# 指定查找名为 nacos-provider-config.yaml 的配置文件spring.cloud.nacos.config.file-extension=yaml# Nacos Server 的地址spring.cloud.nacos.config.server-addr=127.0.0.1:8848 注意：在之前的 Spring Cloud Netflix 课程中有提到过 Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 启动应用程序启动应用后我们可以通过日志看到，已经成功加载到了配置文件 配置的动态更新Nacos Config 也支持配置的动态更新，操作流程如下： 修改服务端配置，增加一个 user.name 的属性 修改 Controller ，增加一个请求方法，测试配置更新效果 123456789// 注入配置文件上下文@Autowiredprivate ConfigurableApplicationContext applicationContext;// 从上下文中读取配置@GetMapping(value = "/hi")public String sayHi() &#123; return "Hello " + applicationContext.getEnvironment().getProperty("user.name");&#125; 通过浏览器访问该接口，浏览器显示 1Hello cheng 修改服务端配置 此时观察控制台日志，你会发现我们已经成功刷新了配置 刷新浏览器，浏览器显示 1Hello chengChange 注意：你可以使用 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新 Nacos Config 多环境的配置Spring Boot Profile我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar spring-cloud-alibaba-demo-nacos-provider-1.0.0-SNAPSHOT.jar --spring.profiles.active=prod Nacos Config Profilespring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataid 为 ${spring.application.name}.${file-extension:properties} 为前缀的基础配置，还加载了 dataid 为 ${spring.application.name}-${profile}.${file-extension:properties} 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过 Spring 提供的 ${spring.profiles.active} 这个配置项来配置。 此处我们以之前创建的 服务提供者 项目为例 在 Nacos Server 中增加配置增加一个名为 nacos-provider-config-prod.yaml 的配置 注意：此时，我将配置文件中的端口由 8081 -&gt; 8082 在项目中增加配置增加一个名为 bootstrap-prod.properties 的配置文件，内容如下： 1234spring.profiles.active=prodspring.application.name=nacos-provider-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848 主要增加了 spring.profiles.active=prod 配置，用于指定访问 Nacos Server 中的 nacos-provider-config-prod.yaml 配置 启动应用程序此时我们有两个配置文件，分别为 bootstrap.properties 和 bootstrap-prod.properties ，我们需要指定启动时加载哪一个配置文件，操作流程如下： Run -&gt; Edit Configurations.. 设置需要激活的配置 观察日志，判断是否成功加载配置]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自定义Banner]]></title>
    <url>%2F2019%2F01%2F09%2FSpringBoot%E8%87%AA%E5%AE%9A%E4%B9%89Banner(%E4%BD%9B%E7%A5%96%E4%BF%9D%E4%BD%91)%2F</url>
    <content type="text"><![CDATA[在 Spring Boot 启动的时候会有一个默认的启动图案 1234567. ____ _ __ _ _ /\\ / ___&apos;_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | &apos;_ | &apos;_| | &apos;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.5.8.RELEASE) 我们在 src/main/resources 目录下新建一个 banner.txt 通过 http://patorjk.com/software/taag 网站生成字符串，将网站生成的字符复制到 banner.txt 中 再次运行这个程序 1234567891011121314151617181920212223$&#123;AnsiColor.BRIGHT_RED&#125;////////////////////////////////////////////////////////////////////// _ooOoo_ //// o8888888o //// 88&quot; . &quot;88 //// (| ^_^ |) //// O\ = /O //// ____/`---&apos;\____ //// .&apos; \\| |// `. //// / \\||| : |||// \ //// / _||||| -:- |||||- \ //// | | \\\ - /// | | //// | \_| &apos;&apos;\---/&apos;&apos; | | //// \ .-\__ `-` ___/-. / //// ___`. .&apos; /--.--\ `. . ___ //// .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. //// | | : `- \`.;`\ _ /`;.`/ - ` : | | //// \ \ `-. \_ __\ /__ _/ .-` / / //// ========`-.____`-.___\_____/___.-`____.-&apos;======== //// `=---=&apos; //// ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ //// 佛祖保佑 永不宕机 永无BUG ////////////////////////////////////////////////////////////////////// 常用属性设置： ${AnsiColor.BRIGHT_RED}：设置控制台中输出内容的颜色 ${application.version}：用来获取 MANIFEST.MF 文件中的版本号 ${application.formatted-version}：格式化后的 ${application.version} 版本信息 ${spring-boot.version}：Spring Boot 的版本号 ${spring-boot.formatted-version}：格式化后的 ${spring-boot.version} 版本信息]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Banner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合tk.mybatis]]></title>
    <url>%2F2019%2F01%2F09%2FSpringBoot%E6%95%B4%E5%90%88tk.mybatis%2F</url>
    <content type="text"><![CDATA[tk.mybatis 简介tk.mybatis 是在 MyBatis 框架的基础上提供了很多工具，让开发更加高效 引入依赖在 pom.xml 文件中引入 mapper-spring-boot-starter 依赖，该依赖会自动引入 MyBaits 相关依赖 12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 配置 application.yml配置 MyBatis 123mybatis: type-aliases-package: 实体类的存放路径，如：com.funtl.hello.spring.boot.entity mapper-locations: classpath:mapper/*.xml 创建一个通用的父级接口主要作用是让 DAO 层的接口继承该接口，以达到使用 tk.mybatis 的目的 1234567891011package tk.mybatis;import tk.mybatis.mapper.common.Mapper;import tk.mybatis.mapper.common.MySqlMapper;/** * 自己的 Mapper * 特别注意，该接口不能被扫描到，否则会出错 * 不能放在主启动类所在包及其子包下 */public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; &#123;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>tk.mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Druid]]></title>
    <url>%2F2019%2F01%2F09%2FSpringBoot%E6%95%B4%E5%90%88Druid%2F</url>
    <content type="text"><![CDATA[引入依赖在 pom.xml 文件中引入 druid-spring-boot-starter 依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 引入数据库连接依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 配置 application.yml在 application.yml 中配置数据库连接 1234567891011spring: datasource: druid: url: jdbc:mysql://ip:port/dbname?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true driver-class-name: com.mysql.jdbc.Driver]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云短信服务工具类]]></title>
    <url>%2F2019%2F01%2F09%2F%E9%98%BF%E9%87%8C%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[短信服务（Short Message Service）是阿里云为用户提供的一种通信服务的能力。支持国内和国际快速发送验证码、短信通知和推广短信，服务范围覆盖全球200多个国家和地区。国内短信支持三网合一专属通道，与工信部携号转网平台实时互联。电信级运维保障，实时监控自动切换，到达率高达99%。完美支撑双11期间20亿短信发送，6亿用户触达。 工具内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import com.aliyuncs.DefaultAcsClient;import com.aliyuncs.IAcsClient;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsRequest;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsResponse;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsRequest;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsResponse;import com.aliyuncs.exceptions.ClientException;import com.aliyuncs.profile.DefaultProfile;import com.aliyuncs.profile.IClientProfile;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.env.Environment;import org.springframework.stereotype.Component;import java.text.SimpleDateFormat;import java.util.Date;/** * 短信工具类 * @author Administrator * */@Componentpublic class SmsUtil &#123; //产品名称:云通信短信API产品,开发者无需替换 static final String product = "Dysmsapi"; //产品域名,开发者无需替换 static final String domain = "dysmsapi.aliyuncs.com"; @Autowired private Environment env; // TODO 此处需要替换成开发者自己的AK(在阿里云访问控制台寻找) /** * 发送短信 * @param mobile 手机号 * @param template_code 模板号 * @param sign_name 签名 * @param param 参数 * @return * @throws ClientException */ public SendSmsResponse sendSms(String mobile,String template_code,String sign_name,String param) throws ClientException &#123; String accessKeyId =env.getProperty("aliyun.sms.accessKeyId"); String accessKeySecret = env.getProperty("aliyun.sms.accessKeySecret"); //可自助调整超时时间 System.setProperty("sun.net.client.defaultConnectTimeout", "10000"); System.setProperty("sun.net.client.defaultReadTimeout", "10000"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessKeySecret); DefaultProfile.addEndpoint("cn-hangzhou", "cn-hangzhou", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象-具体描述见控制台-文档部分内容 SendSmsRequest request = new SendSmsRequest(); //必填:待发送手机号 request.setPhoneNumbers(mobile); //必填:短信签名-可在短信控制台中找到 request.setSignName(sign_name); //必填:短信模板-可在短信控制台中找到 request.setTemplateCode(template_code); //可选:模板中的变量替换JSON串,如模板内容为"亲爱的$&#123;name&#125;,您的验证码为$&#123;code&#125;"时,此处的值为 request.setTemplateParam(param); //选填-上行短信扩展码(无特殊需求用户请忽略此字段) //request.setSmsUpExtendCode("90997"); //可选:outId为提供给业务方扩展字段,最终在短信回执消息中将此值带回给调用者 request.setOutId("yourOutId"); //hint 此处可能会抛出异常，注意catch SendSmsResponse sendSmsResponse = acsClient.getAcsResponse(request); return sendSmsResponse; &#125; public QuerySendDetailsResponse querySendDetails(String mobile,String bizId) throws ClientException &#123; String accessKeyId =env.getProperty("accessKeyId"); String accessKeySecret = env.getProperty("accessKeySecret"); //可自助调整超时时间 System.setProperty("sun.net.client.defaultConnectTimeout", "10000"); System.setProperty("sun.net.client.defaultReadTimeout", "10000"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessKeySecret); DefaultProfile.addEndpoint("cn-hangzhou", "cn-hangzhou", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象 QuerySendDetailsRequest request = new QuerySendDetailsRequest(); //必填-号码 request.setPhoneNumber(mobile); //可选-流水号 request.setBizId(bizId); //必填-发送日期 支持30天内记录查询，格式yyyyMMdd SimpleDateFormat ft = new SimpleDateFormat("yyyyMMdd"); request.setSendDate(ft.format(new Date())); //必填-页大小 request.setPageSize(10L); //必填-当前页码从1开始计数 request.setCurrentPage(1L); //hint 此处可能会抛出异常，注意catch QuerySendDetailsResponse querySendDetailsResponse = acsClient.getAcsResponse(request); return querySendDetailsResponse; &#125;&#125;]]></content>
      <categories>
        <category>JavaUtils</category>
      </categories>
      <tags>
        <tag>JavaUtils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 搭建FTP]]></title>
    <url>%2F2019%2F01%2F09%2FCentOS7%E6%90%AD%E5%BB%BAFTP%2F</url>
    <content type="text"><![CDATA[查看是否安装了FTP：rpm -qa |grep vsftpd 如果没有任何输出，表示没有安装。 如果出现如下版本信息，则表示已经安装。 如果没有安装，可以使用如下命令直接安装1yum -y install vsftpd 默认安装目录：/etc/vsftpd 添加FTP账号1useradd admin -s /sbin/nologin 该账户路径默认指向/home/admin目录 设置密码：passwd admin 一些常用设置 设置匿名用户可以下载上传将文件/etc/vsftpd/vsftpd.conf 中下面两句的注释删除 12anon_upload_enable=YESanon_mkdir_write_enable=YES 根据个人需要设置默认目录修改/etc/passwd文件，找到你的用户名的那一行修改路径，然后保存即可，无需重启 将admin:x:500:500::/home/admin:/sbin/nologin 改成admin:x:500:500::/自定义文件夹:/sbin/nologin 启动 启动：systemctl start vsftpd 重启：systemctl restart vsftpd 开机自启：systemctl enable vsftpd]]></content>
      <categories>
        <category>FTP</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 Zookeeper安装]]></title>
    <url>%2F2019%2F01%2F08%2FZookeeper%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Zookeeper 部署有三种方式，单机模式、集群模式、伪集群模式，以下采用手动安装的方式部署 注意： 集群为大于等于3个奇数，如 3、5、7,不宜太多，集群机器多了选举和数据同步耗时长，不稳定。 单机模式下载进入要下载的版本的目录，选择 .tar.gz 文件下载，下载链接：http://archive.apache.org/dist/zookeeper/ 安装注意： 需要先安装 Java 使用 tar 解压要安装的目录即可，以 3.4.13 版本为例，解压到 /usr/local/zookeeper-3.4.13 1tar -zxvf zookeeper-3.4.13.tar.gz -C /usr/local 配置在根目录下创建 data 和 logs 两个目录用于存储数据和日志 123cd /usr/local/zookeeper-3.4.13mkdir datamkdir logs 在 conf 目录下新建 zoo.cfg 文件，写入以下内容保存 1234tickTime=2000dataDir=/usr/local/zookeeper-3.4.13/datadataLogDir=/usr/local/zookeeper-3.4.13/logsclientPort=2181 启动和停止进入 bin 目录，启动、停止、重启和查看当前节点状态 1234./zkServer.sh start./zkServer.sh stop./zkServer.sh restart./zkServer.sh status 伪集群模式伪集群模式就是在同一主机启动多个 zookeeper 并组成集群，下边以在 192.168.10.134 主机上创 3 个 zookeeper 组集群为例。 将通过单机模式安装的 zookeeper，复制成 zookeeper1/zookeeper2/zookeeper3 三份 zookeeper1 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper1/datadataLogDir=/usr/local/zookeeper1/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID 1echo '1' &gt; data/myid zookeeper2 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper2/datadataLogDir=/usr/local/zookeeper2/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID1echo '2' &gt; data/myid zookeeper3 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper3/datadataLogDir=/usr/local/zookeeper3/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID 1echo '3' &gt; data/myid 启动和停止分别启动服务器，顺序无所谓 1234./zkServer.sh start./zkServer.sh stop./zkServer.sh restart./zkServer.sh status 集群模式集群模式就是在不同主机上安装 zookeeper 然后组成集群的模式，操作步骤同上，此处不再赘述。]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 Jenkins安装]]></title>
    <url>%2F2019%2F01%2F08%2FJenkins%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载jenkins 1wget https://pkg.jenkins.io/redhat/jenkins‐2.83‐1.1.noarch.rpm 安装jenkins 1rpm ‐ivh jenkins‐2.83‐1.1.noarch.rpm 配置jenkins 修改用户和端口vi /etc/sysconfig/jenkins 12JENKINS_USER=&quot;root&quot;JENKINS_PORT=&quot;8888&quot; 配置java环境变量vi /etc/rc.d/init.d/jenkins 1234567891011# see http://www.nabble.com/guinea-pigs-wanted-----Hudson-RPM-for-RedHat-Linux-td25673707.htmlcandidates=&quot;/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java#在下面加入java环境变量/usr/java/jdk1.8.0_161/bin/java&quot; 启动服务 1systemctl start jenkins 访问链接 http://IP:8888 从/var/lib/jenkins/secrets/initialAdminPassword中获取初始密码串]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载均衡]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[Nginx 实现负载均衡 nginx 作为负载均衡服务器，用户请求先到达 nginx，再由 nginx 根据负载配置将请求转发至 tomcat 服务器 nginx 负载均衡服务器：192.168.75.145:80 tomcat1 服务器：192.168.75.145:9090 tomcat2 服务器：192.168.75.145:9091Nginx 配置负载均衡修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 1234567891011121314151617181920212223242526272829user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; upstream myapp1 &#123; server 192.168.75.145:9090 weight=10; server 192.168.75.145:9091 weight=10; &#125; server &#123; listen 80; server_name nginx.funtl.com; location / &#123; proxy_pass http://myapp1; index index.jsp index.html index.htm; &#125; &#125;&#125; 相关配置说明1234567# 定义负载均衡设备的 Ip及设备状态 upstream myServer &#123; server 127.0.0.1:9090 down; server 127.0.0.1:8080 weight=2; server 127.0.0.1:6060; server 127.0.0.1:7070 backup;&#125; 在需要使用负载的 Server 节点下添加 1proxy_pass http://myServer; upstream：每个设备的状态: down：表示当前的 server 暂时不参与负载 weight：默认为 1 weight 越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为 1 当超过最大次数时，返回 proxy_next_upstream 模块定义的错误 fail_timeout:max_fails 次失败后，暂停的时间。 backup：其它所有的非 backup 机器 down 或者忙的时候，请求 backup 机器。所以这台机器压力会最轻]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 反向代理]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[使用 Nginx 反向代理 Tomcat 需求 两个 tomcat 服务通过 nginx 反向代理 nginx 服务器：192.168.75.145:80 tomcat1 服务器：192.168.75.145:9090 tomcat2 服务器：192.168.75.145:9091 启动 Tomcat 容器启动两个 Tomcat 容器，映射端口为 9090 和 9091，docker-compose.yml 如下： 12345678910111213version: &apos;3&apos;services: tomcat1: image: tomcat container_name: tomcat1 ports: - 9090:8080 tomcat2: image: tomcat container_name: tomcat2 ports: - 9091:8080 配置 Nginx 反向代理修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 配置一个代理即 tomcat1 服务器 upstream tomcat_server1 &#123; server 192.168.75.145:9090; &#125; # 配置一个代理即 tomcat2 服务器 upstream tomcat_server2 &#123; server 192.168.75.145:9091; &#125; # 配置一个虚拟主机 server &#123; listen 80; server_name admin.service.itoken.funtl.com; location / &#123; # 域名 admin.service.itoken.funtl.com 的请求全部转发到 tomcat_server1 即 tomcat1 服务上 proxy_pass http://tomcat_server1; # 欢迎页面，按照从左到右的顺序查找页面 index index.jsp index.html index.htm; &#125; &#125; server &#123; listen 80; server_name admin.web.itoken.funtl.com; location / &#123; # 域名 admin.web.itoken.funtl.com 的请求全部转发到 tomcat_server2 即 tomcat2 服务上 proxy_pass http://tomcat_server2; index index.jsp index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 虚拟主机]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%20%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[使用 Docker 来安装和运行 Nginx，docker-compose.yml 配置如下：1234567891011version: '3.1'services: nginx: restart: always image: nginx container_name: nginx ports: - 81:80 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./wwwroot:/usr/share/nginx/wwwroot 基于端口的虚拟主机配置需求 Nginx 对外提供 80 和 8080 两个端口监听服务 请求 80 端口则请求 html80 目录下的 html 请求 8080 端口则请求 html8080 目录下的 html创建目录及文件在/usr/local/docker/nginx/wwwroot 目录下创建 html80 和 html8080 两个目录，并分辨创建两个 index.html 文件 配置虚拟主机修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 启动进程,通常设置成和 CPU 的数量相等worker_processes 1;events &#123; # epoll 是多路复用 IO(I/O Multiplexing) 中的一种方式 # 但是仅用于 linux2.6 以上内核,可以大大提高 nginx 的性能 use epoll; # 单个后台 worker process 进程的最大并发链接数 worker_connections 1024;&#125;http &#123; # 设定 mime 类型,类型由 mime.type 文件定义 include mime.types; default_type application/octet-stream; # sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， # 必须设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平衡磁盘与网络 I/O 处理速度，降低系统的 uptime. sendfile on; # 连接超时时间 keepalive_timeout 65; # 设定请求缓冲 client_header_buffer_size 2k; # 配置虚拟主机 192.168.75.145 server &#123; # 监听的ip和端口，配置 192.168.75.145:80 listen 80; # 虚拟主机名称这里配置ip地址 server_name 192.168.75.145; # 所有的请求都以 / 开始，所有的请求都可以匹配此 location location / &#123; # 使用 root 指令指定虚拟主机目录即网页存放目录 # 比如访问 http://ip/index.html 将找到 /usr/local/docker/nginx/wwwroot/html80/index.html # 比如访问 http://ip/item/index.html 将找到 /usr/local/docker/nginx/wwwroot/html80/item/index.html root /usr/share/nginx/wwwroot/html80; # 指定欢迎页面，按从左到右顺序查找 index index.html index.htm; &#125; &#125; # 配置虚拟主机 192.168.75.245 server &#123; listen 8080; server_name 192.168.75.145; location / &#123; root /usr/share/nginx/wwwroot/html8080; index index.html index.htm; &#125; &#125;&#125; 基于域名的虚拟主机配置需求 两个域名指向同一台 Nginx 服务器，用户访问不同的域名显示不同的网页内容 两个域名是 admin.service.com 和 admin.web..com Nginx 服务器使用虚拟机 192.168.75.145配置 Windows Hosts 文件 通过 host 文件指定 admin.service.com 和 admin.web.com 对应 192.168.75.145 虚拟机： 修改 window 的 hosts 文件：（C:\Windows\System32\drivers\etc） 创建目录及文件在 /usr/local/docker/nginx/wwwroot 目录下创建 htmlservice 和 htmlweb 两个目录，并分辨创建两个 index.html 文件 配置虚拟主机12345678910111213141516171819202122232425262728293031323334user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name admin.service.com; location / &#123; root /usr/share/nginx/wwwroot/htmlservice; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name admin.web.com; location / &#123; root /usr/share/nginx/wwwroot/htmlweb; index index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose]]></title>
    <url>%2F2019%2F01%2F08%2FDocker%20Compose%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 123456789version: "3"services: webapp: image: examples/web ports: - "80:80" volumes: - "/data" 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: '3'services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: '3'services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 12345build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： 12cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： 12cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令。 1command: echo "hello world" configs仅用于 Swarm mode cgroup_parent指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 1cgroup_parent: cgroups_1 container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy仅用于 Swarm mode devices指定设备映射关系。 12devices: - "/dev/ttyUSB1:/dev/ttyUSB0" depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: '3'services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns自定义 DNS 服务器。可以是一个值，也可以是一个列表。 12345dns: 8.8.8.8dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。 12345dns_search: example.comdns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器。 1234tmpfs: /runtmpfs: - /run - /tmp env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 123expose: - "3000" - "8000" external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 123extra_hosts: - "googledns:8.8.8.8" - "dockerhub:52.1.157.61" 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 128.8.8.8 googledns52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: ["CMD", "curl", "-f", "http://localhost"] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 1234labels: com.startupteam.description: "webapp for a startup team" com.startupteam.department: "devops department" com.startupteam.release: "rc3 for v1.0" links 注意：不推荐使用该指令。 logging配置日志选项。 1234logging: driver: syslog options: syslog-address: "tcp://192.168.0.42:123" 目前支持三种日志驱动类型。 123driver: "json-file"driver: "syslog"driver: "none" options 配置日志驱动的相关参数。 123options: max-size: "200k" max-file: "10" network_mode设置网络模式。使用和 docker run 的 --network 参数一样的值。 12345network_mode: "bridge"network_mode: "host"network_mode: "none"network_mode: "service:[service name]"network_mode: "container:[container name/id]" networks配置容器连接的网络。 1234567891011version: "3"services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: pid跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 1pid: &quot;host&quot; ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - "3000" - "8000:8000" - "49100:22" - "127.0.0.1:8001:8001" 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets存储敏感数据，例如 mysql 服务密码。 12345678910111213141516version: "3.1"services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 123security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 1stop_signal: SIGUSR1 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 其它指令此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 1entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名。 1user: nginx 指定容器中工作目录。 1working_dir: /code 指定容器中搜索域名、主机名、mac 地址等。 123domainname: your_website.comhostname: testmac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 1privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 1restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 1yamlread_only: true 打开标准输入，可以接受外部输入。 1stdin_open: true 模拟一个伪终端。 1tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 12345version: "3"services:db: image: "mongo:$&#123;MONGO_VERSION&#125;" 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 12# 支持 # 号注释MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose命令]]></title>
    <url>%2F2019%2F01%2F08%2FDocker%20Compose%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 build格式为 docker-compose build [options] [SERVICE...]。 构建（重新构建）项目中的服务容器。 服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 选项包括： --force-rm 删除构建过程中的临时容器。 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 --pull 始终尝试通过 pull 来获取更新版本的镜像。 config验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 down此命令将会停止 up 命令所启动的容器，并移除网络 exec进入指定的容器。 help获得一个命令的帮助。 images列出 Compose 文件中包含的镜像。 kill格式为 docker-compose kill [options] [SERVICE...]。 通过发送 SIGKILL 信号来强制停止服务容器。 支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 1$ docker-compose kill -s SIGINT logs格式为 docker-compose logs [options] [SERVICE...]。 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 pause格式为 docker-compose pause [SERVICE...]。 暂停一个服务容器。 port格式为 docker-compose port [options] SERVICE PRIVATE_PORT。 打印某个容器端口所映射的公共端口。 选项： --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： pull 格式为 docker-compose pull [options] [SERVICE...]。 拉取服务依赖的镜像。 选项： --ignore-pull-failures 忽略拉取镜像过程中的错误。 pushrestart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。 在指定服务上执行一个命令。 例如： 1$ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如 1$ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 选项： -d 后台运行容器。 --name NAME 为容器指定一个名字。 --entrypoint CMD 覆盖默认的容器启动指令。 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。 --no-deps 不自动启动关联的服务容器。 --rm 运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] 映射容器端口到本地主机。 --service-ports 配置服务端口并映射到本地主机。 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale格式为 docker-compose scale [options] [SERVICE=NUM...]。 设置指定服务运行的容器个数。 通过 service=num 的参数来设置数量。例如： 1$ docker-compose scale web=3 db=2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。 一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start格式为 docker-compose start [SERVICE...]。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version格式为 docker-compose version。 打印版本信息。]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose]]></title>
    <url>%2F2019%2F01%2F08%2FDocker%20Compose%2F</url>
    <content type="text"><![CDATA[什么是 Docker ComposeDocker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 概述Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Docker Compose安装与卸载Compose 支持 Linux、macOS、Windows 10 三大平台。 Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。 前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景。 Docker for Mac 、Docker for Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 123$ docker-compose --versiondocker-compose version 1.17.1, build 6d101fb Linux 系统请使用以下介绍的方法安装。在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose 卸载1$ sudo rm /usr/local/bin/docker-compose]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS Docker 安装]]></title>
    <url>%2F2019%2F01%2F08%2FCentOS%20Docker%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker支持以下的CentOS版本： CentOS 7 (64-bit) CentOS 6.5 (64-bit) 或更高的版本 前提条件目前，CentOS 仅发行版本中的内核支持 Docker。 Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。 Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。 使用 yum 安装（CentOS 7下）Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 通过 uname -r 命令查看你当前的内核版本 [root@runoob ~]# uname -r 3.10.0-327.el7.x86_64 安装Docker CE版 移除旧的版本 12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ ocker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安装一些必要的系统工具： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加软件源信息： 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum缓存 1sudo yum makecache fast 安装Docker-ce 1sudo yum -y install docker-ce 启动Docker服务 1sudo systemctl start docker 设置Docker开机自启 1sudo systemctl enable docker 关闭Docker服务 1sudo systemctl stop docker 镜像加速 在 /etc/docker/daemon.json中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 删除Docker CE12$ sudo yum remove docker-ce$ sudo rm -rf /var/lib/docker]]></content>
      <categories>
        <category>Docker</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS单机版安装]]></title>
    <url>%2F2019%2F01%2F07%2FFastDFS%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[配置镜像加速器:修改daemon配置文件/etc/docker/daemon.json12sudo mkdir -p /etc/dockersudo vi /etc/docker/daemon.json 在key为registry-mirrors追加&quot;https://1031vuk0.mirror.aliyuncs.com&quot; 1234# 若没有直接cv大法&#123; "registry-mirrors": ["https://1031vuk0.mirror.aliyuncs.com"]&#125; 重启docker刷新配置12sudo systemctl daemon-reloadsudo systemctl restart docker 编写docker-compose.yml123456789version: '3.1'services: fastdfs: image: registry.cn-shenzhen.aliyuncs.com/dev_docker_resp/fastdfs restart: always container_name: fastdfs volumes: - ./storage:/fastdfs/storage network_mode: host 运行docker-compose up -d]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>FastDFS</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件RabbitMQ]]></title>
    <url>%2F2019%2F01%2F07%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6RabbitMQ%2F</url>
    <content type="text"><![CDATA[消息中间件RabbitMQ 消息队列中间件简介 消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题实现高性能，高可用，可伸缩和最终一致性[架构] 使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 以下介绍消息队列在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景 RabbitMQ 简介 RabbitMQ 是一个由 Erlang语言开发的AMQP的开源实现。 AMQP：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。 主要概念 RabbitMQ Server： 也叫broker server，它是一种传输服务。 他的角色就是维护一条从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer： 消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服务器然后将消息投递到Exchange。 Consumer：消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列，RabbitMQ将Queue中的消息发送到消息消费者。 Exchange：生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue：（队列）是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 RoutingKey：生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则，而这个routing key需要与Exchange Type binding key联合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定routing key来决定消息流向哪里。RabbitMQ为routing key设定的长度限制为255bytes。 Connection： （连接）：Producer和Consumer都是通过TCP连接到RabbitMQ Server的。以后我们可以看到，程序的起始处就是建立这个TCP连接。 Channels： （信道）：它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 VirtualHost：权限控制的基本单位，一个VirtualHost里面有若干Exchange和MessageQueue，以及指定被哪些user使用 RabbitMQ安装与启动 编写docker-compose.yml文件 1234567891011121314151617181920version: '3.1'services: rabbitmq: restart: always image: rabbitmq:management container_name: rabbitmq ports: - 5672:5672 - 15672:15672 - 5671:5617 - 15671:15671 - 25672:25672 environment: TZ: Asia/Shanghai RABBITMQ_DEFAULT_USER: rabbit RABBITMQ_DEFAULT_PASS: 123456 volumes: - data:/var/lib/rabbitmqvolumes: data: rabbitmq需要有映射以下端口: 5671、5672、4369、15671、15672、25672 15672 (if management plugin is enabled) 15671 management监听端口 5672, 5671 (AMQP 0-9-1 without and with TLS) 4369 (epmd) epmd 代表 Erlang 端口映射守护进程 25672 (Erlang distribution) 启动容器docker-compose up -d 访问地址：http://IP:15672,即可看到管理界面的登陆页]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
</search>
