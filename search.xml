<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ElasticSearch的Head插件]]></title>
    <url>%2F2019%2F03%2F15%2FElasticsearch%2FElasticSearch%E7%9A%84Head%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Head是elasticsearch的集群管理工具，可以用于数据的浏览和查询，elasticsearch-head是一款开源软件，被托管在github上面 源码安装下载插件123git clone https://github.com/mobz/elasticsearch-head.gitcd /usr/local/elasticsearch-head 安装elasticsearch-head依赖包 1npm install -g grunt-cli 安装 123npm install -g cnpm --registry=https://registry.npm.taobao.orgcnpm install 启动1npm run start docker安装编写docker-compose.yml 12345678910version: &apos;3&apos;services: elasticsearch-head: restart: always image: mobz/elasticsearch-head container_name: elasticsearch-head environment: TZ: &apos;Asia/Shanghai&apos; ports: - &apos;9100:9100&apos;]]></content>
      <categories>
        <category>Elasticsearch head</category>
      </categories>
      <tags>
        <tag>Elasticsearch head</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kibana安装]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2Fkibana%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[docker-compose.yml123456789101112version: '3'services: kibana: container_name: kibana image: docker.elastic.co/kibana/kibana:6.5.4 volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml ports: - 5601:5601 environment: SERVER_HOST: 0.0.0.0 ELASTICSEARCH_URL: http://IP:9200/ 注:IP为elasticsearch的IP地址]]></content>
      <categories>
        <category>kibana</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB安装]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2FMongoDB%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[docker-compose.yml：123456789101112version: "3"services: mongo: restart: always image: mongo container_name: mongo volumes: - data:/data/db ports: - 27017:27017volumes: data:]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker构建jar包并创建docker-compose启动镜像]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2Fdocker%E6%9E%84%E5%BB%BAjar%E5%8C%85%E5%B9%B6%E5%88%9B%E5%BB%BAdocker-compose%E5%90%AF%E5%8A%A8%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[创建Dockerfile文件123456789FROM openjdk:8-jreRUN mkdir /appCOPY jar包.jar /app/CMD java -jar /app/jar包.jar --spring.profiles.active=prodEXPOSE 暴露端口号 通过dockerfile文本生成工程镜像 1docker build -t canteen . docker build -t canteen:命令构建镜像名为canteen的镜像，-t:给镜像取名为canteen 编写docker-compose.yml12345678910version: &apos;3.1&apos;services: canteen: restart: always image: canteen container_name: canteen prots: - 8002:8002 environment: TZ: Asia/Shanghai]]></content>
      <categories>
        <category>Docker build</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Docker build</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2FUntitled%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Redis安装]]></title>
    <url>%2F2019%2F03%2F15%2FRedis%2FRedis%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[编写docker-compose.yml配置文件12345678910111213version: &apos;3.1&apos;services: redis: restart: always image: redis container_name: redis command: redis-server --requirepass 123456 --appendonly yes ports: - &quot;6379:6379&quot; volumes: - data:/datavolumes: data: --requirepass:设置密码，--appendonly:开启持久化 使用命令docker-compose up -d运行]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Registry私服安装及使用]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2FRegistry%E7%A7%81%E6%9C%8D%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介官方的 Docker Hub 是一个用于管理公共镜像的地方，我们可以在上面找到我们想要的镜像，也可以把我们自己的镜像推送上去。但是，有时候我们的服务器无法访问互联网，或者你不希望将自己的镜像放到公网当中，那么你就需要 Docker Registry，它可以用来存储和管理自己的镜像。 安装编写docker-compose.yml在之前的 Docker 私有仓库 章节中已经提到过如何配置和使用容器运行私有仓库，这里我们使用 docker-compose 来安装，配置如下： 12345678910version: '3.1'services: registry: image: registry restart: always container_name: registry ports: - 5000:5000 volumes: - /usr/local/docker/registry/data:/var/lib/registry 测试启动成功后需要测试服务端是否能够正常提供服务，有两种方式： 浏览器端访问 1http://ip:5000/v2/ 终端访问 1curl http://ip:5000/v2/ 配置 Docker Registry 客户端在 /etc/docker/daemon.json中增加如下内容（如果文件不存在请新建该文件） 12345678&#123; &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot;: [ &quot;ip:5000&quot; ]&#125; 注意：该文件必须符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 检查客户端配置是否生效使用 docker info 命令手动检查，如果从配置中看到如下内容，说明配置成功（192.168.0.113） 测试镜像上传我们以 mysql 为例测试镜像上传功能 12345678910111213141516## 拉取一个镜像docker pull mysql:5.7.23## 查看全部镜像docker images## 标记本地镜像并指向目标仓库（ip:port/image_name:tag，该格式为标记版本号）docker tag nginx 192.168.0.113:5000/mysql:5.7.23## 提交镜像到仓库docker push 192.168.0.113:5000/mysql:5.7.23 查看全部镜像1curl -XGET http://192.168.0.113:5000/v2/_catalog 查看指定镜像以 mysql 为例，查看已提交的列表 1curl -XGET http://192.168.0.113:5000/v2/mysql/tags/list 测试拉取镜像 先删除镜像 12docker rmi mysql:5.7.23docker rmi 192.168.0.113:5000/mysql:5.7.23 再拉取镜像 1docker pull 192.168.75.133:5000/nginx 部署 Docker Registry WebUI私服安装成功后就可以使用 docker 命令行工具对 registry 做各种操作了。然而不太方便的地方是不能直观的查看 registry 中的资源情况。如果可以使用 UI 工具管理镜像就更好了。这里介绍两个 Docker Registry WebUI 工具 docker-registry-frontend docker-registry-web 两个工具的功能和界面都差不多，我们以 docker-registry-fontend 为例讲解 docker-registry-frontend我们使用 docker-compose 来安装和运行，docker-compose.yml 配置如下： 123456789101112version: &apos;3.1&apos;services: frontend: image: konradkleine/docker-registry-frontend:v2 ports: - 8080:80 volumes: - ./certs/frontend.crt:/etc/apache2/server.crt:ro - ./certs/frontend.key:/etc/apache2/server.key:ro environment: - ENV_DOCKER_REGISTRY_HOST=192.168.0.113 - ENV_DOCKER_REGISTRY_PORT=5000 注意：请将配置文件中的主机和端口换成自己仓库的地址 运行成功后在浏览器访问：http://192.168.0.113]]></content>
      <categories>
        <category>Registry</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在项目中使用 Maven 私服]]></title>
    <url>%2F2019%2F03%2F15%2FdevNote%2F%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8%20Maven%20%E7%A7%81%E6%9C%8D%2F</url>
    <content type="text"><![CDATA[配置认证信息在 Maven settings.xml 中添加 Nexus 认证信息(servers 节点下)： 1234567891011&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt;&lt;/server&gt; Snapshots 与 Releases 的区别 nexus-releases: 用于发布 Release 版本 nexus-snapshots: 用于发布 Snapshot 版本（快照版） Release 版本与 Snapshot 定义如下： 12Release: 1.0.0/1.0.0-RELEASESnapshot: 1.0.0-SNAPSHOT 在项目 pom.xml 中设置的版本号添加 SNAPSHOT 标识的都会发布为 SNAPSHOT 版本，没有 SNAPSHOT 标识的都会发布为 RELEASE 版本。 SNAPSHOT 版本会自动加一个时间作为标识，如：1.0.0-SNAPSHOT发布后为变成 1.0.0-SNAPSHOT-20180522.123456-1.jar 配置自动化部署在 pom.xml 中添加如下代码： 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 注意事项： id 名称必须要与 settings.xml 中 Servers 配置的 id 名称保持一致。 项目版本号中有 SNAPSHOT 标识的，会发布到 Nexus Snapshots Repository, 否则发布到 Nexus Release Repository，并根据 ID 去匹配授权账号。 部署到仓库1mvn deploy -Dmaven.test.skip=true 上传第三方 JAR 包 Nexus 3.0 不支持页面上传，可使用 maven 命令： 如第三方JAR包：kaptcha-2.3.jar12345678mvn deploy:deploy-file ^ -DgroupId=com.google.code.kaptcha ^ -DartifactId=kaptcha ^ -Dversion=2.3 ^ -Dpackaging=jar ^ -Dfile=jar包本地路径 ^ -Durl=http://私服ip:端口/repository/maven-releases/ ^ -DrepositoryId=nexus-releases 注意事项： 建议在上传第三方 JAR包时，创建单独的第三方JAR包管理仓库，便于管理有维护。（maven-3rd） -DrepositoryId=nexus-releases对应的是settings.xml中Servers配置的ID名称。（授权） 配置代理仓库1234567891011121314151617181920212223242526&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Repository&lt;/name&gt; &lt;url&gt;http://私服ip:端口/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Plugin Repository&lt;/name&gt; &lt;url&gt;http://私服ip:端口/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab安装]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2Fgitlab%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介GitLab 是利用 Ruby on Rails 一个开源的版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。它拥有与 Github 类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找。 编写docker-compose.yml文件 12345678910111213141516171819202122version: &apos;3&apos;services: web: image: &apos;twang2218/gitlab-ce-zh:10.5&apos; restart: always hostname: &apos;192.168.0.125&apos; privileged: true environment: TZ: &apos;Asia/Shanghai&apos; GITLAB_OMNIBUS_CONFIG: | external_url &apos;http://192.168.0.125&apos; gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 2222 unicorn[&apos;port&apos;] = 8888 nginx[&apos;listen_port&apos;] = 80 ports: - &apos;80:80&apos; - &apos;8443:443&apos; - &apos;2222:22&apos; volumes: - /usr/local/docker/gitlab/config:/etc/gitlab - /usr/local/docker/gitlab/data:/var/opt/gitlab - /usr/local/docker/gitlab/logs:/var/log/gitlab 使用命令docker-compose up启动访问http://192.168.0.125，验证gitlab是否安装成功gitlab默认用户root]]></content>
      <categories>
        <category>Gitlab</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven私服Nexus3快速搭建使用]]></title>
    <url>%2F2019%2F03%2F15%2Fdocker%2FMySQL%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1. 编写docker-compose.yml文件Mysql 51234567891011121314151617181920version: '3'services: mysql: restart: always image: mysql:5.7.23 container_name: mysql ports: - 3306:3306 environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 command: --character-set-server=utf8 --collation-server=utf8_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M --sql-mode="STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO" volumes: - ./data:/var/lib/mysql Mysql 8**1234567891011121314151617181920212223version: '3.1'services: db: image: mysql restart: always environment: MYSQL_ROOT_PASSWORD: 123456 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8 --collation-server=utf8_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql adminer: image: adminer restart: always ports: - 8080:8080 2. 使用命令docker-compose up -d启动]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[引入thymeleaf并支持非严格的HTML]]></title>
    <url>%2F2019%2F03%2F15%2Fspring-boot%2F%E5%BC%95%E5%85%A5thymeleaf%E5%B9%B6%E6%94%AF%E6%8C%81%E9%9D%9E%E4%B8%A5%E6%A0%BC%E7%9A%84HTML%2F</url>
    <content type="text"><![CDATA[引入依赖主要增加 spring-boot-starter-thymeleaf 和 nekohtml 这两个依赖 spring-boot-starter-thymeleaf：Thymeleaf 自动配置 nekohtml：允许使用非严格的 HTML 语法 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt;&lt;/dependency&gt; 在 application.yml 中配置 Thymeleaf1234567spring: thymeleaf: cache: false # 开发时关闭缓存,不然没法看到实时页面 mode: LEGACYHTML5 # 用非严格的 HTML encoding: UTF-8 servlet: content-type: text/html 修改 html 标签用于引入 thymeleaf 引擎，这样才可以在其他标签里使用 th:* 语法，声明如下： 12&lt;!DOCTYPE html SYSTEM &quot;http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-spring4-4.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;]]></content>
      <categories>
        <category>thymeleaf</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成MyBatis的Maven插件生成代码]]></title>
    <url>%2F2019%2F03%2F15%2Fspring-boot%2F%E9%9B%86%E6%88%90MyBatis%E7%9A%84Maven%E6%8F%92%E4%BB%B6%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[我们无需手动编写 实体类、DAO、XML 配置文件，只需要使用 MyBatis 提供的一个 Maven 插件就可以自动生成所需的各种文件便能够满足基本的业务需求，如果业务比较复杂只需要修改相关文件即可。 配置插件在 pom.xml 文件中增加 mybatis-generator-maven-plugin 插件 1234567891011121314151617181920212223242526&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;3.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; configurationFile：自动生成所需的配置文件路径 自动生成的配置在 src/main/resources/generator/ 目录下创建 generatorConfig.xml 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;!-- 引入数据库连接配置 --&gt; &lt;properties resource="jdbc.properties"/&gt; &lt;context id="Mysql" targetRuntime="MyBatis3Simple" defaultModelType="flat"&gt; &lt;property name="beginningDelimiter" value="`"/&gt; &lt;property name="endingDelimiter" value="`"/&gt; &lt;!-- 配置 tk.mybatis 插件 --&gt; &lt;plugin type="tk.mybatis.mapper.generator.MapperPlugin"&gt; &lt;property name="mappers" value="com.funtl.utils.MyMapper"/&gt; &lt;/plugin&gt; &lt;!-- 配置数据库连接 --&gt; &lt;jdbcConnection driverClass="$&#123;jdbc.driverClass&#125;" connectionURL="$&#123;jdbc.connectionURL&#125;" userId="$&#123;jdbc.username&#125;" password="$&#123;jdbc.password&#125;"&gt; &lt;/jdbcConnection&gt; &lt;!-- 配置实体类存放路径 --&gt; &lt;javaModelGenerator targetPackage="com.funtl.hello.spring.boot.entity" targetProject="src/main/java"/&gt; &lt;!-- 配置 XML 存放路径 --&gt; &lt;sqlMapGenerator targetPackage="mapper" targetProject="src/main/resources"/&gt; &lt;!-- 配置 DAO 存放路径 --&gt; &lt;javaClientGenerator targetPackage="com.funtl.hello.spring.boot.mapper" targetProject="src/main/java" type="XMLMAPPER"/&gt; &lt;!-- 配置需要生成的表，% 代表所有 --&gt; &lt;table tableName="%"&gt; &lt;!-- mysql 配置 --&gt; &lt;generatedKey column="id" sqlStatement="Mysql" identity="true"/&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 配置数据源在 src/main/resources 目录下创建 jdbc.properties 数据源配置： 1234jdbc.driverClass=com.mysql.jdbc.Driverjdbc.connectionURL=jdbc:mysql://ip:port/dbname?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=falsejdbc.username=rootjdbc.password=123456 插件自动生成命令1mvn mybatis-generator:generate 完整配置案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN""http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;!-- 配置生成器 --&gt;&lt;generatorConfiguration&gt;&lt;!-- 可以用于加载配置项或者配置文件，在整个配置文件中就可以使用$&#123;propertyKey&#125;的方式来引用配置项 resource：配置资源加载地址，使用resource，MBG从classpath开始找，比如com/myproject/generatorConfig.properties url：配置资源加载地质，使用URL的方式，比如file:///C:/myfolder/generatorConfig.properties. 注意，两个属性只能选址一个; 另外，如果使用了mybatis-generator-maven-plugin，那么在pom.xml中定义的properties都可以直接在generatorConfig.xml中使用&lt;properties resource="" url="" /&gt; --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包 location属性指明加载jar/zip包的全路径&lt;classPathEntry location="/Program Files/IBM/SQLLIB/java/db2java.zip" /&gt; --&gt;&lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG--&gt;&lt;context id="mysql" defaultModelType="hierarchical" targetRuntime="MyBatis3Simple" &gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name="autoDelimitKeywords" value="false"/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name="javaFileEncoding" value="UTF-8"/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name="javaFormatter" value="org.mybatis.generator.api.dom.DefaultJavaFormatter"/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name="xmlFormatter" value="org.mybatis.generator.api.dom.DefaultXmlFormatter"/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;property name="beginningDelimiter" value="`"/&gt; &lt;property name="endingDelimiter" value="`"/&gt; &lt;!-- 必须要有的，使用这个配置链接数据库 @TODO:是否可以扩展 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql:///pss" userId="root" password="admin"&gt; &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 --&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type="org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl"&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage="com._520it.mybatis.domain" targetProject="src/main/java"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;property name="rootClass" value="com._520it.mybatis.domain.BaseDomain"/&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成SQL map的XML文件生成器， 注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口）， 或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置 targetPackage/targetProject:同javaModelGenerator --&gt; &lt;sqlMapGenerator targetPackage="com._520it.mybatis.mapper" targetProject="src/main/resources"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;javaClientGenerator targetPackage="com._520it.mybatis.mapper" type="ANNOTATEDMAPPER" targetProject="src/main/java"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的""把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers="true"即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName="userinfo" &gt; &lt;!-- 参考 javaModelGenerator 的 constructorBased属性--&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； --&gt; &lt;property name="ignoreQualifiersAtRuntime" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 immutable 属性 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 --&gt; &lt;property name="modelOnly" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 &lt;property name="rootClass" value=""/&gt; --&gt; &lt;!-- 参考javaClientGenerator 的 rootInterface 属性 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog &lt;property name="runtimeCatalog" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema &lt;property name="runtimeSchema" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename &lt;property name="runtimeTableName" value=""/&gt; --&gt; &lt;!-- 注意，该属性只针对MyBatis3Simple有用； 如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； --&gt; &lt;property name="selectAllOrderByClause" value="age desc,username asc"/&gt; &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN_DATE，生成的属性名字就是BORN_DATE,而不会是bornDate --&gt; &lt;property name="useActualColumnNames" value="false"/&gt; &lt;!-- generatedKey用于生成生成主键的方法， 如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选 column:主键的列名； sqlStatement：要生成的selectKey语句，有以下可选项： Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2 :相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2_MF :相当于selectKey的SQL为：SELECT IDENTITY_VAL_LOCAL() FROM SYSIBM.SYSDUMMY1 Derby :相当于selectKey的SQL为：VALUES IDENTITY_VAL_LOCAL() HSQLDB :相当于selectKey的SQL为：CALL IDENTITY() Informix :相当于selectKey的SQL为：select dbinfo('sqlca.sqlerrd1') from systables where tabid=1 MySql :相当于selectKey的SQL为：SELECT LAST_INSERT_ID() SqlServer :相当于selectKey的SQL为：SELECT SCOPE_IDENTITY() SYBASE :相当于selectKey的SQL为：SELECT @@IDENTITY JDBC :相当于在生成的insert元素上添加useGeneratedKeys="true"和keyProperty属性 &lt;generatedKey column="" sqlStatement=""/&gt; --&gt; &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候， 比如列名为：CUST_ID,CUST_NAME,CUST_EMAIL,CUST_ADDRESS等； 那么就可以设置searchString为"^CUST_"，并使用空白替换，那么生成的Customer对象中的属性名称就不是 custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email； 注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的， 如果使用了columnOverride元素，该属性无效； &lt;columnRenamingRule searchString="" replaceString=""/&gt; --&gt; &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性； column:要重新设置的列名； 注意，一个table元素中可以有多个columnOverride元素哈~ --&gt; &lt;columnOverride column="username"&gt; &lt;!-- 使用property属性来指定列要生成的属性名称 --&gt; &lt;property name="property" value="userName"/&gt; &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名 &lt;property name="javaType" value=""/&gt; --&gt; &lt;!-- jdbcType用于指定该列的JDBC类型 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名 注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler 只会生成类似：where id = #&#123;id,jdbcType=BIGINT,typeHandler=com._520it.mybatis.MyTypeHandler&#125;的参数描述 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- 参考table元素的delimitAllColumns配置，默认为false &lt;property name="delimitedColumnName" value=""/&gt; --&gt; &lt;/columnOverride&gt; &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 column:指定要忽略的列的名字； delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false 注意，一个table元素中可以有多个ignoreColumn元素 &lt;ignoreColumn column="deptId" delimitedColumnName=""/&gt; --&gt; &lt;/table&gt;&lt;/context&gt;&lt;/generatorConfiguration&gt;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba 合集]]></title>
    <url>%2F2019%2F02%2F19%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%20%E5%90%88%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Spring Cloud AlibabaSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。 参考文档 请查看 WIKI 。 创建统一的依赖管理概述 温馨提示 项目的最新版本是 0.2.1.RELEASE 和 0.1.1.RELEASE，版本 0.2.1.RELEASE 对应的是 Spring Cloud Finchley 版本，版本 0.1.1.RELEASE 对应的是 Spring Cloud Edgware 版本。 故在选择 Spring Boot 版本时不要使用 2.1.0 及以上版本（因为 2.1.x 版本必须使用 Spring Cloud Greenwich，俗称 G 版），请使用官方 Demo 中使用的 2.0.5.RELEASE，以免发生意想不到的问题（比如服务无法注册到服务器） Spring Cloud Alibaba 项目都是基于 Spring Cloud，而 Spring Cloud 项目又是基于 Spring Boot 进行开发，并且都是使用 Maven 做项目管理工具。在实际开发中，我们一般都会创建一个依赖管理项目作为 Maven 的 Parent 项目使用，这样做可以极大的方便我们对 Jar 包版本的统一管理。 创建依赖管理项目创建一个工程名为 cloud-alibaba-dependencies 的项目，pom.xml 配置文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.5.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-alibaba-dependencies：在 properties 配置中预定义了版本号为 0.2.1.RELEASE ，表示我们的 Spring Cloud Alibaba 对应的是 Spring Cloud Finchley 版本 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 服务注册与发现概述在 Spring Cloud Netflix 阶段我们采用 Eureka 做作为我们的服务注册与发现服务器，现利用 Spring Cloud Alibaba 提供的 Nacos 组件替代该方案。 Nacos 官网 什么是 NacosNacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 基本架构及概念 服务 (Service)服务是指一个或一组软件功能（例如特定信息的检索或一组操作的执行），其目的是不同的客户端可以为不同的目的重用（例如通过跨进程的网络调用）。Nacos 支持主流的服务生态，如 Kubernetes Service、gRPC|Dubbo RPC Service 或者 Spring Cloud RESTful Service. 服务注册中心 (Service Registry)服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求。 服务元数据 (Service Metadata)服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据 服务提供方(Service Provider)是指提供可复用和可调用服务的应用方 服务消费方 (Service Consumer)是指会发起对某个服务调用的应用方 配置 (Configuration)在系统开发过程中通常会将一些需要变更的参数、变量等从代码中分离出来独立管理，以独立的配置文件的形式存在。目的是让静态的系统工件或者交付物（如 WAR，JAR 包等）更好地和实际的物理运行环境进行适配。配置管理一般包含在系统部署的过程中，由系统管理员或者运维人员完成这个步骤。配置变更是调整系统运行时的行为的有效手段之一 配置管理 (Configuration Management)在数据中心中，系统中所有配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等所有与配置相关的活动统称为配置管理 名字服务 (Naming Service)提供分布式系统中所有对象(Object)、实体(Entity)的“名字”到关联的元数据之间的映射管理服务，例如 ServiceName -&gt; Endpoints Info, Distributed Lock Name -&gt; Lock Owner/Status Info, DNS Domain Name -&gt; IP List, 服务发现和 DNS 就是名字服务的2大场景 配置服务 (Configuration Service)在服务或者应用运行过程中，提供动态配置或者元数据以及配置管理的服务提供者 下载安装预备环境准备Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行Nacos，还需要为此配置 Maven环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+；下载 &amp; 配置。 Maven 3.2.x+；下载 &amp; 配置。 下载源码或者安装包 从 Github 上下载源码方式 1234567git clone https://github.com/alibaba/nacos.gitcd nacos/mvn -Prelease-nacos clean install -U ls -al distribution/target/// change the $version to your actual pathcd distribution/target/nacos-server-$version/nacos/bin 下载编译后压缩包方式 您可以从 最新稳定版本 下载 nacos-server-$version.zip 包。 12unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gzcd nacos/bin 启动服务器 Linux/Unix/Mac 启动命令(standalone代表着单机模式运行，非集群模式): 1sh startup.sh -m standalone Windows 启动命令： 1cmd startup.cmd 或者双击startup.cmd运行文件。 访问服务打开浏览器访问：http://132.232.137.183:8848/nacos 默认用户名：nacos 密码：nacos 创建服务提供者概述通过一个简单的示例来感受一下如何将服务注册到 Nacos，其实和 Eureka 没有太大差别。 POM创建一个工程名为 cloud-alibaba-service-provider 的服务提供者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-service-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; Application通过 @EnableDiscoveryClient 注解表明是一个 Nacos 客户端，该注解是 Spring Cloud 提供的原生注解 1234567@SpringBootApplication@EnableDiscoveryClientpublic class ServiceProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceProviderApplication.class,args); &#125;&#125; Controller1234567891011@RestControllerpublic class ProviderController &#123; @Value("$&#123;server.port&#125;") private int port; @GetMapping("/hello/&#123;message&#125;") public String hello(@PathVariable("message")String message)&#123; return String.format("Hello " + message + ",I am provider .I am from "+ port); &#125;&#125; application.yml1234567891011121314server: port: 8081spring: application: name: service-provider cloud: nacos: discovery: server-addr: 132.232.137.183:8848management: endpoints: web: exposure: include: "*" 启动工程通过浏览器访问 http://132.232.137.183:8848/nacos，即 Nacos Server 网址 你会发现一个服务已经注册在服务中了，服务名为service-provider 这时打开 http://localhost:8081/hello/nacos ，你会在浏览器上看到： 服务的端点检查spring-cloud-starter-alibaba-nacos-discovery 在实现的时候提供了一个 EndPoint, EndPoint 的访问地址为 http://ip:port/actuator/nacos-discovery。 EndPoint 的信息主要提供了两类: 121、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 通过浏览器访问 http://localhost:8081/actuator/nacos-discovery 你会在浏览器上看到： 附：Nacos Starter 更多配置项信息 配置项 Key 默认值 说明 服务端地址 spring.cloud.nacos.discovery.server-addr 无 Nacos Server 启动监听的ip地址和端口 服务名 spring.cloud.nacos.discovery.service ${spring.application.name} 给当前的服务命名 权重 spring.cloud.nacos.discovery.weight 1 取值范围 1 到 100，数值越大，权重越大 网卡名 spring.cloud.nacos.discovery.network-interface 无 当IP未配置时，注册的IP为此网卡所对应的IP地址，如果此项也未配置，则默认取第一块网卡的地址 注册的IP地址 spring.cloud.nacos.discovery.ip 无 优先级最高 注册的端口 spring.cloud.nacos.discovery.port -1 默认情况下不用配置，会自动探测 命名空间 spring.cloud.nacos.discovery.namespace 无 常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 AccessKey spring.cloud.nacos.discovery.access-key 无 当要上阿里云时，阿里云上面的一个云账号名 SecretKey spring.cloud.nacos.discovery.secret-key 无 当要上阿里云时，阿里云上面的一个云账号密码 Metadata spring.cloud.nacos.discovery.metadata 无 使用 Map 格式配置，用户可以根据自己的需要自定义一些和服务相关的元数据信息 日志文件名 spring.cloud.nacos.discovery.log-name 无 接入点 spring.cloud.nacos.discovery.enpoint UTF-8 地域的某个服务的入口域名，通过此域名可以动态地拿到服务端地址 是否集成 Ribbon ribbon.nacos.enabled true 创建服务消费者概述服务消费者的创建与服务提供者大同小异，这里采用最原始的一种方式，即显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 POM创建一个工程名为 cloud-alibaba-service-consumer 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-service-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; Application1234567@SpringBootApplication@EnableDiscoveryClientpublic class ServiceConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceConsumerApplication.class,args); &#125;&#125; Configuration创建一个名为 ConsumerConfiguration 的 Java 配置类，主要作用是为了注入 RestTemplate 12345678@Configurationpublic class ConsumerConfiguration &#123; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; Controller创建一个名为 ConsumerController 测试用的 Controller 123456789101112131415161718192021222324@RestControllerpublic class ConsumerController &#123; private final LoadBalancerClient loadBalancerClient; private final RestTemplate restTemplate; @Autowired public ConsumerController(LoadBalancerClient loadBalancerClient, RestTemplate restTemplate) &#123; this.loadBalancerClient = loadBalancerClient; this.restTemplate = restTemplate; &#125; @Value("$&#123;spring.application.name&#125;") private String appName; @GetMapping(value = "/echo/app/name") public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 ServiceInstance serviceInstance = loadBalancerClient.choose("service-provider"); String url = String.format("http://%s:%s/hello/%s", serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; application.yml1234567891011121314server: port: 9091spring: application: name: service-consumer cloud: nacos: discovery: server-addr: 132.232.137.183:8848management: endpoints: web: exposure: include: "*" 启动工程通过浏览器访问 http://132.232.137.183:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 service-consumer 的服务 这时打开 http://localhost:9091/echo/app/name ，你会在浏览器上看到： 服务的端点检查通过浏览器访问 http://localhost:9091/actuator/nacos-discovery 你会在浏览器上看到： 创建服务消费者（Feign）概述Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon POM创建一个工程名为 cloud-alibaba-service-consumer-feign 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-service-consumer-feign&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-openfeign 依赖 Application通过 @EnableFeignClients 注解开启 Feign 功能 12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class ServiceConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceConsumerFeignApplication.class,args); &#125;&#125; 创建 Feign 接口通过 @FeignClient(&quot;服务名&quot;) 注解来指定调用哪个服务。代码如下： 12345@FeignClient(value = "service-provider")public interface ConsumerService &#123; @GetMapping("/hello/&#123;message&#125;") String hello(@PathVariable("message")String message);&#125; Controller1234567891011121314@RestControllerpublic class ConsumerFeignController &#123; private final ConsumerService consumerService; @Autowired public ConsumerFeignController(ConsumerService consumerService) &#123; this.consumerService = consumerService; &#125; @GetMapping(value = "/hello/&#123;message&#125;") public String hello(@PathVariable("message")String message) &#123; return consumerService.hello(message); &#125;&#125; application.yml1234567891011121314server: port: 9092spring: application: name: service-consumer-feign cloud: nacos: discovery: server-addr: 132.232.137.183:8848management: endpoints: web: exposure: include: "*" 启动工程通过浏览器访问 http://132.232.137.183:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 service-consumer-feign 的服务 这时打开 http://localhost:9092/hello/feign ，你会在浏览器上看到： 测试负载均衡 启动多个 service-provider 实例，效果图如下： 在浏览器上多次访问 http://localhost:9092/hello/feign ，浏览器交替显示 使用熔断器防止服务雪崩概述在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC相互调用，在 Spring Cloud 中可以用 RestTemplate + LoadBalanceClient 和 Feign来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 阿里巴巴开源了 Sentinel 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图： 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值 什么是 Sentinel随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性 Sentinel 的特征 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的 双十一大促流量 的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等 Feign 中使用 Sentinel如果要在您的项目中引入 Sentinel，使用 group ID 为 org.springframework.cloud 和 artifact ID 为 spring-cloud-starter-alibaba-sentinel 的 starter。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; Sentinel 适配了 Feign 组件。但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: sentinel: enabled: true 在 Service 中增加 fallback 指定类12345@FeignClient(value = "service-provider", fallback = ConsumerServiceFallback.class)public interface ConsumerService &#123; @GetMapping("/hello/&#123;message&#125;") String hello(@PathVariable("message")String message);&#125; 创建熔断器类并实现对应的 Feign 接口1234567@Componentpublic class ConsumerServiceFallback implements ConsumerService &#123; @Override public String hello(String message) &#123; return "服务器繁忙，请稍后重试"; &#125;&#125; 注意：一定要加上@component注解 测试熔断器此时我们关闭服务提供者 再次请求 http://localhost:9092/hello/feign 浏览器会显示： 使用熔断器仪表盘监控Sentinel 控制台Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 获取控制台 您可以从 release 页面 下载最新版本的控制台 jar 包。 您也可以从最新版本的源码自行构建 Sentinel 控制台： 下载 控制台 工程 使用以下命令将代码打包成一个 fat jar: mvn clean package 启动控制台Sentinel 控制台是一个标准的 SpringBoot 应用，以 SpringBoot 的方式运行 jar 包即可。 12# 使用源码自行构建jar包位置 sentinel-dashboard\targetjava -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 如若8080端口冲突，可使用 -Dserver.port=新端口 进行设置。 访问服务打开浏览器访问：http://127.0.0.1:8080/#/dashboard/home 配置控制台信息application.yml 配置文件中增加如下配置： 123456spring: cloud: sentinel: transport: port: 8719 dashboard: 127.0.0.1:8080 这里的 spring.cloud.sentinel.transport.port 端口配置会在应用对应的机器上启动一个 Http Server，该 Server 会与 Sentinel 控制台做交互。比如 Sentinel 控制台添加了 1 个限流规则，会把规则数据 push 给这个 Http Server 接收，Http Server 再将规则注册到 Sentinel 中 测试 Sentinel使用之前的 Feign 客户端，application.yml 完整配置如下： 123456789101112131415161718192021server: port: 9092spring: application: name: service-consumer-feign cloud: nacos: discovery: server-addr: 132.232.137.183:8848 sentinel: transport: port: 8719 dashboard: 127.0.0.1:8080management: endpoints: web: exposure: include: "*"feign: sentinel: enabled: true 注：由于 8719 端口已被 sentinel-dashboard 占用，不修改也能注册，会自动帮你在端口号上 + 1； 打开浏览器访问：http://127.0.0.1:8080/#/dashboard/home 此时会多一个名为 service-consumer-feign 的服务 使用路由网关统一访问接口什么是 Spring Cloud GatewaySpring Cloud Gateway 是 Spring 官方基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，Spring Cloud Gateway 旨在为微服务架构提供一种简单而有效的统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系中的网关，目标是替代 Netflix ZUUL，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 Spring Cloud Gateway 功能特征 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 Spring Cloud Gateway 工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑。 POM创建一个工程名为 cloud-alibaba-gateway 的服务提供者项目，pom.xml 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-gateway 依赖 特别注意 Spring Cloud Gateway 不使用 Web 作为服务器，而是 使用 WebFlux 作为服务器，Gateway 项目已经依赖了 starter-webflux，所以这里 千万不要依赖 starter-web 由于过滤器等功能依然需要 Servlet 支持，故这里还需要依赖 javax.servlet:javax.servlet-api Application12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class,args); &#125;&#125; application.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253spring: application: # 应用名称 name: cloud-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 132.232.137.183:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: 127.0.0.1:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.0.2.RELEASE/single/spring-cloud-gateway.html#gateway-route-filters） - id: SERVICE-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://service-consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: SERVICE-CONSUMER-FEIGN uri: lb://service-consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 目前无效feign: sentinel: enabled: truemanagement: endpoints: web: exposure: include: "*"# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 注意：请仔细阅读注释 测试访问依次运行 Nacos 服务、ServiceProviderApplication、ServiceConsumerApplication、ServiceConsumerFeignApplication、GatewayApplication 打开浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 浏览器显示 打开浏览器访问：http://localhost:9000/nacos-consumer-feign/hello/gateway 浏览器显示 注意：请求方式是 http://路由网关IP:路由网关Port/服务名/** 至此说明 Spring Cloud Gateway 的路由功能配置成功 使用路由网关的全局过滤功能概述全局过滤器作用于所有的路由，不需要单独配置，我们可以用它来实现很多统一化处理的业务需求，比如权限认证，IP 访问限制等等。 注意：Spring Cloud Finchley.SR2版默认引入 Spring Cloud Gateway 2.0.2.RELEASE 其文档并不完善，并且有些地方还要重新设计，这里仅提供一个基本的案例 详见：Spring Cloud Gateway Documentation 生命周期 Spring Cloud Gateway 基于 Project Reactor 和 WebFlux，采用响应式编程风格，打开它的 Filter 的接口 GlobalFilter 你会发现它只有一个方法 filter 创建全局过滤器实现 GlobalFilter, Ordered 接口并在类上增加 @Component 注解就可以使用过滤功能了，非常简单方便 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.collect.Maps;import org.apache.commons.lang3.StringUtils;import org.springframework.cloud.gateway.filter.GatewayFilter;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.http.HttpStatus;import org.springframework.http.server.reactive.ServerHttpResponse;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.HashMap;/** * @author by cheng * @description: 全局拦截器 * @data 2019/2/19 */@Componentpublic class ComsumerFilter implements GatewayFilter,Ordered&#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst("token"); if (StringUtils.isBlank(token))&#123; ServerHttpResponse response = exchange.getResponse(); // 封装错误信息 HashMap&lt;String, Object&gt; respData = Maps.newHashMap(); respData.put("code",401); respData.put("message","非法请求"); respData.put("cause","Token is empty"); try &#123; // 将信息转换为 JSON ObjectMapper objectMapper = new ObjectMapper(); byte[] data = objectMapper.writeValueAsBytes(respData); // 输出错误信息到页面 DataBuffer buffer = response.bufferFactory().wrap(data); response.setStatusCode(HttpStatus.UNAUTHORIZED); response.getHeaders().add("Content-Type", "application/json;charset=UTF-8"); return response.writeWith(Mono.just(buffer)); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; &#125; return chain.filter(exchange); &#125; /** * 设置过滤器的执行顺序 * @return */ @Override public int getOrder() &#123; return Ordered.LOWEST_PRECEDENCE; &#125;&#125; 测试过滤器浏览器访问：http://localhost:9000/service-consumer-feign/hello/globalFilter 网页显示 浏览器访问：http://localhost:9000/service-consumer-feign/hello/globalFilter?token=123456网页显示 附：Spring Cloud Gateway BenchmarkSpring 官方人员提供的网关基准测试报告 GitHub Proxy Avg Latency Avg Req/Sec/Thread gateway 6.61ms 3.24k linkered 7.62ms 2.82k zuul 12.56ms 2.09k none 2.09ms 11.77k 说明 这里的 Zuul 为 1.x 版本，是一个基于阻塞 IO 的 API Gateway Zuul 已经发布了 Zuul 2.x，基于 Netty，非阻塞的，支持长连接，但 Spring Cloud 暂时还没有整合计划 Linkerd 基于 Scala 实现的、目前市面上仅有的生产级别的 Service Mesh（其他诸如 Istio、Conduit 暂时还不能用于生产）。 Nacos Config 服务端初始化分布式配置中心在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件 Nacos ConfigNacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，您可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Spring Cloud Alibaba Nacos Config 是 Spring Cloud Config Server 和 Client 的替代方案，客户端和服务器上的概念与 Spring Environment 和 PropertySource 有着一致的抽象，在特殊的 bootstrap 阶段，配置被加载到 Spring 环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容 创建配置文件需要在 Nacos Server 中创建配置文件，我们依然采用 YAML 的方式部署配置文件，操作流程如下： 浏览器打开 http://132.232.137.183:8848/nacos ，访问 Nacos Server 新建配置文件，此处我们以之前创建的服务提供者项目为例 注意：Data ID 的默认扩展名为 .properties ，希望使用 YAML 配置，此处必须指明是 .yaml 发布成功后在 “配置列表” 一栏即可看到刚才创建的配置项 Nacos Config 客户端的使用POM此处我们以之前创建的服务提供者项目为例 在 pom.xml 中增加 org.springframework.cloud:spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 完整的 pom.xml 如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-service-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; bootstrap.properties创建名为 bootstrap.properties 的配置文件并删除之前创建的 application.yml 配置文件，由于已经在服务端配置，此处不再赘述 123456# 这里的应用名对应 Nacos Config 中的 Data ID，实际应用名称以配置中心的配置为准spring.application.name=service-provider-config# 指定查找名为 service-provider-config.yaml 的配置文件spring.cloud.nacos.config.file-extension=yaml# Nacos Server 的地址spring.cloud.nacos.config.server-addr=132.232.137:8848 注意：在之前的 Spring Cloud Netflix 课程中有提到过 Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 启动应用程序启动应用后我们可以通过日志看到，已经成功加载到了配置文件 配置的动态更新Nacos Config 也支持配置的动态更新，操作流程如下： 修改服务端配置，增加一个 user.name 的属性 修改 Controller ，增加一个请求方法，测试配置更新效果 12345678// 注入配置文件上下文@Autowiredprivate ConfigurableApplicationContext applicationContext;// 从上下文中读取配置@GetMapping("getname") public String getName()&#123; return "Hello " + applicationContext.getEnvironment().getProperty("user.name"); &#125; 通过浏览器访问该接口http://localhost:8081/getname，浏览器显示 修改服务端配置 此时观察控制台日志，你会发现我们已经成功刷新了配置 刷新浏览器，浏览器显示 注意：你可以使用 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新 Nacos Config 多环境的配置Spring Boot Profile我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar cloud-alibaba-service-provider-1.0.0-SNAPSHOT.jar --spring.profiles.active=prod Nacos Config Profilespring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataid 为 ${spring.application.name}.${file-extension:properties} 为前缀的基础配置，还加载了 dataid 为 ${spring.application.name}-${profile}.${file-extension:properties} 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过 Spring 提供的 ${spring.profiles.active} 这个配置项来配置。 此处我们以之前创建的服务提供者项目为例 在 Nacos Server 中增加配置增加一个名为 service-provider-config-prod.yaml 的配置 注意：此时，我将配置文件中的端口由 8081 -&gt; 8082 在项目中增加配置增加一个名为 bootstrap-prod.properties 的配置文件，内容如下： 1234spring.profiles.active=prodspring.application.name=service-provider-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848 主要增加了 spring.profiles.active=prod 配置，用于指定访问 Nacos Server 中的 nacos-provider-config-prod.yaml 配置 启动应用程序此时我们有两个配置文件，分别为 bootstrap.properties 和 bootstrap-prod.properties ，我们需要指定启动时加载哪一个配置文件，操作流程如下： Run -&gt; Edit Configurations.. 设置需要激活的配置 观察日志，判断是否成功加载配置 Spring Cloud Alibaba 链路追踪什么是链路追踪微服务架构是通过业务来划分服务的，使用 REST 调用。对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。 随着服务的越来越多，对调用链的分析会越来越复杂。它们之间的调用关系也许如下： 面对以上情况，我们就需要一些可以帮助理解系统行为、用于分析性能问题的工具，以便发生故障的时候，能够快速定位和解决问题，这就是所谓的 APM（应用性能管理） 什么是 SkyWalking目前主要的一些 APM 工具有: Cat、Zipkin、Pinpoint、SkyWalking；Apache SkyWalking 是观察性分析平台和应用性能管理系统。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 Skywalking Agent： 使用 JavaAgent 做字节码植入，无侵入式的收集，并通过 HTTP 或者 gRPC 方式发送数据到 SkyWalking Collector。 SkyWalking Collector： 链路数据收集器，对 agent 传过来的数据进行整合分析处理并落入相关的数据存储中。 Storage： SkyWalking 的存储，时间更迭，SW 已经开发迭代到了 6.x 版本，在 6.x 版本中支持以 ElasticSearch(支持 6.x)、Mysql、TiDB、H2、作为存储介质进行数据存储。 UI： Web 可视化平台，用来展示落地的数据。 SkyWalking 功能特性 多种监控手段，语言探针和服务网格(Service Mesh) 多语言自动探针，Java，.NET Core 和 Node.JS 轻量高效，不需要大数据 模块化，UI、存储、集群管理多种机制可选 支持告警 优秀的可视化方案 SkyWalking 服务端配置基于 Docker 安装 ElasticSearch在 为什么需要链路追踪 章节中介绍过 SkyWalking 存储方案有多种，官方推荐的方案是 ElasticSearch ，所以我们需要先安装 ElasticSearch。 docker-compose.yml 1234567891011version: '3'services: elasticsearch: image: wutang/elasticsearch-shanghai-zone:6.3.2 container_name: elasticsearch restart: always ports: - 9200:9200 - 9300:9300 environment: cluster.name: elasticsearch 其中，9200 端口号为 SkyWalking 配置 ElasticSearch 所需端口号，cluster.name为 SkyWalking 配置 ElasticSearch 集群的名称 测试是否启动成功浏览器访问 http://elasticsearchIP:9200/ ，浏览器返回如下信息即表示成功启动 下载并启动 SkyWalking官方已经为我们准备好了编译过的服务端版本，下载地址为 http://skywalking.apache.org/downloads/，这里我们需要下载 6.x releases 版本 配置 SkyWalking下载完成后解压缩，进入 apache-skywalking-apm-incubating/config 目录并修改 application.yml 配置文件 这里需要做三件事： 注释 H2 存储方案 启用 ElasticSearch 存储方案 修改 ElasticSearch 服务器地址 启动 SkyWalking修改完配置后，进入 apache-skywalking-apm-incubating\bin 目录，运行 startup.bat 启动服务端 通过浏览器访问 http://localhost:8080 出现如下界面即表示启动成功 默认的用户名密码为：admin/admin，登录成功后，效果如下图 SkyWalking 客户端配置Java Agent 服务器探针参考官网给出的帮助 Setup java agent，我们需要使用官方提供的探针为我们达到监控的目的，按照实际情况我们需要实现三种部署方式 IDEA 部署探针 Java 启动方式部署探针（我们是 Spring Boot 应用程序，需要使用 java -jar 的方式启动应用） Docker 启动方式部署探针（需要做到一次构建到处运行的持续集成效果，本章节暂不提供解决方案，到后面的实战环节再实现） 探针文件在 apache-skywalking-apm-incubating/agent 目录下 IDEA 部署探针继续之前的案例项目，创建一个名为 cloud-external-skywalking 的目录，并将 agent 整个目录拷贝进来 修改项目的 VM 运行参数，点击菜单栏中的 Run -&gt; EditConfigurations...，此处我们以 nacos-provider 项目为例，修改参数如下 123-javaagent:H:\code\cloud-alibaba\cloud-external-skywalking\agent\skywalking-agent.jar-Dskywalking.agent.service_name=service-provider-Dskywalking.collector.backend_service=localhost:11800 -javaagent：用于指定探针路径 -Dskywalking.agent.service_name：用于重写 agent/config/agent.config 配置文件中的服务名 -Dskywalking.collector.backend_service：用于重写 agent/config/agent.config 配置文件中的服务地址 Java 启动方式1java -javaagent:H:\code\cloud-alibaba\cloud-external-skywalking\agent\skywalking-agent.jar -Dskywalking.agent.service_name=service-provider -Dskywalking.collector.backend_service=localhost:11800 -jar yourApp.jar 测试监控启动 service-provider 项目，通过观察日志可以发现，已经成功加载探针 访问之前写好的接口 http://localhost:8081/hello/skywalking 之后再刷新 SkyWalking Web UI，你会发现 Service 与 Endpoint 已经成功检测到了 至此，表示 SkyWalking 链路追踪配置成功 SkyWalking Trace 监控SkyWalking 通过业务调用监控进行依赖分析，提供给我们了服务之间的服务调用拓扑关系、以及针对每个 Endpoint 的 Trace 记录 调用链路监控 点击 Trace 菜单，进入追踪页 点击 Trace ID 展开详细信息 上图展示了一次正常的响应，总响应时间为 444ms 共有一个 Span（基本工作单元，表示一次完整的请求，包含响应，即请求并响应） Span /hello/{message} 说明如下： Duration：响应时间 444 毫秒 component：组件类型为 SpringMVC url：请求地址 http.method：请求类型 服务性能指标监控 点击 Service 菜单，进入服务性能指标监控页 选择希望监控的服务 Avg SLA： 服务可用性（主要是通过请求成功与失败次数来计算） CPM： 每分钟调用次数 Avg Response Time： 平均响应时间 点击 More Server Details... 还可以查看详细信息 上图中展示了服务在一定时间范围内的相关数据，包括： 服务可用性指标 SLA 每分钟平均响应数 平均响应时间 服务进程 PID 服务所在物理机的 IP、Host、OS 运行时 CPU 使用率 运行时堆内存使用率 运行时非堆内存使用率 GC 情况 附：Maven Assembly 插件 什么是 Assembly Plugin Assembly 插件目的是提供一个把工程依赖元素、模块、网站文档等其他文件存放到单个归档文件里 Assembly 支持的归档文件类型 zip tar.gz tar.bz2 jar dir war 使用步骤 此处以将 SkyWalking 探针打包为 tar.gz 为例，为后期持续集成时构建 Docker 镜像做好准备 POM 在 pom.xml 中增加插件配置 123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;!-- 配置执行器 --&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;!-- 绑定到 package 生命周期阶段上 --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- 只运行一次 --&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;finalName&gt;skywalking&lt;/finalName&gt; &lt;descriptors&gt; &lt;!-- 配置描述文件路径 --&gt; &lt;descriptor&gt;src/main/resources/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; assembly.xml 创建 src/main/resources/assembly.xml 配置文件 1234567891011121314151617181920212223242526&lt;assembly&gt; &lt;id&gt;6.0.0-Beta&lt;/id&gt; &lt;formats&gt; &lt;!-- 打包的文件格式，支持 zip、tar.gz、tar.bz2、jar、dir、war --&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;!-- tar.gz 压缩包下是否生成和项目名相同的根目录，有需要请设置成 true --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;!-- 是否把本项目添加到依赖文件夹下，有需要请设置成 true --&gt; &lt;useProjectArtifact&gt;false&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;!-- 将 scope 为 runtime 的依赖包打包 --&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;!-- 设置需要打包的文件路径 --&gt; &lt;directory&gt;agent&lt;/directory&gt; &lt;!-- 打包后的输出路径 --&gt; &lt;outputDirectory&gt;&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 打包 12mvn clean packagemvn clean install package：会在 target 目录下创建名为 skywalking-6.0.0-Beta.tar.gz 的压缩包 install：会在本地仓库目录下创建名为 hello-spring-cloud-external-skywalking-1.0.0-SNAPSHOT-6.0.0-Beta.tar.gz 的压缩包 Spring Cloud Alibaba 异步通信消息队列的流派什么是 MQMessage Queue（MQ），消息队列中间件。很多人都说：MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是——MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。MQ 真正的目的是为了通讯，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。一个分布式系统中两个模块之间通讯要么是 HTTP，要么是自己开发的 TCP，但是这两种协议其实都是原始的协议。HTTP 协议很难实现两端通讯——模块 A 可以调用 B，B 也可以主动调用 A，如果要做到这个两端都要背上 WebServer，而且还不支持长连接（HTTP 2.0 的库根本找不到）。TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者/消费者模型。MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。它定义了两个对象——发送数据的叫生产者；接收数据的叫消费者， 提供一个 SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议 有 Broker 的 MQ这个流派通常有一台服务器作为 Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker 则把消息主动推送给消费者（或者消费者主动轮询） 重 Topickafka、JMS（ActiveMQ）就属于这个流派，生产者会发送 key 和数据到 Broker，由 Broker 比较 key 之后决定给哪个消费者。这种模式是我们最常见的模式，是我们对 MQ 最多的印象。在这种模式下一个 topic 往往是一个比较大的概念，甚至一个系统中就可能只有一个 topic，topic 某种意义上就是 queue，生产者发送 key 相当于说：“hi，把数据放到 key 的队列中” 如上图所示，Broker 定义了三个队列，key1，key2，key3，生产者发送数据的时候会发送 key1 和 data，Broker 在推送数据的时候则推送 data（也可能把 key 带上）。 虽然架构一样但是 kafka 的性能要比 jms 的性能不知道高到多少倍，所以基本这种类型的 MQ 只有 kafka 一种备选方案。如果你需要一条暴力的数据流（在乎性能而非灵活性）那么 kafka 是最好的选择 轻 Topic这种的代表是 RabbitMQ（或者说是 AMQP）。生产者发送 key 和数据，消费者定义订阅的队列，Broker 收到数据之后会通过一定的逻辑计算出 key 对应的队列，然后把数据交给队列 这种模式下解耦了 key 和 queue，在这种架构中 queue 是非常轻量级的（在 RabbitMQ 中它的上限取决于你的内存），消费者关心的只是自己的 queue；生产者不必关心数据最终给谁只要指定 key 就行了，中间的那层映射在 AMQP 中叫 exchange（交换机）。 AMQP 中有四种 exchange Direct exchange：key 就等于 queue Fanout exchange：无视 key，给所有的 queue 都来一份 Topic exchange：key 可以用“宽字符”模糊匹配 queue Headers exchange：无视 key，通过查看消息的头部元数据来决定发给那个 queue（AMQP 头部元数据非常丰富而且可以自定义） 这种结构的架构给通讯带来了很大的灵活性，我们能想到的通讯方式都可以用这四种 exchange 表达出来。如果你需要一个企业数据总线（在乎灵活性）那么 RabbitMQ 绝对的值得一用 无 Broker 的 MQ无 Broker 的 MQ 的代表是 ZeroMQ。该作者非常睿智，他非常敏锐的意识到——MQ 是更高级的 Socket，它是解决通讯问题的。所以 ZeroMQ 被设计成了一个“库”而不是一个中间件，这种实现也可以达到——没有 Broker 的目的 节点之间通讯的消息都是发送到彼此的队列中，每个节点都既是生产者又是消费者。ZeroMQ 做的事情就是封装出一套类似于 Socket 的 API 可以完成发送数据，读取数据 ZeroMQ 其实就是一个跨语言的、重量级的 Actor 模型邮箱库。你可以把自己的程序想象成一个 Actor，ZeroMQ 就是提供邮箱功能的库；ZeroMQ 可以实现同一台机器的 RPC 通讯也可以实现不同机器的 TCP、UDP 通讯，如果你需要一个强大的、灵活、野蛮的通讯能力，别犹豫 ZeroMQ 附：Queue 和 Topic 的区别 Queue： 一个发布者发布消息，下面的接收者按队列顺序接收，比如发布了 10 个消息，两个接收者 A,B 那就是 A,B 总共 会收到 10 条消息，不重复。 Topic： 一个发布者发布消息，有两个接收者 A,B 来订阅，那么发布了 10 条消息，A,B 各收到 10 条消息。 类型 Topic Queue 概要 Publish Subscribe Messaging 发布订阅消息 Point-to-Point 点对点 有无状态 Topic 数据默认不落地，是无状态的。 Queue 数据默认会在 MQ 服务器上以文件形式保存，比如 ActiveMQ 一般保存在 $AMQ_HOME\data\kr-store\data下面。也可以配置成 DB 存储。 完整性保障 并不保证 Publisher 发布的每条数据，Subscriber 都能接受到。 Queue 保证每条数据都能被 Receiver 接收。 消息是否会丢失 一般来说 Publisher 发布消息到某一个 Topic 时，只有正在监听该 Topic 地址的 Sub 能够接收到消息；如果没有 Sub 在监听，该 Topic 就丢失了。 Sender 发送消息到目标 Queue，Receiver 可以异步接收这个 Queue 上的消息。Queue 上的消息如果暂时没有 Receiver 来取，也不会丢失。 消息发布接收策略 一对多的消息发布接收策略，监听同一个 Topic 地址的多个 Sub 都能收到 Publisher 发送的消息。Sub 接收完通知 MQ 服务器 一对一的消息发布接收策略，一个 Sender 发送的消息，只能有一个 Receiver 接收。Receiver 接收完后，通知 MQ 服务器已接收，MQ 服务器对 Queue 里的消息采取删除或其他操作。 RocketMQ 简介概述消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势： 削峰填谷： 主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题 系统解耦： 解决不同重要程度、不同能力级别系统之间依赖导致一死全死 提升性能： 当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统 蓄流压测： 线上有些链路不好压测，可以通过堆积一定量消息再放开来压测 RocketMQApache Alibaba RocketMQ 是一个消息中间件。消息中间件中有两个角色：消息生产者和消息消费者。RocketMQ 里同样有这两个概念，消息生产者负责创建消息并发送到 RocketMQ 服务器，RocketMQ 服务器会将消息持久化到磁盘，消息消费者从 RocketMQ 服务器拉取消息并提交给应用消费 RocketMQ 特点RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： 支持严格的消息顺序 支持 Topic 与 Queue 两种模式 亿级消息堆积能力 比较友好的分布式特性 同时支持 Push 与 Pull 方式消费消息 历经多次天猫双十一海量消息考验 RocketMQ 优势目前主流的 MQ 主要是 RocketMQ、kafka、RabbitMQ，其主要优势有： 支持事务型消息（消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 不支持） 支持结合 RocketMQ 的多个系统之间数据最终一致性（多方事务，二方事务是前提） 支持 18 个级别的延迟消息（RabbitMQ 和 Kafka 不支持） 支持指定次数和时间间隔的失败消息重发（Kafka 不支持，RabbitMQ 需要手动确认） 支持 Consumer 端 Tag 过滤，减少不必要的网络传输（RabbitMQ 和 Kafka 不支持） 支持重复消费（RabbitMQ 不支持，Kafka 支持） 消息队列对比参照表 基于 Docker 安装 RocketMQdocker-compose.yml注意：启动 RocketMQ Server + Broker + Console 至少需要 2G 内存 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: '3.5'services: rmqnamesrv: image: foxiswho/rocketmq:server container_name: rmqnamesrv ports: - 9876:9876 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store networks: rmq: aliases: - rmqnamesrv rmqbroker: image: foxiswho/rocketmq:broker container_name: rmqbroker ports: - 10909:10909 - 10911:10911 volumes: - ./data/logs:/opt/logs - ./data/store:/opt/store - ./data/brokerconf/broker.conf:/etc/rocketmq/broker.conf environment: NAMESRV_ADDR: "rmqnamesrv:9876" JAVA_OPTS: " -Duser.home=/opt" JAVA_OPT_EXT: "-server -Xms128m -Xmx128m -Xmn128m" command: mqbroker -c /etc/rocketmq/broker.conf depends_on: - rmqnamesrv networks: rmq: aliases: - rmqbroker rmqconsole: image: styletang/rocketmq-console-ng container_name: rmqconsole ports: - 8080:8080 environment: JAVA_OPTS: "-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false" depends_on: - rmqnamesrv networks: rmq: aliases: - rmqconsolenetworks: rmq: name: rmq driver: bridge broker.confRocketMQ Broker 需要一个配置文件，按照上面的 Compose 配置，我们需要在 ./data/brokerconf/ 目录下创建一个名为 broker.conf 的配置文件，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the &quot;License&quot;); you may not use this file except in compliance with# the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# 所属集群名字brokerClusterName=DefaultCluster# broker 名字，注意此处不同的配置文件填写的不一样，如果在 broker-a.properties 使用: broker-a,# 在 broker-b.properties 使用: broker-bbrokerName=broker-a# 0 表示 Master，&gt; 0 表示 SlavebrokerId=0# nameServer地址，分号分割# namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876# 启动IP,如果 docker 报 com.alibaba.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;192.168.0.120:10909&gt; failed# 解决方式1 加上一句 producer.setVipChannelEnabled(false);，解决方式2 brokerIP1 设置宿主机IP，不要使用docker 内部IP# brokerIP1=192.168.0.253# 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4# 是否允许 Broker 自动创建 Topic，建议线下开启，线上关闭 ！！！这里仔细看是 false，false，falseautoCreateTopicEnable=true# 是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true# Broker 对外服务的监听端口listenPort=10911# 删除文件时间点，默认凌晨4点deleteWhen=04# 文件保留时间，默认48小时fileReservedTime=120# commitLog 每个文件的大小默认1GmapedFileSizeCommitLog=1073741824# ConsumeQueue 每个文件默认存 30W 条，根据业务情况调整mapedFileSizeConsumeQueue=300000# destroyMapedFileIntervalForcibly=120000# redeleteHangedFileInterval=120000# 检测物理文件磁盘空间diskMaxUsedSpaceRatio=88# 存储路径# storePathRootDir=/home/ztztdata/rocketmq-all-4.1.0-incubating/store# commitLog 存储路径# storePathCommitLog=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/commitlog# 消费队列存储# storePathConsumeQueue=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/consumequeue# 消息索引存储路径# storePathIndex=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/index# checkpoint 文件存储路径# storeCheckpoint=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/checkpoint# abort 文件存储路径# abortFile=/home/ztztdata/rocketmq-all-4.1.0-incubating/store/abort# 限制的消息大小maxMessageSize=65536# flushCommitLogLeastPages=4# flushConsumeQueueLeastPages=2# flushCommitLogThoroughInterval=10000# flushConsumeQueueThoroughInterval=60000# Broker 的角色# - ASYNC_MASTER 异步复制Master# - SYNC_MASTER 同步双写Master# - SLAVEbrokerRole=ASYNC_MASTER# 刷盘方式# - ASYNC_FLUSH 异步刷盘# - SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH# 发消息线程池数量# sendMessageThreadPoolNums=128# 拉消息线程池数量# pullMessageThreadPoolNums=128 RocketMQ 控制台访问 http://rmqIP:8080 登入控制台 RocketMQ 生产者概述RocketMQ 是一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 由于本教程整个案例基于 Spring Cloud，故我们采用 Spring Cloud Stream 完成一次发布和订阅 官方教程 Spring Cloud StreamSpring Cloud Stream 是一个用于构建基于消息的微服务应用框架。它基于 Spring Boot 来创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Spring Cloud Stream 提供了消息中间件配置的统一抽象，推出了 publish-subscribe、consumer groups、partition 这些统一的概念。 Spring Cloud Stream 内部有两个概念： Binder： 跟外部消息中间件集成的组件，用来创建 Binding，各消息中间件都有自己的 Binder 实现。 Binding： 包括 Input Binding 和 Output Binding。 Binding 在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，实现了开发者只需使用应用程序的 Provider 或 Consumer 生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。 解决连接超时问题我们采用 Docker 部署了 RocketMQ 服务，此时 RocketMQ Broker 暴露的地址和端口(10909，10911)是基于容器的，会导致我们开发机无法连接，从而引发 org.apache.rocketmq.remoting.exception.RemotingTooMuchRequestException: sendDefaultImpl call timeout 异常 注意下图中的 IP 地址，这个是容器的 IP，开发机与容器不在一个局域网所以无法连接。 解决方案是在 broker.conf 配置文件中增加 brokerIP1=宿主机IP 即可 POM创建一个工程名为 cloud-alibaba-rocketmq-provider RocketMQ 生产者项目,主要增加了 org.springframework.cloud:spring-cloud-starter-stream-rocketmq 依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-rocketmq-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 消息生产者服务12345678910111213141516package club.codeopen.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;import org.springframework.stereotype.Service;@Servicepublic class ProviderService &#123; @Autowired private MessageChannel output; public void send(String message) &#123; output.send(MessageBuilder.withPayload(message).build()); &#125;&#125; Application配置 Output(Source.class) 的 Binding 信息并配合 @EnableBinding 注解使其生效 1234567891011121314151617181920212223242526272829package club.codeopen;import club.codeopen.service.ProviderService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;@SpringBootApplication@EnableBinding(&#123;Source.class&#125;)public class RocketMQProviderApplication implements CommandLineRunner &#123; @Autowired private ProviderService providerService; public static void main(String[] args) &#123; SpringApplication.run(RocketMQProviderApplication.class, args); &#125; /** * 实现了 CommandLineRunner 接口，只是为了 Spring Boot 启动时执行任务，不必特别在意 * @param args * @throws Exception */ @Override public void run(String... args) throws Exception &#123; providerService.send("Hello RocketMQ"); &#125;&#125; application.yml123456789101112131415161718192021spring: application: name: rocketmq-provider cloud: stream: rocketmq: binder: # RocketMQ 服务器地址 namesrv-addr: 192.168.129.149:9876 bindings: # 这里是个 Map 类型参数，&#123;&#125; 为 YAML 中 Map 的行内写法 output: &#123;destination: test-topic, content-type: application/json&#125;server: port: 9093management: endpoints: web: exposure: include: '*' 运行成功后即可在 RocketMQ 控制台的 消息 列表中选择 test-topic 主题即可看到发送的消息 RocketMQ 消费者POM创建一个工程名为 cloud-alibaba-rocketmq-consumer RocketMQ 消费者项目,主要增加了 org.springframework.cloud:spring-cloud-starter-stream-rocketmq 依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../cloud-alibaba-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;cloud-alibaba-rocketmq-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 消息消费者服务主要使用 @StreamListener(&quot;input&quot;) 注解来订阅从名为 input 的 Binding 中接收的消息 12345678910111213package club.codeopen.receive;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.stereotype.Service;@Servicepublic class ConsumerReceive &#123; @StreamListener("input") public void receiveInput(String message) &#123; System.out.println("Receive input: " + message); &#125;&#125; Application配置 Input(Sink.class) 的 Binding 信息并配合 @EnableBinding 注解使其生效 1234567891011121314package club.codeopen;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Sink;@SpringBootApplication@EnableBinding(&#123;Sink.class&#125;)public class RocketMQConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RocketMQConsumerApplication.class, args); &#125;&#125; application.yml123456789101112131415161718192021spring: application: name: rocketmq-consumer cloud: stream: rocketmq: binder: namesrv-addr: 192.168.129.149:9876 bindings: input: &#123;consumer.orderly: true&#125; bindings: input: &#123;destination: test-topic, content-type: text/plain, group: test-group, consumer.maxAttempts: 1&#125;server: port: 9094management: endpoints: web: exposure: include: '*' 运行成功后即可在控制台接收到消息：Receive input: Hello RocketMQ RocketMQ 自定义 Binding概述在实际生产中，我们需要发布和订阅的消息可能不止一种 Topic ，故此时就需要使用自定义 Binding 来帮我们实现多 Topic 的发布和订阅功能 生产者自定义 Output 接口，代码如下： 1234567public interface MySource &#123; @Output("output1") MessageChannel output1(); @Output("output2") MessageChannel output2();&#125; 发布消息的案例代码如下： 123456@Autowiredprivate MySource source;public void send(String msg) throws Exception &#123; source.output1().send(MessageBuilder.withPayload(msg).build());&#125; 消费者自定义 Input 接口，代码如下： 12345678910111213public interface MySink &#123; @Input("input1") SubscribableChannel input1(); @Input("input2") SubscribableChannel input2(); @Input("input3") SubscribableChannel input3(); @Input("input4") SubscribableChannel input4();&#125; 接收消息的案例代码如下： 1234@StreamListener("input1")public void receiveInput1(String receiveMsg) &#123; System.out.println("input1 receive: " + receiveMsg);&#125; Application配置 Input 和 Output 的 Binding 信息并配合 @EnableBinding 注解使其生效，代码如下： 1234567@SpringBootApplication@EnableBinding(&#123; MySource.class, MySink.class &#125;)public class RocketMQApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RocketMQApplication.class, args); &#125;&#125; application.yml 生产者 1234567891011spring: application: name: rocketmq-provider cloud: stream: rocketmq: binder: namesrv-addr: 192.168.129.149:9876 bindings: output1: &#123;destination: test-topic1, content-type: application/json&#125; output2: &#123;destination: test-topic2, content-type: application/json&#125; 消费者 123456789101112131415spring: application: name: rocketmq-consumer cloud: stream: rocketmq: binder: namesrv-addr: 192.168.129.149:9876 bindings: input: &#123;consumer.orderly: true&#125; bindings: input1: &#123;destination: test-topic1, content-type: text/plain, group: test-group, consumer.maxAttempts: 1&#125; input2: &#123;destination: test-topic1, content-type: text/plain, group: test-group, consumer.maxAttempts: 1&#125; input3: &#123;destination: test-topic2, content-type: text/plain, group: test-group, consumer.maxAttempts: 1&#125; input4: &#123;destination: test-topic2, content-type: text/plain, group: test-group, consumer.maxAttempts: 1&#125;]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Compose安装ElasticSearch单机版]]></title>
    <url>%2F2019%2F02%2F19%2FElasticsearch%2FDocker-Compose%E5%AE%89%E8%A3%85ElasticSearch%E5%8D%95%E6%9C%BA%E7%89%88%2F</url>
    <content type="text"><![CDATA[系统调优 修改/etc/security/limits.conf ，追加内容 12* soft nofile 65536* hard nofile 65536 nofile是单个进程允许打开的最大文件个数 soft nofile 是软限制 hard nofile是硬限制 修改/etc/sysctl.conf，追加内容 1vm.max_map_count=655360 限制一个进程可以拥有的VMA(虚拟内存区域)的数量 执行下面命令 修改内核参数马上生效 1sysctl -p 编写docker-compose.yml文件 1234567891011121314151617181920212223242526version: &apos;3&apos;services: elasticsearch: restart: always image: elasticsearch:5.6.13 container_name: elasticsearch environment: - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 volumes: - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - ./plugins:/usr/share/elasticsearch/plugins - ./data:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 networks: - esnetvolumes: data:networks: esnet: 编写elasticsearch.yml 123456789# 5.6.13 版本http.host: 0.0.0.0# Uncomment the following lines for a production cluster deploymenttransport.host: 0.0.0.0#discovery.zen.minimum_master_nodes: 1http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 123456789# 6.5.3 版本network.bind_host: 0.0.0.0cluster.name: elastic-clusternetwork.host: 0.0.0.0# discovery.zen.minimum_master_nodes: 1# bootstrap.memory_lock: truediscovery.type: single-nodehttp.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 启动容器docker-compose up -d]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Druid并开启监控]]></title>
    <url>%2F2019%2F02%2F13%2Fspring-boot%2FSpringBoot%20%E6%95%B4%E5%90%88%20Druid%2F</url>
    <content type="text"><![CDATA[引入依赖在pom.xml文件中引入druid-spring-boot-starter 依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 引入数据库连接依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 配置 application.yml在 application.yml 中配置数据库连接 1234567891011spring: datasource: druid: url: jdbc:mysql://ip:port/dbname?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true driver-class-name: com.mysql.jdbc.Driver 配置Druid监控 编写druid监控配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @author by cheng * @Classname DruidConfig * @Description druid 配置 * @Date 2019/2/12 13:38 */@Configurationpublic class DruidConfig &#123; @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new StatViewServlet(),"/druid/*"); // 白名单 servletRegistrationBean.addInitParameter("allow", "127.0.0.1"); // IP 黑名单 (存在共同是， deny 优先于 allow ) servletRegistrationBean.addInitParameter("deny", "192.168.0.103"); // 登录查看详细的账号、密码 servletRegistrationBean.addInitParameter("loginUsername","druid"); servletRegistrationBean.addInitParameter("loginPassword","123456"); // 是否能够重置数据 servletRegistrationBean.addInitParameter("resetEnable","false"); return servletRegistrationBean; &#125; @Bean public FilterRegistrationBean statFilter()&#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter()); // 添加过滤规则 filterRegistrationBean.addUrlPatterns("/*"); // 添加不需要忽略的格式信息 filterRegistrationBean.addInitParameter("exclusions","*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid2/*"); return filterRegistrationBean; &#125; @Bean PersistenceExceptionTranslationPostProcessor persistenceExceptionTranslationPostProcessor()&#123; return new PersistenceExceptionTranslationPostProcessor(); &#125; /** * 配置数据库的基本连接信息 * @return */ @Bean(name = "dataSource") @Primary @ConfigurationProperties(prefix = "spring.datasource") // 可以在 application.yml 中直接获取 public DataSource dataSource()&#123; return DataSourceBuilder.create().type(DruidDataSource.class).build(); &#125; @Bean public SqlSessionFactoryBean sqlSessionFactoryBean(@Qualifier("dataSource")DataSource dataSource) throws IOException &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dataSource); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); bean.setMapperLocations(resolver.getResources("classpath:/mapper/*.xml")); return bean; &#125;&#125; 访问druid监控页面 http://127.0.0.1:8080/druid/login.html 用户名、密码可自定义 用户名：druid 密码：123456]]></content>
      <categories>
        <category>SpringBoot</category>
        <category>Druid</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA 常用快捷键]]></title>
    <url>%2F2019%2F02%2F13%2FdevNote%2FIntellij%20IDEA%20%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Intellij IDEA 常用快捷键 智能提示 设置为Alt + / 代码模板生成 psvm sout ifn 生成getting、setting方法等 alt + Insert 编辑快捷键 删除行：ctrl + y 复制行：ctrl + d 注释行：ctrl + / 自动按照语法选中代码：ctrl + w 反向按照语法撤销选中代码：ctrl + shrft + w 前后单词移动光标：ctrl + left/right 查找 查找类或资源，提供模糊品牌：ctrl + n 全局搜索：双击 shift 内容搜索：ctrl + shift + f 代码格式化 格式化 import：ctrl + alt + o 格式化代码： ctrl + alt + l 切换标签窗体：ctrl + tab 选择最近打开的文件：ctrl + e 打开最近编辑过的文件：ctrl + shift + e 自我修复：alt + enter 撤销：ctrl + z 取消撤销：ctrl + shift +z]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用maven-tomcat插件实现tomcat热部署]]></title>
    <url>%2F2019%2F02%2F13%2FdevNote%2F%E4%BD%BF%E7%94%A8maven-tomcat%E6%8F%92%E4%BB%B6%E5%AE%9E%E7%8E%B0tomcat%E7%83%AD%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[配置tomcat开启manager项目 在tomcat目录中修改 vi config/tomcat-users.xml文件，在&lt;/tomcat-users&gt;前添加 123&lt;role rolename="manager-gui"/&gt;&lt;role rolename="manager-script"/&gt;&lt;user username="tomcat" password="managepwd" roles="manager-gui,manager-script"/&gt; 启动 tomcat 1./bin/startup.sh 点击Manager App出现登录弹窗 输入上面配置的用户名：tomcat，密码managepwd回车即可进入manager项目 集成tomcat插件配置pom.xml文件 123456789101112131415161718192021&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;!-- 控制tomcat端口号,部署到服务器时失效，以服务器启动的 tomcat 为准 --&gt; &lt;port&gt;80&lt;/port&gt; &lt;!-- 项目发布到tomcat后的名称 --&gt; &lt;!-- / 相当于把项目发布名称为ROOT --&gt; &lt;path&gt;/&lt;/path&gt; &lt;!-- 用户名和密码均以服务器上的 tomcat 配置为准 --&gt; &lt;username&gt;tomcat&lt;/username&gt; &lt;password&gt;managepwd&lt;/password&gt; &lt;!-- IP 以自己为准 --&gt; &lt;url&gt;http://132.232.137.183:8080/manager/text&lt;/url&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 部署项目 点击Add configuration 配置启动脚本 因为/对应的项目是ROOT文件，已存在，因此我们直接使用tomcat7:redeploy 点击Apply-&gt;OK，然后RUN 在webapp目录下新增WEB-INF/web.xml文件，不然会报错123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app version="3.0" xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"&gt;&lt;/web-app&gt; 然后重新RUN验证即可访问http://132.232.137.183:8080/]]></content>
      <categories>
        <category>maven-tomcat</category>
      </categories>
      <tags>
        <tag>maven-tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next第三方服务集成]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%20Next%E7%AC%AC%E4%B8%89%E6%96%B9%E6%9C%8D%E5%8A%A1%E9%9B%86%E6%88%90%2F</url>
    <content type="text"><![CDATA[评论系统NexT 支持多款评论系统(大多数由于种种原因被劝退)。 如需取消某个 页面/文章 的评论，在 md 文件的 front-matter 中增加 comments: false 说几个勉强可以用的吧 来必力 由 asmoker 贡献（站长使用ing）登陆 来必力 获取你的 LiveRe UID。 编辑 主题配置文件， 编辑 livere_uid 字段，设置如下： 1livere_uid: #your livere_uid Gitment github集成的评论系统，推荐使用，一般应该不会被墙吧，哈哈1234567891011121314151617181920212223242526- 注册 OAuth Application - [点击此处](https://github.com/settings/applications/new) 来注册一个新的 OAuth Application。其他内容可以随意填写，但要确保填入正确的 callback URL（一般是评论页面对应的域名，如站长网站 `https://www.codeopen.club`）。 - 你会得到一个 `client ID` 和一个 `client secret`，这个将被用于之后的用户登录。- 引入 Gitment 将下面的代码添加到你的页面： ~~~html &lt;div id=&quot;container&quot;&gt;&lt;/div&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://imsun.github.io/gitment/style/default.css&quot;&gt; &lt;script src=&quot;https://imsun.github.io/gitment/dist/gitment.browser.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var gitment = new Gitment(&#123; id: &apos;页面 ID&apos;, // 可选。默认为 location.href owner: &apos;你的 GitHub ID&apos;, repo: &apos;存储评论的 repo&apos;, oauth: &#123; client_id: &apos;你的 client ID&apos;, client_secret: &apos;你的 client secret&apos;, &#125;, &#125;) gitment.render(&apos;container&apos;) &lt;/script&gt; 注意，上述代码引用的 Gitment 将会随着开发变动。如果你希望始终使用最新的界面与特性即可引入上述代码。 如果你希望引用确定版本的 Gitment，则应该使用 npm 进行安装。 1$ npm install --save gitment 初始化评论 修改主题配置文件,找到配置文件中gitment节点，示例如下： 1234567891011gitment: enable: true mint: true # RECOMMEND, A mint on Gitment, to support count, language and proxy_gateway count: true # Show comments count in post meta area lazy: false # Comments lazy loading with a button cleanly: false # Hide 'Powered by ...' on footer, and more language: zh-Hans # Force language, or auto switch by theme github_user: 填写你的github用户名 github_repo: 填写你的存储评论的仓库的git地址(HTTP) client_id: 填写刚刚注册OAuth Application的client ID client_secret: 填写刚刚注册OAuth Application的client secret DISQUS(不建议使用，在墙内你懂的)Next版本&gt;=5.1.1编辑 主题配置文件， 将 disqus 下的 enable 设定为 true，同时提供您的 shortname。count 用于指定是否显示评论数量。 1234disqus: enable: false shortname: count: true Next版本&lt;5.1.1编辑 主题配置文件，设定 disqus_shortname 的值即可。 1disqus_shortname: your-disqus-shortname 数据统计与分析百度统计 登录 百度统计，定位到站点的代码获取页面 复制 hm.js? 后面那串统计脚本 id，如下图所示： 编辑 主题配置文件， 修改字段 baidu_analytics，值设置成你的百度统计脚本 id。 Google 分析编辑 主题配置文件， 修改字段 google_analytics， 值设置成你的 Google 跟踪 ID。跟踪 ID 通常是以 UA- 开头。 腾讯分析 由 Cissoid 贡献请登录 腾讯分析，登录并获取分析的 ID。 然后在 主题配置文件 里将 ID 放置 tencent_analytics 字段。 不蒜子统计 由 panzhitian 贡献注意： 此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后 全局配置（站长使用ing） 编辑 主题配置文件 中的busuanzi_count的配置项。 当enable: true时，代表开启全局开关。若site_uv、site_pv、page_pv的值均为false时，不蒜子仅作记录而不会在页面上显示。 站点UV配置 当site_uv: true时，代表在页面底部显示站点的UV值。 site_uv_header和site_uv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[site_uv_header]UV值[site_uv_footer]。 12345&gt; # 效果：本站访客数12345人次&gt; site_uv: true&gt; site_uv_header: 本站访客数&gt; site_uv_footer: 人次&gt; 站点Pv配置 当site_pv: true时，代表在页面底部显示站点的PV值。 site_pv_header和site_pv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[site_pv_header]PV值[site_pv_footer]。 12345&gt; # 效果：本站总访问量12345次&gt; site_pv: true&gt; site_pv_header: 本站总访问量&gt; site_pv_footer: 次&gt; 单页面配置 当page_pv: true时，代表在文章页面的标题下显示该页面的PV值（阅读数）。 page_pv_header和page_pv_footer为自定义样式配置，相关的值留空时将不显示，可以使用（带特效的）font-awesome。显示效果为[page_pv_header]PV值[page_pv_footer]。 12345&gt; # 效果：本文总阅读量12345次&gt; page_pv: true&gt; page_pv_header: 本文总阅读量&gt; page_pv_footer: 次&gt; 没得耐心看的人，被坑很正常，站长踩过的坑分享： 不蒜子统计在主题中的链接已失效，需改： 修改themes\next\layout\_third-party\analytics\busuanzi-counter.swig中的链接，位置自己找，如果真的找不到，那可能这个不适合你吧 1&lt;script async src=&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt; 腾讯移动分析 由 aleonchen 贡献编辑 主题配置文件，填写 tencent_mta 的值。 12# Tencent MTA IDtencent_mta: your-tencent-mta-id 阅读次数统计（LeanCloud) 由 Doublemine 贡献 注册LeanCloud 创建应用 我们新建一个应用来专门进行博客的访问统计的数据操作。首先，打开控制台，如下图所示： 在出现的界面点击创建应用 在接下来的页面，新建的应用名称我们可以随意输入，即便是输入的不满意我们后续也是可以更改的 这里我新创建一个取名为blog的应用。创建完成之后我们点击新创建的应用的名字来进行该应用的参数配置 在应用的数据配置界面，左侧下划线开头的都是系统预定义好的表，为了便于区分我们新建一张表来保存我们的数据。点击左侧右上角的齿轮图标，新建Class：在弹出的选项中选择创建Class来新建Class用来专门保存我们博客的文章访问量等数据:点击创建Class之后，理论上来说名字可以随意取名，只要你交互代码做相应的更改即可，但是为了保证我们前面对NexT主题的修改兼容，此处的新建Class名字必须为Counter: 由于LeanCloud升级了默认的ACL权限，如果你想避免后续因为权限的问题导致次数统计显示不正常，建议在此处选择无限制。 创建完成之后，左侧数据栏应该会多出一栏名为Counter的栏目，这个时候我们点击顶部的设置，切换到test应用的操作界面:在弹出的界面中，选择左侧的应用Key选项，即可发现我们创建应用的AppID以及AppKey，有了它，我们就有权限能够通过主题中配置好的Javascript代码与这个应用的Counter表进行数据存取操作了: 复制AppID以及AppKey并在NexT主题的_config.yml文件中我们相应的位置填入即可，正确配置之后文件内容像这个样子: 1234leancloud_visitors: enable: true app_id: joaeuuc4hsqudUUwx4gIvGF6-gzGzoHsz app_key: E9UJsJpw1omCHuS22PdSpKoh 这个时候重新生成部署Hexo博客，应该就可以正常使用文章阅读量统计的功能了。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。 后台管理当你配置部分完成之后，初始的文章统计量显示为0，但是这个时候我们LeanCloud对应的应用的Counter表中并没有相应的记录，只是单纯的显示为0而已，当博客文章在配置好阅读量统计服务之后第一次打开时，便会自动向服务器发送数据来创建一条数据，该数据会被记录在对应的应用的Counter表中。 我们可以修改其中的time字段的数值来达到修改某一篇文章的访问量的目的（博客文章访问量快递提升人气的装逼利器）。双击具体的数值，修改之后回车即可保存。 url字段被当作唯一ID来使用，因此如果你不知道带来的后果的话请不要修改。 title字段显示的是博客文章的标题，用于后台管理的时候区分文章之用，没有什么实际作用。 其他字段皆为自动生成，具体作用请查阅LeanCloud官方文档，如果你不知道有什么作用请不要随意修改。 Web安全因为AppID以及AppKey是暴露在外的，因此如果一些别用用心之人知道了之后用于其它目的是得不偿失的，为了确保只用于我们自己的博客，建议开启Web安全选项，这样就只能通过我们自己的域名才有权访问后台的数据了，可以进一步提升安全性。 选择应用的设置的安全中心选项卡: 在Web 安全域名中填入我们自己的博客域名，来确保数据调用的安全 如果你不知道怎么填写安全域名而或者填写完成之后发现博客文章访问量显示不正常，打开浏览器调试模式，发现如下图的输出 这说明你的安全域名填写错误，导致服务器拒绝了数据交互的请求，你可以更改为正确的安全域名或者你不知道如何修改请在本博文中留言或者放弃设置Web安全域名。 内容分享服务JiaThis编辑 主题配置文件， 添加/修改字段 jiathis，值为 true。 JiaThis 内容分享服务配置示例 12# JiaThis 分享服务jiathis: true 百度分享编辑 主题配置文件，添加/修改字段 baidushare，值为 true。 百度内容分享服务配置示例 12# 百度分享服务baidushare: true AddThis 由 hackjustu 贡献(站长使用ing) 在网站 AddThis 上注册账号。 可以使用 Google/Facebook/Twitter 账号进行第三方登陆 从下面菜单获得 AddThis id：More.. --&gt; General --&gt; ID。 具体 ID 获得方式参考以下截图 在 主题配置文件 中，把#Share下的 #add_this_id取消注释， 改为add_this_id: put_your_add_this_id_here 搜索服务NexT 支持集成 Swiftype、 微搜索、Local Search 和 Algolia。 具体自己官网看吧，一堆外国产品注册，都不想看了，站长就用了一个Local Search Local Search 由 flashlab 贡献添加百度/谷歌/本地 自定义站点内容搜索 安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 想要更多的第三方集成，自己百度，不然就翻墙走谷歌]]></content>
      <categories>
        <category>blog</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo NexT主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next构建个人博客]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%20Next%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[环境支持 Hexo 安装 Hexo NexT主题安装 Hexo Next主题配置 Hexo Next第三方服务集成 写作 在source/_posts下写md文章会自动处理为html文件 每篇文章开头根据需要写 123456789---title: Hexo Next构建个人博客tags: #标签 - 随便写，乐意就要，一个也行 - 随便写，乐意就要categories: # 分类 - 随便写，乐意就要，一个也行 - 随便写，乐意就要--- 部署 安装 hexo-deployer-git。 1$ npm install hexo-deployer-git --save 修改配置。 1`deploy: type: git repo: &lt;repository url&gt; #https://bitbucket.org/JohnSmith/johnsmith.bitbucket.io branch: [branch] #published message: [message]` 参数 描述 repo 库（Repository）地址 branch 分支名称。如果您使用的是 GitHub 或 GitCafe 的话，程序会尝试自动检测。 message 自定义提交信息 (默认为) 生成站点文件并推送至远程库。执行hexo clean &amp;&amp; hexo deploy命令。前者清除站点文件，后者重新生成站点文件并将之推送到指定的库分支。（如果您的Hexo是局部安装，则需要执行hexo clean &amp;&amp; hexo deploy。） 登入 Github/BitBucket/Gitlab，请在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻，您的站点就会显示在您的Github Pages中。(不会自己百度) 更多部署https://hexo.io/zh-cn/docs/deployment 至此，一个个人博客就完成了]]></content>
      <categories>
        <category>blog</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo NexT个人博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT主题安装]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%20Next%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。 安装 NexT Hexo 安装主题的方式非常简单，只需要将主题文件拷贝至站点目录的 themes 目录下， 然后修改下配置文件即可。具体到 NexT 来说，安装步骤如下。 下载主题如果你熟悉 Git， 建议你使用 克隆最新版本 的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。 在终端窗口下，定位到 Hexo 站点目录下。使用 Git checkout 代码： 12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 启用 NexT 主题 1theme: next 到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 验证主题首先启动 Hexo 本地站点，并开启调试模式（即加上 --debug），整个命令是 hexo s --debug。 在服务启动的过程，注意观察命令行输出是否有任何异常信息，如果你碰到问题，这些信息将帮助他人更好的定位错误。 当命令行输出中提示出： 1INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. 此时即可使用浏览器访问 http://localhost:4000，检查站点是否正确运行。 当你看到站点的外观与下图所示类似时即说明你已成功安装 NexT 主题。这是 NexT 默认的 Scheme —— Muse 现在，你已经成功安装并启用了 NexT 主题。下一步我们将要更改一些主题的设定，包括个性化以及集成第三方服务。 主题设定选择 SchemeScheme 是 NexT 提供的一种特性，借助于 Scheme，NexT 为你提供多种不同的外观。同时，几乎所有的配置都可以 在 Scheme 之间共用。目前 NexT 支持三种 Scheme，他们是： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Scheme 的切换通过更改主题配置文件，搜索 scheme 关键字。 你会看到有三行 scheme 的配置，将你需用启用的 scheme 前面注释 # 去除即可。 选择 Pisces Scheme 123#scheme: Muse#scheme: Mistscheme: Pisces 设置语言编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下： 1language: zh-Hans 目前 NexT 支持的语言如以下表格所示： 语言 代码 设定示例 English en language: en 简体中文 zh-Hans language: zh-Hans Français fr-FR language: fr-FR Português pt language: pt or language: pt-BR 繁體中文 zh-hk 或者 zh-tw language: zh-hk Русский язык ru language: ru Deutsch de language: de 日本語 ja language: ja Indonesian id language: id Korean ko language: ko 设置菜单菜单配置包括三个部分，第一是菜单项（名称和链接），第二是菜单项的显示文本，第三是菜单项对应的图标。 NexT 使用的是 Font Awesome 提供的图标， Font Awesome 提供了 600+ 的图标，可以满足绝大的多数的场景，同时无须担心在 Retina 屏幕下 图标模糊的问题。 编辑 主题配置文件，修改以下内容： 设定菜单内容，对应的字段是 menu。 菜单内容的设置格式是：item name: link。其中 item name是一个名称，这个名称并不直接显示在页面上，她将用于匹配图标以及翻译。 菜单示例配置: 1234567menu: home: / archives: /archives #about: /about categories: /categories tags: /tags #commonweal: /404.html 若你的站点运行在子目录中，请将链接前缀的 / 去掉 NexT 默认的菜单项有（标注 的项表示需要手动创建这个页面）： | 键值 | 设定值 | 显示文本（简体中文） || ———- | ————————- | ——————– || home | home: / | 主页 || archives | archives: /archives | 归档页 || categories | categories: /categories | 分类页 || tags | tags: /tags | 标签页 || about | about: /about | 关于页面 || commonweal | commonweal: /404.html | 公益 404 | 设置菜单项的显示文本。在第一步中设置的菜单的名称并不直接用于界面上的展示。Hexo 在生成的时候将使用 这个名称查找对应的语言翻译，并提取显示文本。这些翻译文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。 以简体中文为例，若你需要添加一个菜单项，比如 something。那么就需要修改简体中文对应的翻译文件 languages/zh-Hans.yml，在 menu 字段下添加一项： 123456789menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 commonweal: 公益404 something: 有料 设定菜单项的图标，对应的字段是 menu_icons。 此设定格式是 item name: icon name，其中 item name 与上一步所配置的菜单名字对应，icon name 是 Font Awesome 图标的 名字。而 enable 可用于控制是否显示图标，你可以设置成 false 来去掉图标。 菜单图标配置示例: 123456789menu_icons: enable: true # Icon Mapping. home: home about: user categories: th tags: tags archives: archive commonweal: heartbeat 在菜单图标开启的情况下，如果菜单项与菜单未匹配（没有设置或者无效的 Font Awesome 图标名字） 的情况下，NexT 将会使用 作为图标 设置侧栏默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。 可以通过修改 主题配置文件 中的 sidebar 字段来控制侧栏的行为。侧栏的设置包括两个部分，其一是侧栏的位置， 其二是侧栏显示的时机。 设置侧栏的位置，修改 sidebar.position 的值，支持的选项有： left - 靠左放置 right - 靠右放置 目前仅 Pisces Scheme 支持 position 配置。影响版本5.0.0及更低版本。 12sidebar: position: left 设置侧栏显示的时机，修改 sidebar.display 的值，支持的选项有： post - 默认行为，在文章页面（拥有目录列表）时显示 always - 在所有页面中都显示 hide - 在所有页面中都隐藏（可以手动展开） remove - 完全移除 12sidebar: display: post 已知侧栏在 use motion: false 的情况下不会展示。 影响版本5.0.0及更低版本。 设置头像编辑 主题配置文件， 修改字段 avatar， 值设置成头像的链接地址。其中，头像的链接地址可以是： 地址 值 完整的互联网 URI http://example.com/avatar.png 站点内的地址 将头像放置主题目录下的 source/uploads/ （新建 uploads 目录若不存在） 配置为：avatar: /uploads/avatar.png或者 放置在 source/images/ 目录下 配置为：avatar: /images/avatar.png 头像设置示例: 1avatar: http://example.com/avatar.png 设置作者昵称编辑 站点配置文件， 设置 author 为你的昵称。 站点描述编辑 站点配置文件， 设置 description 字段为你的站点描述。站点描述可以是你喜欢的一句签名:)]]></content>
      <categories>
        <category>blog</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo NexT主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo NexT主题配置]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%20Next%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[设置 RSSNexT 中 RSS 有三个设置选项，满足特定的使用场景。 更改 主题配置文件，设定 rss 字段的值： false：禁用 RSS，不在页面上显示 RSS 连接。 留空：使用 Hexo 生成的 Feed 链接。 你可以需要先安装 hexo-generator-feed 插件。 具体的链接地址：适用于已经烧制过 Feed 的情形。 添加「标签」页面新建「标签」页面，并在菜单中显示「标签」链接。「标签」页面将展示站点的所有标签，若你的所有文章都未包含标签，此页面将是空的。 底下代码是一篇包含标签的文章的例子： 123456---title: 标签测试文章tags: - Testing - Another Tag--- 请参阅 Hexo 的分类与标签文档，了解如何为文章添加标签或者分类。 新建标签页面 在终端窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个页面，命名为 tags： 12$ cd your-hexo-site$ hexo new page tags 设置页面类型 编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下： 1234title: 标签date: 2019-01-08 12:39:04type: &quot;tags&quot;--- 修改菜单 在菜单中添加链接。编辑 主题配置文件 ， 添加 tags 到 menu 中，如下: 1234menu: home: / archives: /archives tags: /tags 注意：如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如： ​ 禁用评论示例 12345title: 标签date: 2019-01-08 12:39:04type: &quot;tags&quot;comments: false--- 添加「分类」页面新建「分类」页面，并在菜单中显示「分类」链接。「分类」页面将展示站点的所有分类，若你的所有文章都未包含分类，此页面将是空的。 底下代码是一篇包含分类的文章的例子： 123title: 分类测试文章categories: Testing--- 请参阅 Hexo 的分类与标签文档，了解如何为文章添加标签或者分类。 新建页面 在终端窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个页面，命名为 categories ： 12$ cd your-hexo-site$ hexo new page categories 设置页面类型 编辑刚新建的页面，将页面的 type 设置为 categories ，主题将自动为这个页面显示分类。页面内容如下： 1234title: 分类date: 2019-01-08 12:39:04type: "categories"--- 修改菜单 在菜单中添加链接。编辑 主题配置文件 ， 添加 categories 到 menu 中，如下: 1234menu: home: / archives: /archives categories: /categories 注意：如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如： 禁用评论示例: 12345title: 分类date: 2014-12-22 12:39:04type: &quot;categories&quot;comments: false--- 设置字体注意： 此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后 为了解决 Google Fonts API 不稳定的问题，NexT 在 5.0.1 中引入此特性。 通过此特性，你可以指定所使用的字体库外链地址；与此同时，NexT 开放了 5 个特定范围的字体设定，他们是： 全局字体：定义的字体将在全站范围使用 标题字体：文章内标题的字体（h1, h2, h3, h4, h5, h6） 文章字体：文章所使用的字体 Logo字体：Logo 所使用的字体 代码字体： 代码块所使用的字体 各项所指定的字体将作为首选字体，当他们不可用时会自动 Fallback 到 NexT 设定的基础字体组： 非代码类字体：Fallback 到 &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, sans-serif 代码类字体： Fallback 到 consolas, Menlo, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, monospace 另外，每一项都有一个额外的 external 属性，此属性用来控制是否使用外链字体库。 开放此属性方便你设定那些已经安装在系统中的字体，减少不必要的请求（请求大小）。 配置示例: 12345678910111213141516171819202122232425262728293031font: enable: true # 外链字体库地址，例如 //fonts.googleapis.com (默认值) host: # 全局字体，应用在 body 元素上 global: external: true family: Monda # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: Lobster Two size: 24 # 代码字体，应用于 code 以及代码块 codes: external: true family: PT Mono 设置代码高亮主题NexT 使用 Tomorrow Theme 作为代码高亮，共有5款主题供你选择。 NexT 默认使用的是 白色的 normal 主题，可选的值有 normal，night， night blue， night bright， night eighties： 更改 highlight_theme 字段，将其值设定成你所喜爱的高亮主题，例如： 高亮主题设置示例: 1234# Code Highlight theme# Available value: normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: normal 侧边栏社交链接侧栏社交链接的修改包含两个部分，第一是链接，第二是链接图标。 两者配置均在 主题配置文件 中。 链接放置在 social 字段下，一行一个链接。其键值格式是 显示文本: 链接地址。 配置示例 12345678# Social linkssocial: GitHub: https://github.com/your-user-name Twitter: https://twitter.com/your-user-name 微博: http://weibo.com/your-user-name 豆瓣: http://douban.com/people/your-user-name 知乎: http://www.zhihu.com/people/your-user-name # 等等 设定链接的图标，对应的字段是 social_icons。其键值格式是 匹配键: Font Awesome 图标名称， 匹配键 与上一步所配置的链接的 显示文本 相同（大小写严格匹配），图标名称 是 Font Awesome 图标的名字（不必带 fa- 前缀）。 enable 选项用于控制是否显示图标，你可以设置成 false 来去掉图标。 配置示例 1234567# Social Iconssocial_icons: enable: true # Icon Mappings GitHub: github Twitter: twitter 微博: weibo 开启打赏功能 由 habren 贡献越来越多的平台（微信公众平台，新浪微博，简书，百度打赏等）支持打赏功能，付费阅读时代越来越近，特此增加了打赏功能，支持微信打赏和支付宝打赏。 只需要 主题配置文件 中填入 微信 和 支付宝 收款二维码图片地址 即可开启该功能。 打赏功能配置示例 123reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /path/to/wechat-reward-imagealipay: /path/to/alipay-reward-image 友情链接 由 iamwent 贡献编辑 主题配置文件 添加： 友情链接配置示例 12345# titlelinks_title: Linkslinks: MacTalk: http://macshuo.com/ Title: http://example.com/ 腾讯公益404页面 由 xirong 贡献腾讯公益404页面，寻找丢失儿童，让大家一起关注此项公益事业！效果如下 http://www.ixirong.com/404.html 使用方法，新建 404.html 页面，放到主题的 source 目录下，内容如下： 123456789101112131415161718&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8;&quot;/&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;all&quot; /&gt; &lt;meta name=&quot;robots&quot; content=&quot;index,follow&quot;/&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://qzone.qq.com/gy/404/style/404style.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/plain&quot; src=&quot;http://www.qq.com/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;/&quot; homePageName=&quot;回到我的主页&quot;&gt; &lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/data.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://qzone.qq.com/gy/404/page.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 站点建立时间这个时间将在站点的底部显示，例如 © 2013 - 2015。 编辑 主题配置文件，新增字段 since。 配置示例 1since: 2013 订阅微信公众号 由 huiwang 贡献注意： 此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后 在每篇文章的末尾显示微信公众号二维码，扫一扫，轻松订阅博客。 在微信公众号平台下载您的二维码，并将它存放于博客source/uploads/目录下。 然后编辑 主题配置文件，如下： 配置示例 12345# Wechat Subscriberwechat_subscriber: enabled: true qcode: /uploads/wechat-qcode.jpg description: 欢迎您扫一扫上面的微信公众号，订阅我的博客！ 设置「动画效果」NexT 默认开启动画效果，效果使用 JavaScript 编写，因此需要等待 JavaScript 脚本完全加载完毕后才会显示内容。 如果您比较在乎速度，可以将设置此字段的值为 false 来关闭动画。 编辑 主题配置文件， 搜索 use_motion，根据您的需求设置值为 true 或者 false 即可： 12use_motion: true # 开启动画效果use_motion: false # 关闭动画效果 设置「背景动画」NexT 自带两种背景动画效果 编辑 主题配置文件， 搜索 canvas_nest 或 three_waves，根据您的需求设置值为 true 或者 false即可： 注意： three_waves 在版本 5.1.1 中引入。只能同时开启一种背景动画效果。 canvas_nest 配置示例: 123# canvas_nestcanvas_nest: true //开启动画canvas_nest: false //关闭动画 three_waves 配置示例: 123# three_wavesthree_waves: true //开启动画three_waves: false //关闭动画]]></content>
      <categories>
        <category>blog</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo NexT主题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm切换镜像到淘宝镜像]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2Fnpm%E5%88%87%E6%8D%A2%E9%95%9C%E5%83%8F%E5%88%B0%E6%B7%98%E5%AE%9D%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[NPM安装完成Node(傻瓜式安装)应该自带了NPM了，在控制台输入npm -v查看: npm默认的仓库地址是在国外网站，速度较慢，建议大家设置到淘宝镜像。但是切换镜像是比较麻烦的。推荐一款切换镜像的工具：nrm 我们首先安装nrm，这里-g代表全局安装 1npm install nrm -g 然后通过nrm ls命令查看npm的仓库列表,带*的就是当前选中的镜像仓库： 通过nrm use taobao来指定要使用的镜像源： 然后通过nrm test npm来测试速度： 注意：(重要的事情说三遍！！！) 安装完成请一定要重启下电脑！！！ 安装完成请一定要重启下电脑！！！ 安装完成请一定要重启下电脑！！！]]></content>
      <categories>
        <category>npm</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo建站(博客)]]></title>
    <url>%2F2019%2F02%2F13%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%E5%BB%BA%E7%AB%99%2F</url>
    <content type="text"><![CDATA[环境准备 Hexo安装 VScode(IDE：个人喜好) 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，指定文件夹的目录如下： 123456789.├── _config.yml├── node_modules/├── package.json├── package-lock.json├── scaffolds├── source| └── _posts└── themes _config.yml网站的 配置 信息，您可以在此配置大部分的参数。 package.json应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 12345678910111213141516171819&#123; &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: &#123; &quot;version&quot;: &quot;&quot; &#125;, &quot;dependencies&quot;: &#123; &quot;hexo&quot;: &quot;^3.7.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.5&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;, &quot;hexo-generator-index&quot;: &quot;^0.2.1&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.3.1&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.3.3&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.3.2&quot;, &quot;hexo-server&quot;: &quot;^0.3.1&quot; &#125;&#125; scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。Hexo 会根据主题来生成静态页面。 修改站点信息修改 _config.yml(不是主题的 _config.yml)中的信息，例如： 12345678# Sitetitle: 程鹏subtitle: 不积跬步，无以至千里；不积小流，无以成江海description:keywords: 技术博客,blog,hexoauthor: 程鹏language: zh-Hans # hexo NexT主题用timezone:]]></content>
      <categories>
        <category>blog</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo建站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git快速入手]]></title>
    <url>%2F2019%2F02%2F02%2FGit%2FGit%E5%BF%AB%E9%80%9F%E5%85%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[简介Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Git is easy to learn and has a tiny footprint with lightning fast performance. It outclasses SCM tools like Subversion, CVS, Perforce, and ClearCase with features like cheap local branching, convenient staging areas, and multiple workflows. 官网 下载 git安装 官方教程：https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%AE%89%E8%A3%85-Git windows详细安装教程：https://www.jianshu.com/p/414ccd423efc 配置 git config –list git config –-global user.name &#39;yourname&#39; git config –-global user.email &#39;youremail&#39; ssh-keygen -t rsa -C &#39;youremail&#39; 把本地的 ~/.ssh/xxx.pub 添加到github类似平台的SSH keys中 常用命令 创建自己远端项目 github gitee 码市 gitlab … 分支操作： git branch 创建分支 git branch -b 创建并切换到新建的分支上 git checkout 切换分支 git branch 查看分支列表 git branch -v 查看所有分支的最后一次操作 git branch -vv 查看当前分支 git brabch -b 分支名 origin/分支名 创建远程分支到本地 git branch –merged 查看别的分支和当前分支合并过的分支 git branch –no-merged 查看未与当前分支合并的分支 git branch -d 分支名 删除本地分支 git branch -D 分支名 强行删除分支 git branch origin :分支名 删除远处仓库分支 git merge 分支名 合并分支到当前分支上 暂存操作： git stash 暂存当前修改 git stash apply 恢复最近的一次暂存 git stash pop 恢复暂存并删除暂存记录 git stash list 查看暂存列表 git stash drop 暂存名(例：stash@{0}) 移除某次暂存 git stash clear 清除暂存 回退操作： git reset –hard HEAD^ 回退到上一个版本 git reset –hard ahdhs1(commit_id) 回退到某个版本 git checkout – file撤销修改的文件(如果文件加入到了暂存区，则回退到暂存区的，如果文件加入到了版本库，则还原至加入版本库之后的状态) git reset HEAD file 撤回暂存区的文件修改到工作区 标签操作： git tag 标签名 添加标签(默认对当前版本) git tag 标签名 commit_id 对某一提交记录打标签 git tag -a 标签名 -m ‘描述’ 创建新标签并增加备注 git tag 列出所有标签列表 git show 标签名 查看标签信息 git tag -d 标签名 删除本地标签 git push origin 标签名 推送标签到远程仓库 git push origin –tags 推送所有标签到远程仓库 git push origin :refs/tags/标签名 从远程仓库中删除标签 常规操作： git push origin test 推送本地分支到远程仓库 git rm -r –cached 文件/文件夹名字 取消文件被版本控制 git reflog 获取执行过的命令 git log –graph 查看分支合并图 git merge –no-ff -m ‘合并描述’ 分支名 不使用Fast forward方式合并，采用这种方式合并可以看到合并记录 git check-ignore -v 文件名 查看忽略规则 git add -f 文件名 强制将文件提交 git创建项目仓库： git init 初始化 git remote add origin url 关联远程仓库 git pull git fetch 获取远程仓库中所有的分支到本地 忽略已加入到版本库中的文件： git update-index –assume-unchanged file 忽略单个文件 git rm -r –cached 文件/文件夹名字 (. 忽略全部文件) 取消忽略文件： git update-index –no-assume-unchanged file 拉取、上传免密码： git config –global credential.helper store]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置 Jenkins]]></title>
    <url>%2F2019%2F02%2F02%2FJenkins%2F%E9%85%8D%E7%BD%AE%20Jenkins%2F</url>
    <content type="text"><![CDATA[本教程基于docker-compose安装Jenkins 详细安装教程：站内搜索Docker-Compose安装Jenkins 配置 JDK &amp; Maven 上传 JDK 和 Maven 的 tar 包到服务器（容器数据卷目录/usr/local/docker/jenkins/data） 解压 JDK 和 Maven 的 tar 包，完成后删除压缩包 Manage Jenkins -&gt; Global Tool Configuration 安装 JDK(JAVA_HOME 的路径是宿主机目录) 1/var/jenkins_home/jdk1.8.0_152 安装 Maven(MAVEN_HOME 的路径是宿主机目录) 1/var/jenkins_home/apache-maven-3.5.3 别忘记保存 配置本地化（显示中文） 安装 Locale 插件 Manage Jenkins -&gt; Configure System -&gt; Locale 本地化效果图]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Compose安装Jenkins]]></title>
    <url>%2F2019%2F02%2F02%2FJenkins%2FDocker-Compose%E5%AE%89%E8%A3%85Jenkins%2F</url>
    <content type="text"><![CDATA[配置文件编写docker-compose.ymlJenkins 是一个简单易用的持续集成软件平台，我们依然采用 Docker 的方式部署，docker-compose.yml 配置文件如下： 12345678910111213version: '3'services: jenkins: restart: always image: jenkins/jenkins container_name: jenkins ports: - 8080:8080 # 发布端口 - 50000:50000 # 基于 JNLP 的 Jenkins 代理通过 TCP 端口 50000 与 Jenkins master 进行通信 environment: TZ: Asia/Shanghai volumes: - ./data:/var/jenkins_home 安装过程中会出现 Docker 数据卷 权限问题，用以下命令解决： 1chown -R 1000 /usr/local/docker/jenkins/data 解锁 JenkinsJenkins 第一次启动时需要输入一个初始密码用以解锁安装流程，使用 docker logs jenkins 即可方便的查看到初始密码注意： 安装时可能会因为网速等原因导致安装时间比较长，请大家耐心等待。如果长时间停留在安装页没反应，请尝试使用 F5 刷新一下。 使用自定义插件的方式安装插件是 Jenkins 的核心，其丰富的插件（截止到 2019.1.2 共有 79400 个插件）可以满足不同人群的不同需求 插件地址：https://plugins.jenkins.io/注意： 除了默认勾选的插件外，一定要勾选 Publish over SSH 插件，这是我们实现持续交付的重点插件。 开始安装了，根据网络情况，安装时间可能会比较长，请耐心等待 很多插件装不上怎么办？不要慌，记住这些插件的名字，咱们稍后可以手动安装 安装成功效果图创建管理员 安装完成，进入首页 附：Jenkins 手动安装插件使用插件管理器安装 Manage Jenkins -&gt; Manage Plugins -&gt; Avaliable 过滤出想要安装的插件，然后点击 Download now and install after restart 手动上传 .hpi文件 点击进入插件中心 点击 Archives 下载需要的版本 在插件管理器中选择 Advanced 选择上传即可 重启 Jenkins12docker-compose downdocker-compose up -d 注意： 请留意需要下载插件的警告信息，如果不满足安装条件，Jenkins 是会拒绝安装的。如下图：]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git克隆提交出现ssh connect to host github.com port 22 Connection timed out问题]]></title>
    <url>%2F2019%2F02%2F02%2FGit%2FGit%E5%85%8B%E9%9A%86%E6%8F%90%E4%BA%A4%E5%87%BA%E7%8E%B0ssh%20connect%20to%20host%20github.com%20port%2022%20Connection%20timed%20out%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题使用ssh克隆github上面的代码时出现问题： 分析：输出信息prot 22: Operation timed out，初步分析端口问题我们修改端口试试，这里将端口改为443。 解决方法在存放私钥公钥（id_rsa和id_rsa.pub）文件里，新建config文本。命令vim ~/.ssh/config,输入一下内容： 123456Host github.comUser YourEmail@163.comHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443 保存退出。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven私服Nexus3快速搭建使用]]></title>
    <url>%2F2019%2F02%2F01%2Fdocker%2FMaven%E7%A7%81%E6%9C%8DNexus3%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介 官网：http://books.sonatype.com/nexus-book/reference3/index.html 下载：https://help.sonatype.com/repomanager3/download 话不多说，马上开撸 安装在这里，博主没有使用官方的安装方式，而是使用docker-compose去安装nexus3，个人认为这种方式，简单方便，当然安装前提需要安装docker和docker-compose，这些无脑操作就不赘述了 docker-compose文件docker-compose.yml 12345678910111213version: '3'services: nexus: #restart: always image: sonatype/nexus3 container_name: nexus environment: TZ: Asia/Shanghai INSTALL4J_ADD_VM_PARAMS: "-Xms256m -Xmx256m -XX:MaxDirectMemorySize=512m" ports: - 8081:8081 volumes: - ./data:/nexus-data 自定义配置参数参考：https://hub.docker.com/r/sonatype/nexus3/ 启动nexus 使用启动命令： 1docker-compose up -d 查看启动信息： 1docker logs -f nexus 启动信息没有报错且出现如图则启动成功： 访问nexus http://ip:8081 默认用户名：admin 默认密码：admin123 配置maven中的私服信息在settings.xml中的services节点中添加： 12345678910&lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; 在maven项目中使用配置pom.xml文件 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://132.232.137.183:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://132.232.137.183:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt;]]></content>
      <categories>
        <category>Nexus3</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>Nexus3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch快速入门]]></title>
    <url>%2F2019%2F01%2F29%2FElasticsearch%2FElasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Elasticsearch介绍和安装简介ElasticElastic官网：https://www.elastic.co/cn/ Elastic有一条完整的产品线：Elasticsearch、Kibana、Logstash等，前面说的三个就是大家常说的ELK技术栈。 ElasticsearchElasticsearch官网：https://www.elastic.co/cn/products/elasticsearch 如上所述，Elasticsearch具备以下特点： 分布式，无需人工搭建集群（solr就需要人为配置，使用Zookeeper作为注册中心） Restful风格，一切API都遵循Rest原则，容易上手 近实时搜索，数据更新在Elasticsearch中几乎是完全同步的。 版本目前Elasticsearch最新的版本是6.5.4，我们就使用这个版本 需要虚拟机JDK1.8及以上 CentOS7安装和配置新建一个用户1useradd esearch 设置密码： 1passwd esearch 出于安全考虑，elasticsearch默认不允许以root账号运行。 切换用户： 1su - esearch 上传安装包,并解压我们将安装包上传到：/home/esearch目录 解压缩： 1tar xvf elasticsearch-6.5.4.tar.gz 修改文件拥有者与所属组 1chown esearch:esearch elasticsearch-6.5.4 -R 我们把目录重命名： 1mv elasticsearch-6.5.4 elasticsearch 进入，查看目录结构： 修改配置我们进入config目录：cd config 需要修改的配置文件有两个： 修改jvm配置 Elasticsearch基于Lucene的，而Lucene底层是java实现，因此我们需要配置jvm参数 1vim jvm.options 默认配置如下： 12-Xms1g-Xmx1g 内存占用太多了，我们调小一些： 12-Xms512m-Xmx512m 修改elasticsearch.yml 1vim elasticsearch.yml 修改数据和日志目录： 12path.data: /home/esearch/elasticsearch/data # 数据目录位置path.logs: /home/esearch/elasticsearch/logs # 日志目录位置 修改绑定的ip： 1network.host: 0.0.0.0 # 绑定到0.0.0.0，允许任何ip来访问 默认只允许本机访问，修改为0.0.0.0后则可以远程访问 目前我们是做的单机安装，如果要做集群，只需要在这个配置文件中添加其它节点信息即可。 elasticsearch.yml的其它可配置信息： 属性名 说明 cluster.name 配置elasticsearch的集群名称，默认是elasticsearch。建议修改成一个有意义的名称。 node.name 节点名，es会默认随机指定一个名字，建议指定一个有意义的名称，方便管理 path.conf 设置配置文件的存储路径，tar或zip包安装默认在es根目录下的config文件夹，rpm安装默认在/etc/ elasticsearch path.data 设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开 path.logs 设置日志文件的存储路径，默认是es根目录下的logs文件夹 path.plugins 设置插件的存放路径，默认是es根目录下的plugins文件夹 bootstrap.memory_lock 设置为true可以锁住ES使用的内存，避免内存进行swap network.host 设置bind_host和publish_host，设置为0.0.0.0允许外网访问 http.port 设置对外服务的http端口，默认为9200。 transport.tcp.port 集群结点之间通信端口 discovery.zen.ping.timeout 设置ES自动发现节点连接超时的时间，默认为3秒，如果网络延迟高可设置大些 discovery.zen.minimum_master_nodes 主结点数量的最少值 ,此值的公式为：(master_eligible_nodes / 2) + 1 ，比如：有3个符合要求的主结点，那么这里要设置为2 创建data和logs目录刚才我们修改配置，把data和logs目录修改指向了elasticsearch的安装目录。但是这两个目录并不存在，因此我们需要创建出来： 进入elasticsearch的根目录，然后创建： 12mkdir datamkdir logs 运行进入elasticsearch/bin目录，可以看到下面的执行文件： 然后输入命令： 1./elasticsearch 发现报错了，启动失败. 错误1:1[1]: max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536] 我们用的是esearch用户，而不是root，所以文件权限不足。 首先用root用户登录。 然后修改配置文件: 1vim /etc/security/limits.conf 添加下面的内容： 1234567* soft nofile 65536* hard nofile 131072* soft nproc 4096* hard nproc 4096 错误2：1[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 继续修改配置文件： 1vim /etc/sysctl.conf 添加下面内容： 1vm.max_map_count=655360 然后执行命令： 1sysctl -p 重启终端窗口所有错误修改完毕，一定要重启你的 Xshell终端，否则配置无效。 启动再次启动，终于成功了！ 可以看到绑定了两个端口: 9300：集群节点间通讯接口 9200：客户端访问接口 我们在浏览器中访问(由于博主使用的是云服务器，访问需要使用公网IP访问):http://119.23.208.179:9200 安装kibana什么是Kibana？ Kibana是一个基于Node.js的Elasticsearch索引库数据统计工具，可以利用Elasticsearch的聚合功能，生成各种图表，如柱形图，线状图，饼图等。 而且还提供了操作Elasticsearch索引数据的控制台，并且提供了一定的API提示，非常有利于我们学习Elasticsearch的语法。 安装因为Kibana依赖于node，我的虚拟机没有安装node，而window中安装过。所以我们选择在window下使用kibana。 最新版本与elasticsearch保持一致，也是6.5.4 解压即可： 配置运行 配置 进入安装目录下的config目录，修改kibana.yml文件： 修改elasticsearch服务器的地址： 1elasticsearch.url: &quot;http://119.23.208.179:9200&quot; 运行 进入安装目录下的bin目录： 双击运行kibana.bat： 发现kibana的监听端口是5601 我们访问：http://127.0.0.1:5601 控制台选择左侧的DevTools菜单，即可进入控制台页面： 在页面右侧，我们就可以输入请求，访问Elasticsearch了。 安装ik分词器Lucene的IK分词器早在2012年已经没有维护了，现在我们要使用的是在其基础上维护升级的版本，并且开发为Elasticsearch的集成插件了，与Elasticsearch一起维护升级，版本也保持一致，最新版本：6.5.4 安装下载并上传elasticsearch-analysis-ik-6.5.4.zip包，在/home/esearch/elasticsearch/plugins中，将elasticsearch-analysis-ik-6.5.4.zip解压到ik-analyzer目录中： 使用unzip命令解压： 1unzip elasticsearch-analysis-ik-6.5.4.zip -d ik-analyzer 删除elasticsearch-analysis-ik-6.5.4.zip,然后重启elasticsearch： 测试大家先不管语法，我们先测试一波。 在kibana控制台输入下面的请求： 12345POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;我是中国人&quot;&#125; 运行得到结果： 123456789101112131415161718192021222324252627282930313233343536373839&#123; "tokens" : [ &#123; "token" : "我", "start_offset" : 0, "end_offset" : 1, "type" : "CN_CHAR", "position" : 0 &#125;, &#123; "token" : "是", "start_offset" : 1, "end_offset" : 2, "type" : "CN_CHAR", "position" : 1 &#125;, &#123; "token" : "中国人", "start_offset" : 2, "end_offset" : 5, "type" : "CN_WORD", "position" : 2 &#125;, &#123; "token" : "中国", "start_offset" : 2, "end_offset" : 4, "type" : "CN_WORD", "position" : 3 &#125;, &#123; "token" : "国人", "start_offset" : 3, "end_offset" : 5, "type" : "CN_WORD", "position" : 4 &#125; ]&#125; APIElasticsearch提供了Rest风格的API，即http请求接口，而且也提供了各种语言的客户端API Rest风格API文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html 客户端APIElasticsearch支持的客户端非常多：https://www.elastic.co/guide/en/elasticsearch/client/index.html 点击Java Rest Client后，你会发现又有两个： Low Level Rest Client是低级别封装，提供一些基础功能，但更灵活 High Level Rest Client，是在Low Level Rest Client基础上进行的高级别封装，功能更丰富和完善，而且API会变的简单 如何学习建议先学习Rest风格API，了解发起请求的底层实现，请求体格式等。 操作索引基本概念Elasticsearch也是基于Lucene的全文检索库，本质也是存储数据，很多概念与MySQL类似的。 对比关系： 索引（indices）——————————–Databases 数据库 ​ 类型（type）—————————–Table 数据表 ​ 文档（Document）—————-Row 行 ​ 字段（Field）——————-Columns 列 详细说明： 概念 说明 索引库（indices) indices是index的复数，代表许多的索引， 类型（type） 类型是模拟mysql中的table概念，一个索引库下可以有不同类型的索引，比如商品索引，订单索引，其数据格式不同。不过这会导致索引库混乱，因此未来版本中会移除这个概念 文档（document） 存入索引库原始的数据。比如每一条商品信息，就是一个文档 字段（field） 文档中的属性 映射配置（mappings） 字段的数据类型、属性、是否索引、是否存储等特性 是不是与Lucene和solr中的概念类似。 另外，在SolrCloud中，有一些集群相关的概念，在Elasticsearch也有类似的： 索引集（Indices，index的复数）：逻辑上的完整索引 分片（shard）：数据拆分后的各个部分 副本（replica）：每个分片的复制 要注意的是：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。 创建索引语法Elasticsearch采用Rest风格API，因此其API就是一次http请求，你可以用任何工具发起http请求 创建索引的请求格式： 请求方式：PUT 请求路径：/索引库名 请求参数：json格式： 123456&#123; "settings": &#123; "number_of_shards": 3, "number_of_replicas": 2 &#125;&#125; settings：索引库的设置 number_of_shards：分片数量 number_of_replicas：副本数量 测试我们先用Insomnia来试试 响应： 可以看到索引创建成功了。 使用kibana创建kibana的控制台，可以对http请求进行简化，示例： 相当于是省去了elasticsearch的服务器地址 而且还有语法提示，非常舒服。 查看索引设置 语法 Get请求可以帮我们查看索引信息，格式： 1GET /索引库名 或者，我们可以使用*来查询所有索引库配置： 删除索引删除索引使用DELETE请求 语法 1DELETE /索引库名 示例 再次查看heima2： 当然，我们也可以用HEAD请求，查看索引是否存在： 映射配置索引有了，接下来肯定是添加数据。不过数据存储到索引库中，必须指定一些相关属性，在学习Lucene中我们都见到过，包括到不限于： 字段的数据类型 是否要存储 是否要索引 是否分词 分词器是什么 只有配置清楚，Elasticsearch才会帮我们进行索引库的创建（不一定） 创建映射字段 语法 请求方式依然是PUT 1234567891011PUT /索引库名/_mapping/类型名称&#123; &quot;properties&quot;: &#123; &quot;字段名&quot;: &#123; &quot;type&quot;: &quot;类型&quot;, &quot;index&quot;: true， &quot;store&quot;: true， &quot;analyzer&quot;: &quot;分词器&quot; &#125; &#125;&#125; 类型名称：就是前面将的type的概念，类似于数据库中的不同表字段名：任意填写 ，可以指定许多属性，例如： type：类型，可以是text、long、short、date、integer、object等 index：是否索引，默认为true store：是否存储，默认为false analyzer：分词器，这里的ik_max_word即使用ik分词器 示例 发起请求： 12345678910111213141516PUT test/_mapping/goods&#123; "properties": &#123; "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125;, "images": &#123; "type": "keyword", "index": "false" &#125;, "price": &#123; "type": "float" &#125; &#125;&#125; 响应结果： 123&#123; "acknowledged" : true&#125; 查看映射关系 语法： 1GET /索引库名/_mapping 示例： 1GET /heima/_mapping 响应： 123456789101112131415161718192021&#123; "test" : &#123; "mappings" : &#123; "goods" : &#123; "properties" : &#123; "images" : &#123; "type" : "keyword", "index" : false &#125;, "price" : &#123; "type" : "float" &#125;, "title" : &#123; "type" : "text", "analyzer" : "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125; 字段属性详解 type Elasticsearch中支持的数据类型非常丰富： 我们说几个关键的： String类型，又分两种： text：可分词，不可参与聚合 keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合 Numerical：数值类型，分两类 基本数据类型：long、interger、short、byte、double、float、half_float 浮点数的高精度类型：scaled_float 需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。 Date：日期类型 elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。 index index影响字段的索引情况。 true：字段会被索引，则可以用来进行搜索。默认值就是true false：字段不会被索引，不能用来搜索 index的默认值就是true，也就是说你不进行任何配置，所有字段都会被索引。 但是有些字段是我们不希望被索引的，比如商品的图片信息，就需要手动设置index为false。 store 是否将数据进行额外存储。 在学习lucene和solr时，我们知道如果一个字段的store设置为false，那么在文档列表中就不会有这个字段的值，用户的搜索结果中不会显示出来。 但是在Elasticsearch中，即便store设置为false，也可以搜索到结果。 原因是Elasticsearch在创建文档索引时，会将文档中的原始数据备份，保存到一个叫做_source的属性中。而且我们可以通过过滤_source来选择哪些要显示，哪些不显示。 而如果设置store为true，就会在_source以外额外存储一份数据，多余，因此一般我们都会将store设置为false，事实上，store的默认值就是false。 boost 激励因子，这个与lucene中一样 其它的不再一一讲解，用的不多，大家参考官方文档： 新增数据随机生成id通过POST请求，可以向一个已经存在的索引库中添加数据。 语法： 1234POST /索引库名/类型名&#123; &quot;key&quot;:&quot;value&quot;&#125; 示例： 123456POST /test/goods/&#123; "title":"小米手机", "images":"https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price":3299.00&#125; 响应： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 0, "_primary_term" : 1&#125; 通过kibana查看数据： 123456get _search&#123; &quot;query&quot;:&#123; &quot;match_all&quot;:&#123;&#125; &#125;&#125; 1234567891011&#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 1.0, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125;&#125; _source：源文档信息，所有的数据都在里面。 _id：这条文档的唯一标示，与文档自己的id字段没有关联 自定义id如果我们想要自己新增的时候指定id，可以这么做： 1234POST /索引库名/类型/id值&#123; ...&#125; 示例： 123456POST /test/goods/2&#123; &quot;title&quot;:&quot;大米手机&quot;, &quot;images&quot;:&quot;http://image.codeopen.club/12479122.jpg&quot;, &quot;price&quot;:2899.00&#125; 响应结果: 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 0, "_primary_term" : 1&#125; 智能判断在学习Solr时我们发现，我们在新增数据时，只能使用提前配置好映射属性的字段，否则就会报错。 不过在Elasticsearch中并没有这样的规定。 事实上Elasticsearch非常智能，你不需要给索引库设置任何mapping映射，它也可以根据你输入的数据来判断类型，动态添加数据映射。 测试一下： 12345678POST /test/goods/3&#123; "title":"超米手机", "images":"http://image.codeopen.club/12479122.jpg", "price":2899.00, "stock": 200, "saleable":true&#125; 我们额外添加了stock库存，和saleable是否上架两个字段。 来看结果： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 1, "_primary_term" : 1&#125; 在看下索引库的映射关系GET test/_mapping: 123456789101112131415161718192021222324252627&#123; "test" : &#123; "mappings" : &#123; "goods" : &#123; "properties" : &#123; "images" : &#123; "type" : "keyword", "index" : false &#125;, "price" : &#123; "type" : "float" &#125;, "saleable" : &#123; "type" : "boolean" &#125;, "stock" : &#123; "type" : "long" &#125;, "title" : &#123; "type" : "text", "analyzer" : "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125; stock和saleable都被成功映射了。 修改数据把刚才新增的请求方式改为PUT，就是修改了。不过修改必须指定id， id对应文档存在，则修改 id对应文档不存在，则新增 比如，我们把id为3的数据进行修改： 12345678PUT /test/goods/3&#123; "title":"超大米手机", "images":"http://image.codeopen.club/12479122.jpg", "price":4899.00, "stock": 300, "saleable":true&#125; 结果： 1234567891011121314&#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_version" : 2, "result" : "updated", "_shards" : &#123; "total" : 3, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 2, "_primary_term" : 1&#125; 删除数据删除使用DELETE请求，同样，需要根据id进行删除： 语法 1DELETE /索引库名/类型名/id值 示例： 查询我们从4块来讲查询： 基本查询 _source过滤 结果过滤 高级查询 排序 基本查询： 基本语法 12345678GET /索引库名/_search&#123; "query":&#123; "查询类型":&#123; "查询条件":"查询条件值" &#125; &#125;&#125; 这里的query代表一个查询对象，里面可以有不同的查询属性 查询类型： 例如：match_all， match，term ， range 等等 查询条件：查询条件会根据类型的不同，写法也有差异，后面详细讲解 查询所有（match_all) 示例： 123456GET /test/_search&#123; "query":&#123; "match_all": &#123;&#125; &#125;&#125; query：代表查询对象 match_all：代表查询所有 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 1.0, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125; ] &#125;&#125; took：查询花费时间，单位是毫秒 time_out：是否超时 _shards：分片信息 hits：搜索结果总览对象 total：搜索到的总条数 max_score：所有结果中文档得分的最高分 hits：搜索结果的文档对象数组，每个元素是一条搜索到的文档信息 _index：索引库 _type：文档类型 _id：文档id _score：文档得分 _source：文档的源数据 匹配查询（match）我们先加入一条数据，便于测试： 123456PUT /test/goods/3&#123; "title":"小米电视4S", "images":"https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price":7999.00&#125; 现在，索引库中有2部手机，1台电视： or关系 match类型查询，会把查询条件进行分词，然后进行查询,多个词条之间是or的关系 12345678GET /test/_search&#123; &quot;query&quot;:&#123; &quot;match&quot;:&#123; &quot;title&quot;:&quot;小米电视&quot; &#125; &#125;&#125; 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 10, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 0.22108285, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125; ] &#125;&#125; 在上面的案例中，不仅会查询到电视，而且与小米相关的都会查询到，多个词之间是or的关系。 and关系 某些情况下，我们需要更精确查找，我们希望这个关系变成and，可以这样做： 12345678GET /test/_search&#123; "query":&#123; "match":&#123; "title":&#123;"query":"小米电视","operator":"and"&#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 20, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 本例中，只有同时包含小米和电视的词条才会被搜索到。 or和and之间？ 在 or 与 and 间二选一有点过于非黑即白。 如果用户给定的条件分词后有 5 个查询词项，想查找只包含其中 4 个词的文档，该如何处理？将 operator 操作符参数设置成 and 只会将此文档排除。 有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。 match 查询支持 minimum_should_match 最小匹配参数， 这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量： 1234567891011GET /test/_search&#123; "query":&#123; "match":&#123; "title":&#123; "query":"小米曲面电视", "minimum_should_match": "75%" &#125; &#125; &#125;&#125; 本例中，搜索语句可以分为3个词，如果使用and关系，需要同时满足3个词才会被搜索到。这里我们采用最小品牌数：75%，那么也就是说只要匹配到总词条数量的75%即可，这里3*75% 约等于2。所以只要包含2个词条就算满足条件了。 结果： 123456789101112131415161718192021222324252627&#123; "took" : 4, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.74487394, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.74487394, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 多字段查询（multi_match）multi_match与match类似，不同的是它可以在多个字段中查询 123456789GET /test/_search&#123; "query":&#123; "multi_match": &#123; "query": "小米", "fields": [ "title", "subTitle" ] &#125; &#125;&#125; 本例中，我们会在title字段和subtitle字段中查询小米这个词 结果： 1234567891011121314151617181920212223242526272829303132333435363738&#123; "took" : 4, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 0.22108285, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "iDZznGgB-wYBfzEzkJGx", "_score" : 0.22108285, "_source" : &#123; "title" : "小米手机", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png", "price" : 3299.0 &#125; &#125;, &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 0.15512443, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 词条匹配(term)term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字 12345678GET /test/_search&#123; "query":&#123; "term":&#123; "price":7999.00 &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "3", "_score" : 1.0, "_source" : &#123; "title" : "小米电视4S", "images" : "https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png", "price" : 7999.0 &#125; &#125; ] &#125;&#125; 多词条精确匹配(terms)terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件： 12345678GET /test/_search&#123; "query":&#123; "terms":&#123; "price":[2899.00,3299.00,7999.00] &#125; &#125;&#125; 结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#123; &quot;took&quot; : 3, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 3, &quot;successful&quot; : 3, &quot;skipped&quot; : 0, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 3, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;大米手机&quot;, &quot;images&quot; : &quot;http://image.codeopen.club/12479122.jpg&quot;, &quot;price&quot; : 2899.0 &#125; &#125;, &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;iDZznGgB-wYBfzEzkJGx&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;小米手机&quot;, &quot;images&quot; : &quot;https://i1.mifile.cn/f/i/g/2015/cn-index/note7320-220.png&quot;, &quot;price&quot; : 3299.0 &#125; &#125;, &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;goods&quot;, &quot;_id&quot; : &quot;3&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;小米电视4S&quot;, &quot;images&quot; : &quot;https://i1.mifile.cn/f/i/g/2015/cn-index/4s75.png&quot;, &quot;price&quot; : 7999.0 &#125; &#125; ] &#125;&#125; 结果过滤默认情况下，elasticsearch在搜索的结果中，会把文档中保存在_source的所有字段都返回。 如果我们只想获取其中的部分字段，我们可以添加_source的过滤 直接指定字段示例： 123456789GET /test/_search&#123; "_source": ["title","price"], "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 返回的结果： 1234567891011121314151617181920212223242526&#123; "took" : 2, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "price" : 2899.0, "title" : "大米手机" &#125; &#125; ] &#125;&#125; 指定includes和excludes我们也可以通过： includes：来指定想要显示的字段 excludes：来指定不想要显示的字段 二者都是可选的。 示例： 1234567891011GET /test/_search&#123; "_source": &#123; "includes":["title","price"] &#125;, "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 与下面的结果将是一样的： 1234567891011GET /test/_search&#123; "_source": &#123; "excludes": ["images"] &#125;, "query": &#123; "term": &#123; "price": 2899 &#125; &#125;&#125; 高级查询布尔组合（bool)bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合 12345678910GET /test/_search&#123; "query":&#123; "bool":&#123; "must": &#123; "match": &#123; "title": "大米" &#125;&#125;, "must_not": &#123; "match": &#123; "title": "电视" &#125;&#125;, "should": &#123; "match": &#123; "title": "手机" &#125;&#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.5753642, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 0.5753642, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125; ] &#125;&#125; 范围查询(range)range 查询找出那些落在指定区间内的数字或者时间 1234567891011GET /test/_search&#123; "query":&#123; "range": &#123; "price": &#123; "gte": 1000.0, "lt": 3000.00 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 3, "successful" : 3, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test", "_type" : "goods", "_id" : "2", "_score" : 1.0, "_source" : &#123; "title" : "大米手机", "images" : "http://image.codeopen.club/12479122.jpg", "price" : 2899.0 &#125; &#125; ] &#125;&#125; range查询允许以下字符： 操作符 说明 gt 大于 gte 大于等于 lt 小于 lte 小于等于 模糊查询(fuzzy)我们新增一个商品： 123456POST /test/goods/4&#123; "title":"apple手机", "images":"https://img.pconline.com.cn/images/product/5700/570024/iPhone6plus.jpg", "price":6899.00&#125; fuzzy 查询是 term 查询的模糊等价。它允许用户搜索词条与实际词条的拼写出现偏差，但是偏差的编辑距离不得超过2： 12345678GET /test/_search&#123; "query": &#123; "fuzzy": &#123; "title": "appla" &#125; &#125;&#125; 上面的查询，也能查询到apple手机 我们可以通过fuzziness来指定允许的编辑距离： 1234567891011GET /test/_search&#123; "query": &#123; "fuzzy": &#123; "title": &#123; "value":"appla", "fuzziness":1 &#125; &#125; &#125;&#125; 过滤(filter) 条件查询中进行过滤 所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式： 1234567891011GET /test/_search&#123; "query":&#123; "bool":&#123; "must":&#123; "match": &#123; "title": "小米手机" &#125;&#125;, "filter":&#123; "range":&#123;"price":&#123;"gt":2000.00,"lt":3800.00&#125;&#125; &#125; &#125; &#125;&#125; 注意：filter中还可以再次进行bool组合条件过滤。 无查询条件，直接过滤 如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。 123456789GET /test/_search&#123; "query":&#123; "constant_score": &#123; "filter": &#123; "range":&#123;"price":&#123;"gt":2000.00,"lt":3000.00&#125;&#125; &#125; &#125;&#125; 排序单字段排序sort 可以让我们按照不同的字段进行排序，并且通过order指定排序的方式 123456789101112131415GET /test/_search&#123; "query": &#123; "match": &#123; "title": "小米手机" &#125; &#125;, "sort": [ &#123; "price": &#123; "order": "desc" &#125; &#125; ]&#125; 多字段排序假定我们想要结合使用 price和 _score（得分） 进行查询，并且匹配的结果首先按照价格排序，然后按照相关性得分排序： 123456789101112131415GET /goods/_search&#123; &quot;query&quot;:&#123; &quot;bool&quot;:&#123; &quot;must&quot;:&#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;小米手机&quot; &#125;&#125;, &quot;filter&quot;:&#123; &quot;range&quot;:&#123;&quot;price&quot;:&#123;&quot;gt&quot;:200000,&quot;lt&quot;:300000&#125;&#125; &#125; &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;price&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125;, &#123; &quot;_score&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; ]&#125; 聚合aggregations聚合可以让我们极其方便的实现对数据的统计、分析。例如： 什么品牌的手机最受欢迎？ 这些手机的平均价格、最高价格、最低价格？ 这些手机每月的销售情况如何？ 实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现近实时搜索效果。 基本概念Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量： 桶（bucket） 桶的作用，是按照某种方式对数据进行分组，每一组数据在ES中称为一个桶，例如我们根据国籍对人划分，可以得到中国桶、英国桶，日本桶……或者我们按照年龄段对人进行划分：0~10,10~20,20~30,30~40等。 Elasticsearch中提供的划分桶的方式有很多： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 …… 综上所述，我们发现bucket aggregations 只负责对数据进行分组，并不进行计算，因此往往bucket中往往会嵌套另一种聚合：metrics aggregations即度量 度量（metrics） 分组完成以后，我们一般会对组中的数据进行聚合运算，例如求平均值、最大、最小、求和等，这些在ES中称为度量 比较常用的一些度量聚合方式： Avg Aggregation：求平均值 Max Aggregation：求最大值 Min Aggregation：求最小值 Percentiles Aggregation：求百分比 Stats Aggregation：同时返回avg、max、min、sum、count等 Sum Aggregation：求和 Top hits Aggregation：求前几 Value Count Aggregation：求总数 …… 为了测试聚合，我们先批量导入一些数据 创建索引： 12345678910111213141516171819PUT /cars&#123; "settings": &#123; "number_of_shards": 1, "number_of_replicas": 0 &#125;, "mappings": &#123; "transactions": &#123; "properties": &#123; "color": &#123; "type": "keyword" &#125;, "make": &#123; "type": "keyword" &#125; &#125; &#125; &#125;&#125; 注意：在ES中，需要进行聚合、排序、过滤的字段其处理方式比较特殊，因此不能被分词。这里我们将color和make这两个文字类型的字段设置为keyword类型，这个类型不会被分词，将来就可以参与聚合 导入数据 1234567891011121314151617POST /cars/transactions/_bulk&#123; "index": &#123;&#125;&#125;&#123; "price" : 10000, "color" : "red", "make" : "honda", "sold" : "2014-10-28" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 30000, "color" : "green", "make" : "ford", "sold" : "2014-05-18" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 15000, "color" : "blue", "make" : "toyota", "sold" : "2014-07-02" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 12000, "color" : "green", "make" : "toyota", "sold" : "2014-08-19" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 80000, "color" : "red", "make" : "bmw", "sold" : "2014-01-01" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 25000, "color" : "blue", "make" : "ford", "sold" : "2014-02-12" &#125; 聚合为桶首先，我们按照 汽车的颜色color来划分桶 1234567891011GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125; &#125; &#125;&#125; size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率 aggs：声明这是一个聚合查询，是aggregations的缩写 popular_colors：给这次聚合起一个名字，任意。 terms：划分桶的方式，这里是根据词条划分 field：划分桶的字段 结果： 1234567891011121314151617181920212223242526272829303132333435&#123; "took" : 8, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4 &#125;, &#123; "key" : "blue", "doc_count" : 2 &#125;, &#123; "key" : "green", "doc_count" : 2 &#125; ] &#125; &#125;&#125; hits：查询结果为空，因为我们设置了size为0 aggregations：聚合的结果 popular_colors：我们定义的聚合名称 buckets：查找到的桶，每个不同的color字段值都会形成一个桶 key：这个桶对应的color字段的值 doc_count：这个桶中的文档数量 通过聚合的结果我们发现，目前红色的小车比较畅销！ 桶内度量前面的例子告诉我们每个桶里面的文档数量，这很有用。 但通常，我们的应用需要提供更复杂的文档度量。 例如，每种颜色汽车的平均价格是多少？ 因此，我们需要告诉Elasticsearch使用哪个字段，使用何种度量方式进行运算，这些信息要嵌套在桶内，度量的运算会基于桶内的文档进行 现在，我们为刚刚的聚合结果添加 求价格平均值的度量： 123456789101112131415161718GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125; &#125; &#125; &#125;&#125; aggs：我们在上一个aggs(popular_colors)中添加新的aggs。可见度量也是一个聚合 avg_price：聚合的名称 avg：度量的类型，这里是求平均值 field：度量运算的字段 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&#123; "took" : 10, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4, "avg_price" : &#123; "value" : 32500.0 &#125; &#125;, &#123; "key" : "blue", "doc_count" : 2, "avg_price" : &#123; "value" : 20000.0 &#125; &#125;, &#123; "key" : "green", "doc_count" : 2, "avg_price" : &#123; "value" : 21000.0 &#125; &#125; ] &#125; &#125;&#125; 可以看到每个桶中都有自己的avg_price字段，这是度量聚合的结果 桶内嵌套桶刚刚的案例中，我们在桶内嵌套度量运算。事实上桶不仅可以嵌套运算， 还可以再嵌套其它桶。也就是说在每个分组中，再分更多组。 比如：我们想统计每种颜色的汽车中，分别属于哪个制造商，按照make字段再进行分桶 1234567891011121314151617181920212223GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125;, "maker":&#123; "terms":&#123; "field":"make" &#125; &#125; &#125; &#125; &#125;&#125; 原来的color桶和avg计算我们不变 maker：在嵌套的aggs下新添一个桶，叫做maker terms：桶的划分类型依然是词条 filed：这里根据make字段进行划分 结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "popular_colors" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "red", "doc_count" : 4, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "honda", "doc_count" : 3 &#125;, &#123; "key" : "bmw", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 32500.0 &#125; &#125;, &#123; "key" : "blue", "doc_count" : 2, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "ford", "doc_count" : 1 &#125;, &#123; "key" : "toyota", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 20000.0 &#125; &#125;, &#123; "key" : "green", "doc_count" : 2, "maker" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123; "key" : "ford", "doc_count" : 1 &#125;, &#123; "key" : "toyota", "doc_count" : 1 &#125; ] &#125;, "avg_price" : &#123; "value" : 21000.0 &#125; &#125; ] &#125; &#125;&#125; 我们可以看到，新的聚合maker被嵌套在原来每一个color的桶中。 每个颜色下面都根据 make字段进行了分组 我们能读取到的信息： 红色车共有4辆 红色车的平均售价是 $32，500 美元。 其中3辆是 Honda 本田制造，1辆是 BMW 宝马制造。 划分桶的其它方式前面讲了，划分桶的方式有很多，例如： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 刚刚的案例中，我们采用的是Terms Aggregation，即根据词条划分桶。 接下来，我们再学习几个比较实用的： 阶梯分桶Histogram 原理： histogram是把数值类型的字段，按照一定的阶梯大小进行分组。你需要指定一个阶梯值（interval）来划分阶梯大小。 举例： 比如你有价格字段，如果你设定interval的值为200，那么阶梯就会是这样的： 0，200，400，600，… 上面列出的是每个阶梯的key，也是区间的启点。 如果一件商品的价格是450，会落入哪个阶梯区间呢？计算公式如下： 1bucket_key = Math.floor((value - offset) / interval) * interval + offset value：就是当前数据的值，本例中是450 offset：起始偏移量，默认为0 interval：阶梯间隔，比如200 因此你得到的key = Math.floor((450 - 0) / 200) * 200 + 0 = 400 操作一下： 比如，我们对汽车的价格进行分组，指定间隔interval为5000： 123456789101112GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&#123; "took" : 5, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "price" : &#123; "buckets" : [ &#123; "key" : 10000.0, "doc_count" : 2 &#125;, &#123; "key" : 15000.0, "doc_count" : 1 &#125;, &#123; "key" : 20000.0, "doc_count" : 2 &#125;, &#123; "key" : 25000.0, "doc_count" : 1 &#125;, &#123; "key" : 30000.0, "doc_count" : 1 &#125;, &#123; "key" : 35000.0, "doc_count" : 0 &#125;, &#123; "key" : 40000.0, "doc_count" : 0 &#125;, &#123; "key" : 45000.0, "doc_count" : 0 &#125;, &#123; "key" : 50000.0, "doc_count" : 0 &#125;, &#123; "key" : 55000.0, "doc_count" : 0 &#125;, &#123; "key" : 60000.0, "doc_count" : 0 &#125;, &#123; "key" : 65000.0, "doc_count" : 0 &#125;, &#123; "key" : 70000.0, "doc_count" : 0 &#125;, &#123; "key" : 75000.0, "doc_count" : 0 &#125;, &#123; "key" : 80000.0, "doc_count" : 1 &#125; ] &#125; &#125;&#125; 你会发现，中间有大量的文档数量为0 的桶，看起来很丑。 我们可以增加一个参数min_doc_count为1，来约束最少文档数量为1，这样文档数量为0的桶会被过滤 示例： 12345678910111213GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000, "min_doc_count": 1 &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 8, "max_score" : 0.0, "hits" : [ ] &#125;, "aggregations" : &#123; "price" : &#123; "buckets" : [ &#123; "key" : 10000.0, "doc_count" : 2 &#125;, &#123; "key" : 15000.0, "doc_count" : 1 &#125;, &#123; "key" : 20000.0, "doc_count" : 2 &#125;, &#123; "key" : 25000.0, "doc_count" : 1 &#125;, &#123; "key" : 30000.0, "doc_count" : 1 &#125;, &#123; "key" : 80000.0, "doc_count" : 1 &#125; ] &#125; &#125;&#125; 完美，！ 如果你用kibana将结果变为柱形图，会更好看： 范围分桶range范围分桶与阶梯分桶类似，也是把数字按照阶段进行分组，只不过range方式需要你自己指定每一组的起始和结束大小。 Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方： 很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的 需要自己把对象序列化为json存储 查询到结果也需要自己反序列化为对象 因此，我们这里就不讲解原生的Elasticsearch客户端API了。 而是学习Spring提供的套件：Spring Data Elasticsearch 简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。 查看 Spring Data的官网：http://projects.spring.io/spring-data/ Spring Data 是的使命是给各种数据访问提供统一的编程接口，不管是关系型数据库（如MySQL），还是非关系数据库（如Redis），或者类似Elasticsearch这样的索引数据库。从而简化开发人员的代码，提高开发效率。 包含很多不同数据操作的模块： Spring Data Elasticsearch的页面：https://projects.spring.io/spring-data-elasticsearch/ 特征： 支持Spring的基于@Configuration的java配置方式，或者XML配置方式 提供了用于操作ES的便捷工具类ElasticsearchTemplate。包括实现文档到POJO之间的自动智能映射。 利用Spring的数据转换服务实现的功能丰富的对象映射 基于注解的元数据映射方式，而且可扩展以支持更多不同的数据格式 根据持久层接口自动生成对应实现方法，无需人工编写基本操作代码（类似mybatis，根据接口自动得到实现）。当然，也支持人工定制查询 创建Demo工程我们新建一个Maven项目，学习Elasticsearch pom依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.study.demo&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;elasticsearch&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml文件配置： 12345spring: data: elasticsearch: cluster-name: elasticsearch cluster-nodes: 119.23.208.179:9300 索引操作创建索引和映射 实体类 首先我们准备好实体类： 12345678public class Item &#123; Long id; String title; //标题 String category;// 分类 String brand; // 品牌 Double price; // 价格 String images; // 图片地址&#125; 映射 Spring Data通过注解来声明字段的映射属性，有下面的三个注解： @Document 作用在类，标记实体类为文档对象，一般有两个属性 indexName：对应索引库名称 type：对应在索引库中的类型 shards：分片数量，默认5 replicas：副本数量，默认1 @Id 作用在成员变量，标记一个字段作为id主键 @Field 作用在成员变量，标记为文档的字段，并指定字段映射属性： type：字段类型，是是枚举：FieldType index：是否索引，布尔类型，默认是true store：是否存储，布尔类型，默认是false analyzer：分词器名称 示例： 1234567891011121314151617181920@Document(indexName = "item",type = "docs", shards = 1, replicas = 0)public class Item &#123; @Id private Long id; @Field(type = FieldType.Text, analyzer = "ik_max_word") private String title; //标题 @Field(type = FieldType.Keyword) private String category;// 分类 @Field(type = FieldType.Keyword) private String brand; // 品牌 @Field(type = FieldType.Double) private Double price; // 价格 @Field(index = false, type = FieldType.Keyword) private String images; // 图片地址&#125; 创建索引 ElasticsearchTemplate中提供了创建索引的API： 可以根据类的信息自动生成，也可以手动指定indexName和Settings 映射 映射相关的API： 一样，可以根据类的字节码信息（注解配置）来生成映射，或者手动编写映射 我们这里采用类的字节码信息创建索引并映射： 1234567@Testpublic void createIndex() &#123; // 创建索引，会根据Item类的@Document注解信息来创建 esTemplate.createIndex(Item.class); // 配置映射，会根据Item类中的id、Field等字段来自动完成映射 esTemplate.putMapping(Item.class);&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445GET /item&#123; "item": &#123; "aliases": &#123;&#125;, "mappings": &#123; "docs": &#123; "properties": &#123; "brand": &#123; "type": "keyword" &#125;, "category": &#123; "type": "keyword" &#125;, "images": &#123; "type": "keyword", "index": false &#125;, "price": &#123; "type": "double" &#125;, "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125; &#125; &#125; &#125;, "settings": &#123; "index": &#123; "refresh_interval": "1s", "number_of_shards": "1", "provided_name": "item", "creation_date": "1525405022589", "store": &#123; "type": "fs" &#125;, "number_of_replicas": "0", "uuid": "4sE9SAw3Sqq1aAPz5F6OEg", "version": &#123; "created": "6020499" &#125; &#125; &#125; &#125;&#125; 删除索引删除索引的API： 可以根据类名或索引名删除。 示例： 1234@Testpublic void deleteIndex() &#123; esTemplate.deleteIndex("test");&#125; 结果： 新增文档数据Repository接口Spring Data 的强大之处，就在于你不用写任何DAO处理，自动根据方法名或类的信息进行CRUD操作。只要你定义一个接口，然后继承Repository提供的一些子接口，就能具备各种基本的CRUD功能。 来看下Repository的继承关系： 我们看到有一个ElasticsearchCrudRepository接口： 所以，我们只需要定义接口，然后继承它就OK了。 12public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; &#123;&#125; 接下来，我们测试新增数据： 一个对象123456789@Autowiredprivate ItemRepository itemRepository;@Testpublic void index() &#123; Item item = new Item(1L, "小米手机7", " 手机", "小米", 3499.00, "http://image.codeopen.club/13123.jpg"); itemRepository.save(item);&#125; 去页面查询看看： 12345678910111213141516171819202122232425262728293031&#123; "took": 0, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 1, "max_score": 1, "hits": [ &#123; "_index": "item", "_type": "docs", "_id": "1", "_score": 1, "_source": &#123; "id": 1, "title": "小米手机7", "category": " 手机", "brand": "小米", "price": 3499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125; &#125; ] &#125;&#125; 批量新增代码： 12345678@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(2L, "坚果手机R1", " 手机", "锤子", 3699.00, "http://image.codeopen.club/123.jpg")); list.add(new Item(3L, "华为META10", " 手机", "华为", 4499.00, "http://image.codeopen.club/3.jpg")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 再次去页面查询： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#123; "took": 5, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 3, "max_score": 1, "hits": [ &#123; "_index": "item", "_type": "docs", "_id": "2", "_score": 1, "_source": &#123; "id": 2, "title": "坚果手机R1", "category": " 手机", "brand": "锤子", "price": 3699, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125;, &#123; "_index": "item", "_type": "docs", "_id": "3", "_score": 1, "_source": &#123; "id": 3, "title": "华为META10", "category": " 手机", "brand": "华为", "price": 4499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125;, &#123; "_index": "item", "_type": "docs", "_id": "1", "_score": 1, "_source": &#123; "id": 1, "title": "小米手机7", "category": " 手机", "brand": "小米", "price": 3499, "images": "http://image.codeopen.club/13123.jpg" &#125; &#125; ] &#125;&#125; 修改修改和新增是同一个接口，区分的依据就是id，这一点跟我们在页面发起PUT请求是类似的。 查询基本查询ElasticsearchRepository提供了一些基本的查询方法： 我们来试试查询所有： 12345678@Testpublic void query()&#123; // 查询全部，并安装价格降序排序 Iterable&lt;Item&gt; items = this.itemRepository.findAll(Sort.by("price").descending()); for (Item item : items) &#123; System.out.println("item = " + item); &#125;&#125; 结果： 自定义方法Spring Data 的另一个强大功能，是根据方法名称自动实现功能。 比如：你的方法名叫做：findByTitle，那么它就知道你是根据title查询，然后自动帮你完成，无需写实现类。 当然，方法名称要符合一定的约定： Keyword Sample Elasticsearch Query String And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 例如，我们来按照价格区间查询，定义这样的一个方法： 12345678910public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; &#123; /** * 根据价格区间查询 * @param price1 * @param price2 * @return */ List&lt;Item&gt; findByPriceBetween(double price1, double price2);&#125; 然后添加一些测试数据： 1234567891011@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1L, "小米手机7", "手机", "小米", 3299.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(2L, "坚果手机R1", "手机", "锤子", 3699.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(3L, "华为META10", "手机", "华为", 4499.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(4L, "小米Mix2S", "手机", "小米", 4299.00, "http://image.leyou.com/13123.jpg")); list.add(new Item(5L, "荣耀V10", "手机", "华为", 2799.00, "http://image.leyou.com/13123.jpg")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 不需要写实现类，然后我们直接去运行： 1234567@Testpublic void queryByPriceBetween()&#123; List&lt;Item&gt; list = this.itemRepository.findByPriceBetween(2000.00, 3500.00); for (Item item : list) &#123; System.out.println("item = " + item); &#125;&#125; 结果： 自定义查询先来看最基本的match query： 123456789101112131415@Testpublic void search()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.matchQuery("title", "小米手机")); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("total = " + total); for (Item item : items) &#123; System.out.println(item); &#125;&#125; NativeSearchQueryBuilder：Spring提供的一个查询条件构建器，帮助构建json格式的请求体 QueryBuilders.matchQuery(“title”, “小米手机”)：利用QueryBuilders来生成一个查询。QueryBuilders提供了大量的静态方法，用于生成各种不同类型的查询： Page&lt;item&gt;：默认是分页查询，因此返回的是一个分页的结果对象，包含属性： totalElements：总条数 totalPages：总页数 Iterator：迭代器，本身实现了Iterator接口，因此可直接迭代得到当前页的数据 其它属性： 结果： 分页查询利用NativeSearchQueryBuilder可以方便的实现分页： 123456789101112131415161718192021222324252627@Testpublic void searchByPage()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.termQuery("category", "手机")); // 分页： int page = 0; int size = 2; queryBuilder.withPageable(PageRequest.of(page,size)); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("总条数 = " + total); // 总页数 System.out.println("总页数 = " + items.getTotalPages()); // 当前页 System.out.println("当前页：" + items.getNumber()); // 每页大小 System.out.println("每页大小：" + items.getSize()); for (Item item : items) &#123; System.out.println(item); &#125;&#125; 可以发现，Elasticsearch中的分页是从第0页开始。 排序排序也通用通过NativeSearchQueryBuilder完成： 1234567891011121314151617181920@Testpublic void searchAndSort()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本分词查询 queryBuilder.withQuery(QueryBuilders.termQuery("category", "手机")); // 排序 queryBuilder.withSort(SortBuilders.fieldSort("price").order(SortOrder.ASC)); // 搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 总条数 long total = items.getTotalElements(); System.out.println("总条数 = " + total); for (Item item : items) &#123; System.out.println(item); &#125;&#125; 结果： 聚合聚合为桶桶就是分组，比如这里我们按照品牌brand进行分组： 12345678910111213141516171819202122232425@Testpublic void testAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms("brands").field("brand")); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("brands"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即品牌名称 System.out.println(bucket.getKeyAsString()); // 3.5、获取桶中的文档数量 System.out.println(bucket.getDocCount()); &#125;&#125; 显示的结果： 关键API： AggregationBuilders：聚合的构建工厂类。所有聚合都由这个类来构建，看看他的静态方法： AggregatedPage：聚合查询的结果类。它是Page&lt;T&gt;的子接口： AggregatedPage在Page功能的基础上，拓展了与聚合相关的功能，它其实就是对聚合结果的一种封装，大家可以对照聚合结果的JSON结构来看。 而返回的结果都是Aggregation类型对象，不过根据字段类型不同，又有不同的子类表示 我们看下页面的查询的JSON结果与Java类的对照关系： 嵌套聚合，求平均值代码： 1234567891011121314151617181920212223242526272829@Testpublic void testSubAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms("brands").field("brand") .subAggregation(AggregationBuilders.avg("priceAvg").field("price")) // 在品牌聚合桶内进行嵌套聚合，求平均值 ); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("brands"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即品牌名称 3.5、获取桶中的文档数量 System.out.println(bucket.getKeyAsString() + "，共" + bucket.getDocCount() + "台"); // 3.6.获取子聚合结果： InternalAvg avg = (InternalAvg) bucket.getAggregations().asMap().get("priceAvg"); System.out.println("平均售价：" + avg.getValue()); &#125;&#125; 结果：]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Docker 安装 FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2FFastDFS%2F%E5%9F%BA%E4%BA%8E%20Docker%20%E5%AE%89%E8%A3%85%20FastDFS%2F</url>
    <content type="text"><![CDATA[环境准备所需全部环境配置文件及安装包 libfastcommon.tar.gz fastdfs-5.11.tar.gz nginx-1.13.6.tar.gz fastdfs-nginx-module_v1.16.tar.gz 创建工作目录在 Linux 服务器上创建 /usr/local/docker/fastdfs/environmen 目录 说明： /usr/local/docker/fastdfs：用于存放 docker-compose.yml 配置文件及 FastDFS 的数据卷 /usr/local/docker/fastdfs/environmen：用于存放 Dockerfile 镜像配置文件及 FastDFS 所需环境 docker-compose.yml123456789version: '3.1'services: fastdfs: build: environment restart: always container_name: fastdfs volumes: - ./storage:/fastdfs/storage network_mode: host Dockerfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960FROM ubuntu:xenialMAINTAINER topsale@vip.qq.com# 更新数据源WORKDIR /etc/aptRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiverse&apos; &gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse&apos; &gt;&gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse&apos; &gt;&gt; sources.listRUN echo &apos;deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse&apos; &gt;&gt; sources.listRUN apt-get update# 安装依赖RUN apt-get install make gcc libpcre3-dev zlib1g-dev --assume-yes# 复制工具包ADD fastdfs-5.11.tar.gz /usr/local/srcADD fastdfs-nginx-module_v1.16.tar.gz /usr/local/srcADD libfastcommon.tar.gz /usr/local/srcADD nginx-1.13.6.tar.gz /usr/local/src# 安装 libfastcommonWORKDIR /usr/local/src/libfastcommonRUN ./make.sh &amp;&amp; ./make.sh install# 安装 FastDFSWORKDIR /usr/local/src/fastdfs-5.11RUN ./make.sh &amp;&amp; ./make.sh install# 配置 FastDFS 跟踪器ADD tracker.conf /etc/fdfsRUN mkdir -p /fastdfs/tracker# 配置 FastDFS 存储ADD storage.conf /etc/fdfsRUN mkdir -p /fastdfs/storage# 配置 FastDFS 客户端ADD client.conf /etc/fdfs# 配置 fastdfs-nginx-moduleADD config /usr/local/src/fastdfs-nginx-module/src# FastDFS 与 Nginx 集成WORKDIR /usr/local/src/nginx-1.13.6RUN ./configure --add-module=/usr/local/src/fastdfs-nginx-module/srcRUN make &amp;&amp; make installADD mod_fastdfs.conf /etc/fdfsWORKDIR /usr/local/src/fastdfs-5.11/confRUN cp http.conf mime.types /etc/fdfs/# 配置 NginxADD nginx.conf /usr/local/nginx/confCOPY entrypoint.sh /usr/local/bin/ENTRYPOINT [&quot;/usr/local/bin/entrypoint.sh&quot;]WORKDIR /EXPOSE 8888CMD [&quot;/bin/bash&quot;] entrypoint.sh1234#!/bin/sh/etc/init.d/fdfs_trackerd start/etc/init.d/fdfs_storaged start/usr/local/nginx/sbin/nginx -g &apos;daemon off;&apos; 注：Shell 创建后是无法直接使用的，需要赋予执行的权限，使用 chmod +x entrypoint.sh 命令 各种配置文件说明tracker.confFastDFS 跟踪器配置，容器中路径为：/etc/fdfs，修改为： 1base_path=/fastdfs/tracker storage.confFastDFS 存储配置，容器中路径为：/etc/fdfs，修改为： 1234base_path=/fastdfs/storagestore_path0=/fastdfs/storagetracker_server=192.168.75.128:22122http.server_port=8888 client.confFastDFS 客户端配置，容器中路径为：/etc/fdfs，修改为： 12base_path=/fastdfs/trackertracker_server=192.168.75.128:22122 configfastdfs-nginx-module 配置文件，容器中路径为：/usr/local/src/fastdfs-nginx-module/src，修改为： 1234567# 修改前CORE_INCS=&quot;$CORE_INCS /usr/local/include/fastdfs /usr/local/include/fastcommon/&quot;CORE_LIBS=&quot;$CORE_LIBS -L/usr/local/lib -lfastcommon -lfdfsclient&quot;# 修改后CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot;CORE_LIBS=&quot;$CORE_LIBS -L/usr/lib -lfastcommon -lfdfsclient&quot; mod_fastdfs.conffastdfs-nginx-module 配置文件，容器中路径为：/usr/local/src/fastdfs-nginx-module/src，修改为： 1234connect_timeout=10tracker_server=192.168.75.128:22122url_have_group_name = truestore_path0=/fastdfs/storage nginx.confNginx 配置文件，容器中路径为：/usr/local/src/nginx-1.13.6/conf，修改为： 1234567891011121314151617181920212223242526272829user root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 8888; server_name localhost; location ~/group([0-9])/M00 &#123; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 启动容器1docker-compose up -d 测试上传交互式进入容器1docker exec -it fastdfs /bin/bash 测试文件上传1/usr/bin/fdfs_upload_file /etc/fdfs/client.conf /usr/local/src/fastdfs-5.11/INSTALL 服务器反馈上传地址1group1/M00/00/00/wKhLi1oHVMCAT2vrAAAeSwu9hgM3976341 测试 Nginx 访问1http://192.168.0.128:8888/group1/M00/00/00/wKhLi1oHVMCAT2vrAAAeSwu9hgM3976341]]></content>
      <categories>
        <category>FastDFS</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下安装FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2FFastDFS%2FUbuntu%E4%B8%8B%E5%AE%89%E8%A3%85FastDFS%2F</url>
    <content type="text"><![CDATA[Ubuntu安装FastDFS安装依赖安装libevent1234567891011121314防火墙ufw enableufw disable自启动管理：apt-get install sysv-rc-confapt-get install makeapt-get install unzipapt-get install gccapt-get install libevent-dev 安装libfastcommon通过git下载即可： https://github.com/happyfish100/libfastcommon.git 12apt install unzipapt install gcc nginx依赖12345678910111213安装gcc g++的依赖库sudo apt-get install build-essentialsudo apt-get install libtool安装pcre依赖库（http://www.pcre.org/）sudo apt-get updatesudo apt-get install libpcre3 libpcre3-dev安装zlib依赖库（http://www.zlib.net）sudo apt-get install zlib1g-dev安装SSL依赖库（16.04默认已经安装了）sudo apt-get install openssl]]></content>
      <categories>
        <category>FastDFS</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下安装FastDFS]]></title>
    <url>%2F2019%2F01%2F29%2FFastDFS%2FCentos%E4%B8%8B%E5%AE%89%E8%A3%85FastDFS%2F</url>
    <content type="text"><![CDATA[Centos下安装FastDFS安装依赖FastDFS运行需要一些依赖，在课前资料提供的虚拟中已经安装好了这些依赖，如果大家想要从头学习，可以按下面方式安装： 安装GCC依赖GCC用来对C语言代码进行编译运行，使用yum命令安装： 1sudo yum -y install gcc 安装unzip工具unzip工具可以帮我们对压缩包进行解压 1sudo yum install -y unzip zip 安装libevent1sudo yum -y install libevent 安装Nginx所需依赖1sudo yum -y install pcre pcre-devel zlib zlib-devel openssl openssl-devel 安装libfastcommon-master这个没有yum包，只能通过编译安装： 解压刚刚上传的libfastcommon-master.zip 1unzip libfastcommon-master.zip 进入解压完成的目录： 1cd libfastcommon-master 编译并且安装： 12sudo ./make.sh sudo ./make.sh install 到这里为止，所有依赖都已经安装完毕，接下来我们安装FastDFS： 安装FastDFS编译安装这里我们也采用编译安装，步骤与刚才的编译安装方式一样： 解压 1tar -xvf FastDFS_v5.08.tar.gz 进入目录 1cd FastDFS 编译并安装 12sudo ./make.sh sudo ./make.sh install 校验安装结果 1）安装完成，我们应该能在/etc/init.d/目录，通过命令ll /etc/init.d/ | grep fdfs看到FastDFS提供的启动脚本： 其中： fdfs_trackerd 是tracker启动脚本 fdfs_storaged 是storage启动脚本 2）我们可以在 /etc/fdfs目录，通过命令查看到以下配置文件模板： 其中： tarcker.conf.sample 是tracker的配置文件模板 storage.conf.sample 是storage的配置文件模板 client.conf.sample 是客户端的配置文件模板 启动trackercdFastDFS的tracker和storage在刚刚的安装过程中，都已经被安装了，因此我们安装这两种角色的方式是一样的。不同的是，两种需要不同的配置文件。 我们要启动tracker，就修改刚刚看到的tarcker.conf，并且启动fdfs_trackerd脚本即可。 编辑tracker配置 首先我们将模板文件进行赋值和重命名： 12sudo cp tracker.conf.sample tracker.confsudo vim tracker.conf 打开tracker.conf，修改base_path配置： 1base_path=/leyou/fdfs/tracker # tracker的数据和日志存放目录 创建目录 刚刚配置的目录可能不存在，我们创建出来 1sudo mkdir -p /leyou/fdfs/tracker 启动tracker 我们可以使用 sh /etc/init.d/fdfs_trackerd 启动，不过安装过程中，fdfs已经被设置为系统服务，我们可以采用熟悉的服务启动方式： 1sudo service fdfs_trackerd start # 启动fdfs_trackerd服务，停止用stop 另外，我们可以通过以下命令，设置tracker开机启动： 1sudo chkconfig fdfs_trackerd on 启动storage我们要启动tracker，就修改刚刚看到的tarcker.conf，并且启动fdfs_trackerd脚本即可。 编辑storage配置 首先我们将模板文件进行赋值和重命名： 12sudo cp storage.conf.sample storage.confsudo vim storage.conf 打开storage.conf，修改base_path配置： 123base_path=/leyou/fdfs/storage # storage的数据和日志存放目录store_path0=/leyou/fdfs/storage # storage的上传文件存放路径tracker_server=192.168.56.101:22122 # tracker的地址 创建目录 刚刚配置的目录可能不存在，我们创建出来 1sudo mkdir -p /leyou/fdfs/storage 启动storage 我们可以使用 sh /etc/init.d/fdfs_storaged 启动，同样我们可以用服务启动方式： 1sudo service fdfs_storaged start # 启动fdfs_storaged服务，停止用stop 另外，我们可以通过以下命令，设置tracker开机启动： 1sudo chkconfig fdfs_storaged on 最后，通过ps -ef | grep fdfs 查看进程： 安装Nginx及FastDFS模块FastDFS的Nginx模块 解压 1tar -xvf fastdfs-nginx-module_v1.16.tar.gz ​ 配置config文件 123456# 进入配置目录cd /home/leyou/fdfs/fastdfs-nginx-module/src/# 修改配置vim config# 执行下面命令（将配置中的/usr/local改为/usr）：:%s+/usr/local/+/usr/+g ​ 配置mod_fastdfs.conf 1234# 将src目录下的mod_fastdfs.conf复制到 /etc/fdfs目录：sudo cp mod_fastdfs.conf /etc/fdfs/# 编辑该文件sudo vim /etc/fdfs/mod_fastdfs.conf 修改一下配置： 1234connect_timeout=10 # 客户端访问文件连接超时时长（单位：秒）tracker_server=192.168.56.101:22122 # tracker服务IP和端口url_have_group_name=true # 访问链接前缀加上组名store_path0=/leyou/fdfs/storage # 文件存储路径 复制 FastDFS的部分配置文件到/etc/fdfs目录 12cd /home/leyou/fdfs/FastDFS/conf/cp http.conf mime.types /etc/fdfs/ ​ 安装Nginx 解压 1tar -xvf nginx-1.10.0.tar.gz ​ 配置 1sudo ./configure --prefix=/opt/nginx --sbin-path=/usr/bin/nginx --add-module=/home/leyou/fdfs/fastdfs-nginx-module/src ​ 编译安装 1sudo make &amp;&amp; sudo make install ​ 配置nginx整合fastdfs-module模块 我们需要修改nginx配置文件，在/opt/nginx/config/nginx.conf文件中： 1sudo vim /opt/nginx/conf/nginx.conf 将文件中，原来的server 80{ ...} 部分代码替换为如下代码： 12345678910111213141516171819server &#123; listen 80; server_name image.leyou.com; # 监听域名中带有group的，交给FastDFS模块处理 location ~/group([0-9])/ &#123; ngx_fastdfs_module; &#125; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 启动 123nginx # 启动nginx -s stop # 停止nginx -s reload # 重新加载配置 设置nginx开机启动 创建一个开机启动的脚本： 1vim /etc/init.d/nginx 添加以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15# description: NGINX is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid# Source function library.. /etc/rc.d/init.d/functions# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0nginx="/usr/bin/nginx"prog=$(basename $nginx)NGINX_CONF_FILE="/opt/nginx/conf/nginx.conf"[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginxlockfile=/var/lock/subsys/nginxmake_dirs() &#123; # make required directories user=`$nginx -V 2&gt;&amp;1 | grep "configure arguments:.*--user=" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` if [ -n "$user" ]; then if [ -z "`grep $user /etc/passwd`" ]; then useradd -M -s /bin/nologin $user fi options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done fi&#125;start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; configtest || return $? stop sleep 1 start&#125;reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125;force_reload() &#123; restart&#125;configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 修改文件权限，并加入服务列表 1234# 修改权限chmod 777 /etc/init.d/nginx # 添加到服务列表chkconfig --add /etc/init.d/nginx 设置开机启动 1systemctl enable nginx]]></content>
      <categories>
        <category>FastDFS</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS快速入门]]></title>
    <url>%2F2019%2F01%2F28%2FFastDFS%2FFastDFS%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是FastDFSFastDFS是由淘宝的余庆先生所开发的一个轻量级、高性能的开源分布式文件系统。用纯C语言开发，功能丰富： 文件存储 文件同步 文件访问（上传、下载） 存取负载均衡 在线扩容 适合有大容量存储需求的应用或系统。同类的分布式文件系统有谷歌的GFS、HDFS（Hadoop）、TFS（淘宝）等。 FastDFS的架构架构图先上图： FastDFS两个主要的角色：Tracker Server 和 Storage Server 。 Tracker Server：跟踪服务器，主要负责调度storage节点与client通信，在访问上起负载均衡的作用，和记录storage节点的运行状态，是连接client和storage节点的枢纽。 Storage Server：存储服务器，保存文件和文件的meta data（元数据），每个storage server会启动一个单独的线程主动向Tracker cluster中每个tracker server报告其状态信息，包括磁盘使用情况，文件同步情况及文件上传下载次数统计等信息 Group：文件组，多台Storage Server的集群。上传一个文件到同组内的一台机器上后，FastDFS会将该文件即时同步到同组内的其它所有机器上，起到备份的作用。不同组的服务器，保存的数据不同，而且相互独立，不进行通信。 Tracker Cluster：跟踪服务器的集群，有一组Tracker Server（跟踪服务器）组成。 Storage Cluster ：存储集群，有多个Group组成。 上传和下载流程 上传 Client通过Tracker server查找可用的Storage server。 Tracker server向Client返回一台可用的Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并进行文件上传。 上传完成，Storage server返回Client一个文件ID，文件上传结束。 下载 Client通过Tracker server查找要下载文件所在的的Storage server。 Tracker server向Client返回包含指定文件的某个Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并指定要下载文件。 下载文件成功。 安装和使用安装资源准备，将如下文件下载 百度云盘资源下载地址 Centos安装：站内搜索Centos下安装FastDFSUbuntu安装：站内搜索``java客户端余庆先生提供了一个Java客户端，但是作为一个C程序员，写的java代码可想而知。而且已经很久不维护了。 这里推荐一个开源的FastDFS客户端，支持最新的SpringBoot2.0。 配置使用极为简单，支持连接池，支持自动生成缩略图，狂拽酷炫吊炸天啊，有木有。 地址：tobato/FastDFS_client 引入依赖在父工程中，我们已经管理了依赖，版本为： 1&lt;fastDFS.client.version&gt;1.26.2&lt;/fastDFS.client.version&gt; 因此，这里我们直接引入坐标即可： 1234&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;&lt;/dependency&gt; 引入配置类纯java配置： 123456@Configuration@Import(FdfsClientConfig.class)// 解决jmx重复注册bean的问题@EnableMBeanExport(registration = RegistrationPolicy.IGNORE_EXISTING)public class FastClientImporter &#123;&#125; 编写FastDFS属性12345678fdfs: so-timeout: 1501 connect-timeout: 601 thumb-image: # 缩略图 width: 60 height: 60 tracker-list: # tracker地址 - FastDFS主机IP:22122 测试12345678910111213141516171819202122232425262728293031323334353637@RunWith(SpringRunner.class)@SpringBootTest(classes = UploadService.class)public class FdfsTest &#123; @Autowired private FastFileStorageClient storageClient; @Autowired private ThumbImageConfig thumbImageConfig; @Test public void testUpload() throws FileNotFoundException &#123; File file = new File("D:\\test\\baby.png"); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadFile( new FileInputStream(file), file.length(), "png", null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); &#125; @Test public void testUploadAndCreateThumb() throws FileNotFoundException &#123; File file = new File("D:\\test\\baby.png"); // 上传并且生成缩略图 StorePath storePath = this.storageClient.uploadImageAndCrtThumbImage( new FileInputStream(file), file.length(), "png", null); // 带分组的路径 System.out.println(storePath.getFullPath()); // 不带分组的路径 System.out.println(storePath.getPath()); // 获取缩略图路径 String path = thumbImageConfig.getThumbImagePath(storePath.getPath()); System.out.println(path); &#125;&#125;]]></content>
      <categories>
        <category>FastDFS</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Mybatis分页助手pagehelper]]></title>
    <url>%2F2019%2F01%2F28%2Fspring-boot%2FSpringBoot%E6%95%B4%E5%90%88Mybatis%E5%88%86%E9%A1%B5%E5%8A%A9%E6%89%8B%2F</url>
    <content type="text"><![CDATA[文档 github地址 使用案例 快速上手在 pom.xml 中添加如下依赖：123456789101112131415161718&lt;!--mybatis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--mapper--&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;!--pagehelper--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.10&lt;/version&gt;&lt;/dependency&gt; 在service中使用分页助手1234567891011121314151617181920212223242526272829@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; public PageResult&lt;User&gt; queryUserByPageAndSort( Integer page, Integer rows, String sortBy, Boolean desc, String key) &#123; // 开始分页 PageHelper.startPage(page, rows); // 过滤 Example example = new Example(User.class); if (StringUtils.isNotBlank(key)) &#123; example.createCriteria().andLike("name", "%" + key + "%") .orEqualTo("letter", key.toUpperCase()); &#125; if (StringUtils.isNotBlank(sortBy)) &#123; // 排序 String orderByClause = sortBy + (desc ? " DESC" : " ASC"); example.setOrderByClause(orderByClause); &#125; // 查询 List&lt;User&gt; list = (Page&lt;User&gt;) brandMapper.selectByExample(example); // 解析分页结果 PageInfo&lt;User&gt; info = new PageInfo&lt;&gt;(list); // 返回结果 return new PageResult&lt;&gt;(info.getTotal(),list); &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
        <category>pagehelper</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>pagehelper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通用异常处理]]></title>
    <url>%2F2019%2F01%2F26%2FdevNote%2F%E9%80%9A%E7%94%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[在项目中出现异常是在所难免的，但是出现异常后怎么处理，这就是很有学问了。 场景预设场景我们预设这样一个场景，假如我们做新增商品，需要接受下面的参数： 12price: 价格name: 名称 然后对数据做简单校验 价格不能为空 新增时，自动形成ID，然后随商品对象一起返回 代码为了操作方便，使用假数据，不涉及持久层 实体类： 123456@Data // lombokpublic class Item&#123; private Integer id; private String name; private Long price;&#125; service： 12345678910@Servicepublic class ItemService &#123; // 商品新增 public Item saveItem(Item item)&#123; int id = new Random().nextInt(100); item.setId(id); return item; &#125;&#125; controller： 12345678910111213141516@RestController@RequestMapping("item")public class ItemController &#123; @Autowired private ItemService itemService; @PostMapping public ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(null); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item)); &#125;&#125; 响应状态码： Code HTTP Operation Body Contents Description 200 GET,PUT 资源 操作成功 201 POST 资源，元数据 对象创建成功 202 POST,PUT,DELETE,PATCH N/A 请求已经被接受 204 PUT,DELETE,PATCH N/A 操作已经执行成功，但是没有返回数据 301 GET link 资源已被移除 303 GET link 重定向 304 GET N/A 资源没有被修改 400 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 参数列表错误(缺少，格式不匹配) 401 GET,POST,PUT,DELETE,PATCH 错误提示(消息) w未授权 403 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 访问受限，授权过期 404 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 资源，服务未找到 405 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 不允许的http方法 409 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 资源冲突，或者资源被锁定 415 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 不支持的数据(媒体)类型 429 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 请求过多被限制 500 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 系统内部错误 501 GET,POST,PUT,DELETE,PATCH 错误提示(消息) 接口未实现 统一异常处理rest客户端：https://insomnia.rest/ 初步测试现在我们启动项目，做下测试： 通过insomnia去访问： 发现参数不正确时，返回了400。看起来没问题 统一异常处理我们先修改controller的代码，把异常抛出： 12345678@PostMappingpublic ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; throw new RuntimeException("价格不能为空"); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item));&#125; 接下来，我们使用SpringMVC提供的统一异常拦截器，因为时统一处理，我们放到common项目中： 新建一个类CommonExceptionHandler: 123456789@ControllerAdvice@Slf4jpublic class CommonExceptionHandler &#123; @ExceptionHandler(RuntimeException.class) public ResponseEntity&lt;String&gt; handleException(RuntimeException e)&#123; return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(e.getMessage()); &#125;&#125; 解读： @ControllerAdvice：默认情况下，会拦截所有加了@Controller注解的类 @ExceptionHandler(RuntimeException.class)：作用在方法上，声明要处理的异常类型，可以有多个，这里指定的时RuntimeException，被声明的方法可以看做是一个SPringMVC的Handler： 参数是要处理的异常，类型必须要匹配 返回结果可以是ModelAndView、ResponseEntity等，基本与handler类似 这里等于是从新定义了返回结果，我们可以随意指定想要的返回类型。此处使用了String 然后在service项目中引入common 12345&lt;dependency&gt; &lt;groupId&gt;com.study.common&lt;/groupId&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 重启项目测试： 发现成功获取了提示信息 但是，发现状态码和提示信息被写死了 自定义通用异常处理自定义通用异常消息枚举123456789@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; PRICE_CANNOT_BE_NULL(400,"价格不能为空") ; private int code; private String msg;&#125; 自定义异常返回结果类123456789101112@Datapublic class ExceptionResult &#123; private int status; private String message; private Long timestamp; public ExceptionResult(ExceptionEnum em) &#123; this.status = em.getCode(); this.message = em.getMsg(); this.timestamp = System.currentTimeMillis(); &#125;&#125; 自定义通用异常类123456@NoArgsConstructor@AllArgsConstructor@Getterpublic class CustomException extends RuntimeException &#123; private ExceptionEnum exceptionEnum;&#125; 自定义通用异常处理类12345678910@ControllerAdvice@Slf4jpublic class CommonExceptionHandler &#123; @ExceptionHandler(CustomException.class) public ResponseEntity&lt;ExceptionResult&gt; handleException(CustomException e)&#123; return ResponseEntity.status(e.getExceptionEnum().getCode()) .body(new ExceptionResult(e.getExceptionEnum())); &#125;&#125; 使用通用异常处理12345678910111213141516@RestController@RequestMapping("item")public class ItemController &#123; @Autowired private ItemService itemService; @PostMapping public ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; // 校验价格 if (item.getPrice() == null)&#123; throw new CustomException(ExceptionEnum.PRICE_CANNOT_BE_NULL); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item)); &#125;&#125; 启动项目，查看结果]]></content>
      <categories>
        <category>通用异常处理</category>
      </categories>
      <tags>
        <tag>通用异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue-cli 快速上手]]></title>
    <url>%2F2019%2F01%2F26%2F%E5%89%8D%E7%AB%AF%2Fvue-cli%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[介绍和安装在开发中，需要打包的东西不止是js、css、html。还有更多的东西要处理，这些插件和加载器如果我们一一去添加就会比较麻烦。 幸好，vue官方提供了一个快速搭建vue项目的脚手架：vue-cli 使用它能快速的构建一个web工程模板。 官网：https://github.com/vuejs/vue-cli 安装命令： 1npm install -g vue-cli 快速上手我们新建一个文件夹hello-vue-cli,打开终端并进入目录. 用vue-cli命令，快速搭建一个webpack的项目： 1vue init webpack 前面几项都走默认或yes 下面这些我们选no 最后，再选yes，使用 npm安装 项目结构安装好的项目结构： 入口文件： 单文件组件： 每一个.vue文件，就是一个独立的vue组件。类似于我们刚才写的loginForm.js和registerForm.js 只不过，我们在js中编写 html模板和样式非常的不友好，而且没有语法提示和高亮。 而单文件组件中包含三部分内容： template：模板，支持html语法高亮和提示 script：js脚本，这里编写的就是vue的组件对象，看到上面的data(){}了吧 style：样式，支持CSS语法高亮和提示 每个组件都有自己独立的html、JS、CSS，互不干扰，真正做到可独立复用 运行看生成的package.json： 可以看到这引入了非常多的依赖，绝大多数都是开发期依赖，比如大量的加载器。 运行时依赖只有vue和vue-router 脚本有三个： dev：使用了webpack-dev-server命令，开发时热部署使用 start：使用了npm run dev命令，与上面的dev效果完全一样 build：等同于webpack的打包功能，会打包到dist目录下。 我们执行npm run dev 或者 npm start 都可以启动项目： 页面：]]></content>
      <categories>
        <category>vue-cli</category>
      </categories>
      <tags>
        <tag>vue-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue父子组件通信]]></title>
    <url>%2F2019%2F01%2F25%2F%E5%89%8D%E7%AB%AF%2FVue%E7%88%B6%E5%AD%90%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[父组件向子组件传值 组件实例定义方式，注意：一定要使用props属性来定义父组件传递过来的数据 123456789101112131415&lt;script&gt; // 创建 Vue 实例，得到 ViewModel var vm = new Vue(&#123; el: '#app', data: &#123; msg: '这是父组件中的消息' &#125;, components: &#123; son: &#123; template: '&lt;h1&gt;这是子组件 --- &#123;&#123;finfo&#125;&#125;&lt;/h1&gt;', props: ['finfo'] &#125; &#125; &#125;); &lt;/script&gt; 使用v-bind或简化指令，将数据传递到子组件中： 123&lt;div id="app"&gt; &lt;son :finfo="msg"&gt;&lt;/son&gt; &lt;/div&gt; 子组件向父组件传值 原理：父组件将方法的引用，传递到子组件内部，子组件在内部调用父组件传递过来的方法，同时把要发送给父组件的数据，在调用方法的时候当作参数传递进去； 父组件将方法的引用传递给子组件，其中，getMsg是父组件中methods中定义的方法名称，func是子组件调用传递过来方法时候的方法名称 1&lt;son @func=&quot;getMsg&quot;&gt;&lt;/son&gt; 子组件内部通过this.$emit(&#39;方法名&#39;, 要传递的数据)方式，来调用父组件中的方法，同时把数据传递给父组件使用 12345678910111213141516171819202122232425262728293031323334&lt;div id="app"&gt; &lt;!-- 引用父组件 --&gt; &lt;son @func="getMsg"&gt;&lt;/son&gt; &lt;!-- 组件模板定义 --&gt; &lt;script type="x-template" id="son"&gt; &lt;div&gt; &lt;input type="button" value="向父组件传值" @click="sendMsg" /&gt; &lt;/div&gt; &lt;/script&gt; &lt;/div&gt; &lt;script&gt; // 子组件的定义方式 Vue.component('son', &#123; template: '#son', // 组件模板Id methods: &#123; sendMsg() &#123; // 按钮的点击事件 this.$emit('func', 'OK'); // 调用父组件传递过来的方法，同时把数据传递出去 &#125; &#125; &#125;); // 创建 Vue 实例，得到 ViewModel var vm = new Vue(&#123; el: '#app', data: &#123;&#125;, methods: &#123; getMsg(val)&#123; // 子组件中，通过 this.$emit() 实际调用的方法，在此进行定义 alert(val); &#125; &#125; &#125;); &lt;/script&gt;]]></content>
      <categories>
        <category>Vuejs</category>
      </categories>
      <tags>
        <tag>Vuejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运用Swagger编写API文档]]></title>
    <url>%2F2019%2F01%2F25%2F%E5%89%8D%E7%AB%AF%2FSwagger%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是Swagger随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、先后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。 前端和后端的唯一联系，变成了API接口；API文档变成了前后端开发人员联系的纽带，变得越来越重要，`swagger`就是一款让你更好的书写API文档的框架。 SwaggerEditor安装与启动（1） 下载 （2）解压swagger-editor, （3）全局安装http-server(http-server是一个简单的零配置命令行http服务器) 1npm install -g http-server （4）启动swagger-editor 1http-server swagger-editor （5）浏览器打开： http://localhost:8080 语法规则（1）固定字段 字段名 类型 描述 swagger string 必需的。使用指定的规范版本。 info Info Object 必需的。提供元数据API。 host string 主机名或ip服务API。 basePath string API的基本路径 schemes [string] API的传输协议。 值必须从列表中:”http”,”https”,”ws”,”wss”。 consumes [string] 一个MIME类型的api可以使用列表。值必须是所描述的Mime类型。 produces [string] MIME类型的api可以产生的列表。 值必须是所描述的Mime类型。 paths 路径对象 必需的。可用的路径和操作的API。 definitions 定义对象 一个对象数据类型生产和使用操作。 parameters 参数定义对象 一个对象来保存参数,可以使用在操作。 这个属性不为所有操作定义全局参数。 responses 反应定义对象 一个对象响应,可以跨操作使用。 这个属性不为所有操作定义全球响应。 externalDocs 外部文档对象 额外的外部文档。 summary string 什么操作的一个简短的总结。 最大swagger-ui可读性,这一领域应小于120个字符。 description string 详细解释操作的行为。GFM语法可用于富文本表示。 operationId string 独特的字符串用于识别操作。 id必须是唯一的在所有业务中所描述的API。 工具和库可以使用operationId来唯一地标识一个操作,因此,建议遵循通用的编程的命名约定。 deprecated boolean 声明该操作被弃用。 使用声明的操作应该没有。 默认值是false。 （2）字段类型与格式定义 普通的名字 type format 说明 integer integer int32 签署了32位 long integer int64 签署了64位 float number float double number double string string byte string byte base64编码的字符 binary string binary 任何的八位字节序列 boolean boolean date string date 所定义的full-date- - - - - -RFC3339 dateTime string date-time 所定义的date-time- - - - - -RFC3339 password string password 用来提示用户界面输入需要模糊。 基础模块-城市API文档新增城市编写新增城市的API , post提交城市实体 URL： /city Method: post 编写后的文档内容如下： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748swagger: '2.0'info: version: "1.0.0" title: 基础模块-城市APIbasePath: /basehost: api.tensquare.compaths: /city: post: summary: 新增城市 parameters: - name: "body" in: "body" description: 城市实体类 required: true schema: $ref: '#/definitions/City' responses: 200: description: 成功 schema: $ref: '#/definitions/ApiResponse'definitions: City: type: object properties: id: type: string description: "ID" name: type: string description: "名称" ishot: type: string description: 是否热门 ApiResponse: type: object properties: flag: type: boolean description: 是否成功 code: type: integer format: int32 description: 返回码 message: type: string description: 返回信息 编辑后可以在右侧窗口看到显示的效果 修改城市URL： /city/{cityId} Method: put 编写后的文档内容如下： 代码如下： 12345678910111213141516171819/city/&#123;cityId&#125;: put: summary: 修改城市 parameters: - name: cityId in: path description: 城市ID required: true type: string - name: body in: body description: 城市 schema: $ref: '#/definitions/City' responses: 200: description: 成功响应 schema: $ref: '#/definitions/ApiResponse' 删除城市删除城市地址为/city/{cityId} ，与修改城市的地址相同，区别在于使用delete方法提交请求 代码如下： （/city/{cityId} 下增加delete） 1234567891011121314delete: summary: 根据ID删除 description: 返回是否成功 parameters: - name: cityId in: path description: 城市ID required: true type: string responses: '200': description: 成功 schema: $ref: '#/definitions/ApiResponse' 根据ID查询城市URL: /city/{cityId} Method: get 返回的内容结构为： {flag:true,code:20000, message:”查询成功”,data: {…..} } data属性返回的是city的实体类型 代码实现如下： （1）在definitions下定义城市对象的响应对象 123456789101112ApiCityResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: $ref: '#/definitions/City' （2）/city/{cityId} 下新增get方法API 1234567891011121314get: summary: 根据ID查询 description: 返回一个城市 parameters: - name: cityId in: path description: 城市ID required: true type: string responses: '200': description: 操作成功 schema: $ref: '#/definitions/ApiCityResponse' 城市列表URL: /city Method: get 返回的内容结构为： {flag:true,code:20000, message:”查询成功”,data:[{…..},{…..},{…..}] } data属性返回的是city的实体数组 实现步骤如下： （1）在definitions下定义城市列表对象以及相应对象 12345678910111213141516CityList: type: "array" items: $ref: '#/definitions/City'ApiCityListResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: $ref: '#/definitions/CityList' （2）在/city增加get 12345678get: summary: "城市全部列表" description: "返回城市全部列表" responses: 200: description: "成功查询到数据" schema: $ref: '#/definitions/ApiCityListResponse' 根据条件查询城市列表实现API效果如下: 代码如下： 123456789101112131415/city/search: post: summary: 城市列表(条件查询) parameters: - name: body in: body description: 查询条件 required: true schema: $ref: "#/definitions/City" responses: 200: description: 查询成功 schema: $ref: '#/definitions/ApiCityListResponse' 城市分页列表实现API效果如下： 实现如下： （1）在definitions下定义城市分页列表响应对象 1234567891011121314151617ApiCityPageResponse: type: "object" properties: code: type: "integer" format: "int32" flag: type: "boolean" message: type: "string" data: properties: total: type: "integer" format: "int32" rows: $ref: '#/definitions/CityList' （2）新增节点 123456789101112131415161718192021222324252627/city/search/&#123;page&#125;/&#123;size&#125;: post: summary: 城市分页列表 parameters: - name: page in: path description: 页码 required: true type: integer format: int32 - name: size in: path description: 页大小 required: true type: integer format: int32 - name: body in: body description: 查询条件 required: true schema: $ref: "#/definitions/City" responses: 200: description: 查询成功 schema: $ref: '#/definitions/ApiCityPageResponse' SwaggerUISwaggerUI是用来展示Swagger文档的界面，以下为安装步骤 （1）在本地安装nginx （2）下载SwaggerUI源码 https://swagger.io/download-swagger-ui/ （3）解压，将dist文件夹下的全部文件拷贝至 nginx的html目录 （4）启动nginx （5）浏览器打开页面 http://localhost即可看到文档页面 （6）我们将编写好的yml文件也拷贝至nginx的html目录，这样我们就可以加载我们的swagger文档了]]></content>
      <categories>
        <category>Swagger</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES6 语法指南]]></title>
    <url>%2F2019%2F01%2F25%2F%E5%89%8D%E7%AB%AF%2FES6%20%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[什么是ECMAScript来看下前端的发展历程： web1.0时代： 最初的网页以HTML为主，是纯静态的网页。网页是只读的，信息流只能从服务的到客户端单向流通。开发人员也只关心页面的样式和内容即可。 web2.0时代： 1995年，网景工程师Brendan Eich 花了10天时间设计了JavaScript语言。 1996年，微软发布了JScript，其实是JavaScript的逆向工程实现。 1997年，为了统一各种不同script脚本语言，ECMA（欧洲计算机制造商协会）以JavaScript为基础，制定了ECMAscript标准规范。JavaScript和JScript都是ECMAScript的标准实现者，随后各大浏览器厂商纷纷实现了ECMAScript标准。 所以，ECMAScript是浏览器脚本语言的规范，而各种我们熟知的js语言，如JavaScript则是规范的具体实现。 ECMAScript的快速发展而后，ECMAScript就进入了快速发展期。 1998年6月，ECMAScript 2.0 发布。 1999年12月，ECMAScript 3.0 发布。这时，ECMAScript 规范本身也相对比较完善和稳定了，但是接下来的事情，就比较悲剧了。 2007年10月。。。。ECMAScript 4.0 草案发布。 这次的新规范，历时颇久，规范的新内容也有了很多争议。在制定ES4的时候，是分成了两个工作组同时工作的。 一边是以 Adobe, Mozilla, Opera 和 Google为主的 ECMAScript 4 工作组。 一边是以 Microsoft 和 Yahoo 为主的 ECMAScript 3.1 工作组。 ECMAScript 4 的很多主张比较激进，改动较大。而 ECMAScript 3.1 则主张小幅更新。最终经过 TC39 的会议，决定将一部分不那么激进的改动保留发布为 ECMAScript 3.1，而ES4的内容，则延续到了后来的ECMAScript5和6版本中 2009年12月，ECMAScript 5 发布。 2011年6月，ECMAScript 5.1 发布。 2015年6月，ECMAScript 6，也就是 ECMAScript 2015 发布了。 并且从 ECMAScript 6 开始，开始采用年号来做版本。即 ECMAScript 2015，就是ECMAScript6。 ES5和6的一些新特性我们这里只把一些常用的进行学习，更详细的大家参考：阮一峰的ES6教程 let 和 const 命令 var 之前，js定义变量只有一个关键字：var var有一个问题，就是定义的变量有时会莫名奇妙的成为全局变量。 例如这样的一段代码： 1234for(var i = 0; i &lt; 5; i++)&#123; console.log(i);&#125;console.log("循环外：" + i) 你猜下打印的结果是什么？ let let所声明的变量，只在let命令所在的代码块内有效。 我们把刚才的var改成let试试： 1234for(let i = 0; i &lt; 5; i++)&#123; console.log(i);&#125;console.log("循环外：" + i) 结果： const const声明的变量是常量，不能被修改 字符串扩展 新的API ES6为字符串扩展了几个新的API： includes()：返回布尔值，表示是否找到了参数字符串。 startsWith()：返回布尔值，表示参数字符串是否在原字符串的头部。 endsWith()：返回布尔值，表示参数字符串是否在原字符串的尾部。 实验一下： 字符串模板 ES6中提供了`来作为字符串模板标记。我们可以这么玩： 在两个`之间的部分都会被作为字符串的值，不管你任意换行，甚至加入js脚本 键盘是的1的左侧，tab的上侧，esc的正下方 解构表达式 数组解构 比如有一个数组： 1let arr = [1,2,3] 我想获取其中的值，只能通过角标。ES6可以这样： 123const [x,y,z] = arr;// x，y，z将与arr中的每个位置对应来取值// 然后打印console.log(x,y,z); 结果： 对象解构 例如有个person对象： 12345const person = &#123; name:"jack", age:21, language: ['java','js','css']&#125; 我们可以这么做： 123456// 解构表达式获取值const &#123;name,age,language&#125; = person;// 打印console.log(name);console.log(age);console.log(language); 结果： 如过想要用其它变量接收，需要额外指定别名： {name:n}：name是person中的属性名，冒号后面的n是解构后要赋值给的变量。 函数优化 函数参数默认值 在ES6以前，我们无法给一个函数参数设置默认值，只能采用变通写法： 1234567function add(a , b) &#123; // 判断b是否为空，为空就给默认值1 b = b || 1; return a + b;&#125;// 传一个参数console.log(add(10)); 现在可以这么写： 12345function add(a , b = 1) &#123; return a + b;&#125;// 传一个参数console.log(add(10)); 箭头函数 ES6中定义函数的简写方式： 一个参数时： 12345var print = function (obj) &#123; console.log(obj);&#125;// 简写为：var print2 = obj =&gt; console.log(obj); 多个参数： 123456// 两个参数的情况：var sum = function (a , b) &#123; return a + b;&#125;// 简写为：var sum2 = (a,b) =&gt; a+b; 代码不止一行，可以用{}括起来 123var sum3 = (a,b) =&gt; &#123; return a + b;&#125; 对象的函数属性简写 比如一个Person对象，里面有eat方法： 12345678910111213let person = &#123; name: "jack", // 以前： eat: function (food) &#123; console.log(this.name + "在吃" + food); &#125;, // 箭头函数版： eat2: food =&gt; console.log(person.name + "在吃" + food),// 这里拿不到this // 简写版： eat3(food)&#123; console.log(this.name + "在吃" + food); &#125;&#125; 箭头函数结合解构表达式 比如有一个函数： 123456789const person = &#123; name:"jack", age:21, language: ['java','js','css']&#125;function hello(person) &#123; console.log("hello," + person.name)&#125; 如果用箭头函数和解构表达式 1var hi = (&#123;name&#125;) =&gt; console.log("hello," + name); map和reducemap()`：接收一个函数，将原数组中的所有元素用这个函数处理后放入新数组返回。 举例：有一个字符串数组，我们希望转为int数组 123456let arr = ['1','20','-5','3'];console.log(arr)arr = arr.map(s =&gt; parseInt(s));console.log(arr) reduce reduce()：接收一个函数（必须）和一个初始值（可选），该函数接收两个参数： 第一个参数是上一次reduce处理的结果 第二个参数是数组中要处理的下一个元素 reduce()会从左到右依次把数组中的元素用reduce处理，并把处理的结果作为下次reduce的第一个参数。如果是第一次，会把前两个元素作为计算参数，或者把用户指定的初始值作为起始参数 举例： 1const arr = [1,20,-5,3] 没有初始值： 指定初始值： promise所谓Promise，简单说就是一个容器，里面保存着某个未来才会结束的事件（通常是一个异步操作）的结果。从语法上说，Promise 是一个对象，从它可以获取异步操作的消息。Promise 提供统一的 API，各种异步操作都可以用同样的方法进行处理。 感觉跟java的Future类很像啊，有木有！ 我们可以通过Promise的构造函数来创建Promise对象，并在内部封装一个异步执行的结果。 语法： 123456789const promise = new Promise(function(resolve, reject) &#123; // ... 执行异步操作 if (/* 异步操作成功 */)&#123; resolve(value);// 调用resolve，代表Promise将返回成功的结果 &#125; else &#123; reject(error);// 调用reject，代表Promise会返回失败结果 &#125;&#125;); 这样，在promise中就封装了一段异步执行的结果。 如果我们想要等待异步执行完成，做一些事情，我们可以通过promise的then方法来实现,语法： 123promise.then(function(value)&#123; // 异步执行成功后的回调&#125;); 如果想要处理promise异步执行失败的事件，还可以跟上catch： 12345promise.then(function(value)&#123; // 异步执行成功后的回调&#125;).catch(function(error)&#123; // 异步执行失败后的回调&#125;) 示例： 12345678910111213141516171819const p = new Promise(function (resolve, reject) &#123; // 这里我们用定时任务模拟异步 setTimeout(() =&gt; &#123; const num = Math.random(); // 随机返回成功或失败 if (num &lt; 0.5) &#123; resolve(&quot;成功！num:&quot; + num) &#125; else &#123; reject(&quot;出错了！num:&quot; + num) &#125; &#125;, 300)&#125;)// 调用promisep.then(function (msg) &#123; console.log(msg);&#125;).catch(function (msg) &#123; console.log(msg);&#125;) 结果： set和map（了解）ES6提供了Set和Map的数据结构。 Set，本质与数组类似。不同在于Set中只能保存不同元素，如果元素相同会被忽略。跟java很像吧。 构造函数： 12345// Set构造函数可以接收一个数组或空let set = new Set();set.add(1);// [1]// 接收数组let set2 = new Set([2,3,4,5,5]);// 得到[2,3,4,5] 普通方法： 123456789set.add(1);// 添加set.clear();// 清空set.delete(2);// 删除指定元素set.has(2); // 判断是否存在set.keys();// 返回所有keyset.values();// 返回所有值set.entries();// 返回键值对集合// 因为set没有键值对，所有其keys、values、entries方法返回值一样的。set.size; // 元素个数。是属性，不是方法。 map，本质是与Object类似的结构。不同在于，Object强制规定key只能是字符串。而Map结构的key可以是任意对象。即： object是 &lt;string,object&gt;集合 map是&lt;object,object&gt;集合 构造函数： 12345678910111213// map接收一个数组，数组中的元素是键值对数组const map = new Map([ ['key1','value1'], ['key2','value2'],])// 或者接收一个setconst set = new Set([ ['key1','value1'], ['key2','value2'],])const map2 = new Map(set)// 或者其它mapconst map3 = new Map(map); 方法： 模块化什么是模块化模块化就是把代码进行拆分，方便重复利用。类似java中的导包：要使用一个包，必须先导包。 而JS中没有包的概念，换来的是 模块。 模块功能主要由两个命令构成：export和import。 export命令用于规定模块的对外接口， import命令用于导入其他模块提供的功能。 export比如我定义一个js文件:hello.js，里面有一个对象： 12345const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125; 我可以使用export将这个对象导出： 123456const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125;export util; 当然，也可以简写为： 12345export const util = &#123; sum(a,b)&#123; return a + b; &#125;&#125; export不仅可以导出对象，一切JS变量都可以导出。比如：基本类型变量、函数、数组、对象。 当要导出多个值时，还可以简写。比如我有一个文件：user.js： 123var name = "jack"var age = 21export &#123;name,age&#125; 省略名称 上面的导出代码中，都明确指定了导出的变量名，这样其它人在导入使用时就必须准确写出变量名，否则就会出错。 因此js提供了default关键字，可以对导出的变量名进行省略 例如： 123456// 无需声明对象的名字export default &#123; sum(a,b)&#123; return a + b; &#125;&#125; 这样，当使用者导入时，可以任意起名字 import使用export命令定义了模块的对外接口以后，其他 JS 文件就可以通过import命令加载这个模块。 例如我要使用上面导出的util： 1234// 导入utilimport util from 'hello.js'// 调用util中的属性util.sum(1,2) 要批量导入前面导出的name和age： 123import &#123;name, age&#125; from 'user.js'console.log(name + " , 今年"+ age +"岁了") 但是上面的代码暂时无法测试，因为浏览器目前还不支持ES6 的导入和导出功能。除非借助于工具，把ES6 的语法进行编译降级到ES5，比如Babel-cli工具 我们暂时不做测试，大家了解即可。 对象扩展ES6给Object拓展了许多新的方法，如： keys(obj)：获取对象的所有key形成的数组 values(obj)：获取对象的所有value形成的数组 entries(obj)：获取对象的所有key和value形成的二维数组。格式：[[k1,v1],[k2,v2],...] assian(dest, …src) ：将多个src对象的值 拷贝到 dest中（浅拷贝）。 数组扩展ES6给数组新增了许多方法： find(callback)：把数组中的元素逐个传递给函数callback执行，如果返回true，则返回该元素 findIndex(callback)：与find类似，不过返回的是品牌到的元素的索引 includes（callback）：与find类似，如果匹配到元素，则返回true，代表找到了。]]></content>
      <categories>
        <category>ES6</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置browser-sync浏览器同步测试工具]]></title>
    <url>%2F2019%2F01%2F23%2F%E5%89%8D%E7%AB%AF%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E5%90%8C%E6%AD%A5%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介 Time-saving synchronised browser testing. It’s wicked-fast and totally free. 官方网站 文档 起步 安装依赖12# 也可以 npm i -D browser-syncnpm install --save-dev browser-sync 配置package.json中script123456&#123; "scripts": &#123; "dev": "browser-sync start --server --files \"*.html, css/*.css, js/*.js\"", "start": "npm run dev" &#125;,&#125; 启动开发服务12# 或者 npm startnpm run dev]]></content>
      <categories>
        <category>browser-sync</category>
      </categories>
      <tags>
        <tag>browser-sync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba路由网关全局过滤功能]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%E7%9A%84%E5%85%A8%E5%B1%80%E8%BF%87%E6%BB%A4%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[概述全局过滤器作用于所有的路由，不需要单独配置，我们可以用它来实现很多统一化处理的业务需求，比如权限认证，IP 访问限制等等。 注意：截止博客发表时间 2019 年 01 月 10 日，Spring Cloud Gateway 正式版为 2.0.2 其文档并不完善，并且有些地方还要重新设计，这里仅提供一个基本的案例 详见：Spring Cloud Gateway Documentation 生命周期 Spring Cloud Gateway 基于 Project Reactor 和 WebFlux，采用响应式编程风格，打开它的 Filter 的接口 GlobalFilter 你会发现它只有一个方法 filter 创建全局过滤器实现 GlobalFilter, Ordered 接口并在类上增加 @Component 注解就可以使用过滤功能了，非常简单方便 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package club.codeopen.spring.cloud.gateway.filters;/** * @author by cheng * @Classname AuthFilter * @Description * @Date 2019/1/13 11:36 */import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.common.collect.Maps;import org.springframework.cloud.gateway.filter.GatewayFilterChain;import org.springframework.cloud.gateway.filter.GlobalFilter;import org.springframework.core.Ordered;import org.springframework.core.io.buffer.DataBuffer;import org.springframework.http.HttpStatus;import org.springframework.http.server.reactive.ServerHttpResponse;import org.springframework.stereotype.Component;import org.springframework.web.server.ServerWebExchange;import reactor.core.publisher.Mono;import java.util.Map;/** * 鉴权过滤器 */@Componentpublic class AuthFilter implements GlobalFilter, Ordered &#123; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; String token = exchange.getRequest().getQueryParams().getFirst("token"); if (token == null || token.isEmpty()) &#123; ServerHttpResponse response = exchange.getResponse(); // 封装错误信息 Map&lt;String, Object&gt; responseData = Maps.newHashMap(); responseData.put("code", 401); responseData.put("message", "非法请求"); responseData.put("cause", "Token is empty"); try &#123; // 将信息转换为 JSON ObjectMapper objectMapper = new ObjectMapper(); byte[] data = objectMapper.writeValueAsBytes(responseData); // 输出错误信息到页面 DataBuffer buffer = response.bufferFactory().wrap(data); response.setStatusCode(HttpStatus.UNAUTHORIZED); response.getHeaders().add("Content-Type", "application/json;charset=UTF-8"); return response.writeWith(Mono.just(buffer)); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; &#125; return chain.filter(exchange); &#125; /** * 设置过滤器的执行顺序 * @return */ @Override public int getOrder() &#123; return Ordered.LOWEST_PRECEDENCE; &#125;&#125; 测试过滤器浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 网页显示 浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name?token=123456 网页显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 附：Spring Cloud Gateway BenchmarkSpring 官方人员提供的网关基准测试报告 GitHub Proxy Avg Latency Avg Req/Sec/Thread gateway 6.61ms 3.24k linkered 7.62ms 2.82k zuul 12.56ms 2.09k none 2.09ms 11.77k 说明 这里的 Zuul 为 1.x 版本，是一个基于阻塞 IO 的 API Gateway Zuul 已经发布了 Zuul 2.x，基于 Netty，非阻塞的，支持长连接，但 Spring Cloud 暂时还没有整合计划 Linkerd 基于 Scala 实现的、目前市面上仅有的生产级别的 Service Mesh（其他诸如 Istio、Conduit 暂时还不能用于生产）。]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba路由网关]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[什么是 Spring Cloud GatewaySpring Cloud Gateway 是 Spring 官方基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，Spring Cloud Gateway 旨在为微服务架构提供一种简单而有效的统一的 API 路由管理方式。Spring Cloud Gateway 作为 Spring Cloud 生态系中的网关，目标是替代 Netflix ZUUL，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/埋点，和限流等。 Spring Cloud Gateway 功能特征 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 Spring Cloud Gateway 工程流程 客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（pre）或之后（post）执行业务逻辑 POM1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-gateway&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-gateway&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- Commons Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Commons Begin --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.gateway.GatewayApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354spring: application: # 应用名称 name: spring-gateway cloud: # 使用 Naoos 作为服务注册发现 nacos: discovery: server-addr: 127.0.0.1:8848 # 使用 Sentinel 作为熔断器 sentinel: transport: port: 8721 dashboard: localhost:8080 # 路由网关配置 gateway: # 设置与服务注册发现组件结合，这样可以采用服务名的路由策略 discovery: locator: enabled: true # 配置路由规则 routes: # 采用自定义路由 ID（有固定用法，不同的 id 有不同的功能，详见：https://cloud.spring.io/spring-cloud-gateway/2.0.x/single/spring-cloud-gateway.html#gateway-route-filters） - id: NACOS-CONSUMER # 采用 LoadBalanceClient 方式请求，以 lb:// 开头，后面的是注册在 Nacos 上的服务名 uri: lb://nacos-consumer # Predicate 翻译过来是“谓词”的意思，必须，主要作用是匹配用户的请求，有很多种用法 predicates: # Method 方法谓词，这里是匹配 GET 和 POST 请求 - Method=GET,POST - id: NACOS-CONSUMER-FEIGN uri: lb://nacos-consumer-feign predicates: - Method=GET,POSTserver: port: 9000# 目前无效feign: sentinel: enabled: true# 目前无效management: endpoints: web: exposure: include: "*"# 配置日志级别，方别调试logging: level: org.springframework.cloud.gateway: debug 注意：请仔细阅读注释 测试访问依次运行 Nacos 服务、NacosProviderApplication、NacosConsumerApplication、NacosConsumerFeignApplication、GatewayApplication 打开浏览器访问：http://localhost:9000/nacos-consumer/echo/app/name 浏览器显示 1Hello Nacos Discovery nacos-consumer i am from port 8082 1 打开浏览器访问：http://localhost:9000/nacos-consumer-feign/echo/hi 浏览器显示 1Hello Nacos Discovery Hi Feign i am from port 8082 1 注意：请求方式是 http://路由网关IP:路由网关Port/服务名/** 至此说明 Spring Cloud Gateway 的路由功能配置成功]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloud alibaba统一的依赖管理]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%BB%9F%E4%B8%80%E7%9A%84%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring Cloud Alibaba 项目都是基于 Spring Cloud，而 Spring Cloud 项目又是基于 Spring Boot 进行开发，并且都是使用 Maven 做项目管理工具。在实际开发中，我们一般都会创建一个依赖管理项目作为 Maven 的 Parent 项目使用，这样做可以极大的方便我们对 Jar 包版本的统一管理。 创建依赖管理项目创建一个工程名为 spring-cloud-alibaba-demo-dependencies 的项目，pom.xml 配置文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-dependencies&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt; &lt;spring-cloud-alibaba.version&gt;0.2.1.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- Java Document Generate --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- YUI Compressor (CSS/JS压缩) --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compress&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;jswarn&gt;false&lt;/jswarn&gt; &lt;nosuffix&gt;true&lt;/nosuffix&gt; &lt;linebreakpos&gt;30000&lt;/linebreakpos&gt; &lt;force&gt;true&lt;/force&gt; &lt;includes&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.min.js&lt;/exclude&gt; &lt;exclude&gt;**/*.min.css&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-alibaba-dependencies：在 properties 配置中预定义了版本号为 0.2.1.RELEASE ，表示我们的 Spring Cloud Alibaba 对应的是 Spring Cloud Finchley 版本 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 依赖版本说明项目的最新版本是 0.2.1.RELEASE 和 0.1.1.RELEASE，版本 0.2.1.RELEASE 对应的是 Spring Cloud Finchley 版本，版本 0.1.1.RELEASE 对应的是 Spring Cloud Edgware 版本]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba熔断器仪表盘]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%86%94%E6%96%AD%E5%99%A8%E4%BB%AA%E8%A1%A8%E7%9B%98%2F</url>
    <content type="text"><![CDATA[Sentinel 控制台Sentinel 控制台提供一个轻量级的控制台，它提供机器发现、单机资源实时监控、集群资源汇总，以及规则管理的功能。您只需要对应用进行简单的配置，就可以使用这些功能。 注意: 集群资源汇总仅支持 500 台以下的应用集群，有大概 1 - 2 秒的延时。 下载并打包 可以从最新版本的源码自行构建 Sentinel 控制台 12345# 下载源码git clone https://github.com/alibaba/Sentinel.git# 编译打包mvn clean package 注：下载依赖时间较长，请耐心等待… 也可以从 release 页面 下载最新版本的控制台 jar 包 启动控制台Sentinel 控制台是一个标准的 SpringBoot 应用，以 SpringBoot 的方式运行 jar 包即可。 12345# 自行构建Sentinel控制台，控制台jar包位置cd sentinel-dashboard\targe # 运行jar包java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar 如若 8080 端口冲突，可使用 -Dserver.port=新端口 进行设置。 访问服务打开浏览器访问：http://localhost:8080/#/dashboard/home 测试 Sentinel使用之前的 Feign 客户端，application.yml 完整配置如下： 123456789101112131415161718192021222324spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848 sentinel: transport: port: 8720 dashboard: localhost:8080server: port: 9092feign: sentinel: enabled: truemanagement: endpoints: web: exposure: include: "*" 注：由于 8719 端口已被 sentinel-dashboard 占用，故这里修改端口号为 8720；不修改也能注册，会自动帮你在端口号上 + 1； 打开浏览器访问：http://localhost:8080/#/dashboard/home 此时会多一个名为 nacos-consumer-feign 的服务]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba熔断器]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E7%86%94%E6%96%AD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用，在 Spring Cloud 中可以用 RestTemplate + LoadBalanceClient 和 Feign 来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 阿里巴巴开源了 Sentinel 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。在微服务架构中，一个请求需要调用多个服务是非常常见的，如下图： 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值。 什么是 Sentinel随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性Sentinel 的特征 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的 双十一大促流量 的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等 Feign 中使用 Sentinel如果要在您的项目中引入 Sentinel，使用 group ID 为 org.springframework.cloud 和 artifact ID 为 spring-cloud-starter-alibaba-sentinel 的 starter。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt; Sentinel 适配了 Feign 组件。但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: sentinel: enabled: true 在 Service 中增加 fallback 指定类12345678910111213141516171819package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.fallback.EchoServiceFallback;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @author by cheng * @Classname EchoService * @Description * @Date 2019/1/13 9:52 */@FeignClient(value = "nacos-provider", fallback = EchoServiceFallback.class)public interface EchoService &#123; @GetMapping(value = "/echo/&#123;message&#125;") String echo(@PathVariable("message") String message);&#125; 创建熔断器类并实现对应的 Feign 接口123456789101112131415161718package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.fallback;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.stereotype.Component;/** * @author by cheng * @Classname EchoServiceFallback * @Description * @Date 2019/1/13 10:08 */@Componentpublic class EchoServiceFallback implements EchoService &#123; @Override public String echo(String message) &#123; return "echo fallback"; &#125;&#125; 测试熔断器此时我们关闭服务提供者，再次请求 http://localhost:9092/echo/hi 浏览器会显示： 1echo fallback]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务消费者（Feign）]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%EF%BC%88Feign%EF%BC%89%2F</url>
    <content type="text"><![CDATA[概述Feign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，Nacos 也很好的兼容了 Feign，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-consumer-feign 的服务消费者项目，pom.xml 配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-consumer-feign&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-consumer-feign&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.NacosConsumerFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 org.springframework.cloud:spring-cloud-starter-openfeign 依赖 application.yml12345678910111213141516spring: application: name: nacos-consumer-feign cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9092management: endpoints: web: exposure: include: "*" Application通过 @EnableFeignClients 注解开启 Feign 功能 123456789101112131415161718192021package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;/** * @author by cheng * @Classname NacosConsumerFeignApplication * @Description * @Date 2019/1/13 9:51 */@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class NacosConsumerFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerFeignApplication.class, args); &#125;&#125; 创建 Feign 接口通过 @FeignClient(&quot;服务名&quot;) 注解来指定调用哪个服务。代码如下： 123456789101112131415161718package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;/** * @author by cheng * @Classname EchoService * @Description * @Date 2019/1/13 9:52 */@FeignClient(value = "nacos-provider")public interface EchoService &#123; @GetMapping(value = "/echo/&#123;message&#125;") String echo(@PathVariable("message") String message);&#125; Controller123456789101112131415161718192021222324package club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.controller;import club.codeopen.spring.cloud.alibaba.nacos.consumer.feign.service.EchoService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosConsumerFeignController * @Description * @Date 2019/1/13 9:52 */@RestControllerpublic class NacosConsumerFeignController &#123; @Autowired private EchoService echoService; @GetMapping(value = "/echo/hi") public String echo() &#123; return echoService.echo("Hi Feign"); &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer-feign 的服务 这时打开 http://localhost:9092/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery Hi Feign 测试负载均衡 启动多个 consumer-provider 实例，效果图如下： 修改 consumer-provider 项目中的 Controller 代码，用于确定负载均衡生效 12345678910111213141516171819202122232425262728293031323334package club.codeopen.spring.cloud.alibaba.nacos.provider;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosProviderApplication * @Description * @Date 2019/1/13 9:24 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class, args); &#125; @Value("$&#123;server.port&#125;") private String port; @RestController public class EchoController &#123; @GetMapping(value = "/echo/&#123;message&#125;") public String echo(@PathVariable String message) &#123; return "Hello Nacos Discovery " + message + " i am from port " + port; &#125; &#125;&#125; 在浏览器上多次访问 http://localhost:9092/echo/hi ，浏览器交替显示： 12Hello Nacos Discovery Hi Feign i am from port 8081Hello Nacos Discovery Hi Feign i am from port 8082]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Feign</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务消费者]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[概述服务消费者的创建与服务提供者大同小异，这里采用最原始的一种方式，即显示的使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-consumer 的服务消费者项目，pom.xml 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-consumer&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-consumer&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.consumer.NacosConsumerApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml12345678910111213141516spring: application: name: nacos-consumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 9091management: endpoints: web: exposure: include: "*" Application12345678910111213141516171819package club.codeopen.spring.cloud.alibaba.nacos.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * @author by cheng * @Classname NacosConsumerApplication * @Description * @Date 2019/1/13 9:38 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosConsumerApplication.class, args); &#125;&#125; Configuration创建一个名为 NacosConsumerConfiguration 的 Java 配置类，主要作用是为了注入 RestTemplate 1234567891011121314151617181920package club.codeopen.spring.cloud.alibaba.nacos.consumer.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;/** * @author by cheng * @Classname NacosConsumerConfiguration * @Description * @Date 2019/1/13 9:39 */@Configurationpublic class NacosConsumerConfiguration &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; Controller创建一个名为 NacosConsumerController 测试用的 Controller 123456789101112131415161718192021222324252627282930313233343536package club.codeopen.spring.cloud.alibaba.nacos.consumer.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.client.ServiceInstance;import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;/** * @author by cheng * @Classname NacosConsumerController * @Description * @Date 2019/1/13 9:39 */@RestControllerpublic class NacosConsumerController &#123; @Autowired private LoadBalancerClient loadBalancerClient; @Autowired private RestTemplate restTemplate; @Value("$&#123;spring.application.name&#125;") private String appName; @GetMapping(value = "/echo/app/name") public String echo() &#123; //使用 LoadBalanceClient 和 RestTemplate 结合的方式来访问 ServiceInstance serviceInstance = loadBalancerClient.choose("nacos-provider"); String url = String.format("http://%s:%s/echo/%s", serviceInstance.getHost(), serviceInstance.getPort(), appName); return restTemplate.getForObject(url, String.class); &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现多了一个名为 nacos-consumer 的服务 这时打开 http://localhost:9091/echo/app/name ，你会在浏览器上看到： 1Hello Nacos Discovery nacos-consumer 服务的端点检查通过浏览器访问 http://localhost:9091/actuator/nacos-discovery 你会在浏览器上看到：]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务注册与发现之Nacos]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0%E4%B9%8BNacos%2F</url>
    <content type="text"><![CDATA[什么是 NacosNacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。 Nacos 帮助您更敏捷和容易地构建、交付和管理微服务平台。 Nacos 是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。 基本架构及概念 服务 (Service)服务是指一个或一组软件功能（例如特定信息的检索或一组操作的执行），其目的是不同的客户端可以为不同的目的重用（例如通过跨进程的网络调用）。Nacos 支持主流的服务生态，如 Kubernetes Service、gRPC|Dubbo RPC Service 或者 Spring Cloud RESTful Service 服务注册中心 (Service Registry)服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求 服务元数据 (Service Metadata)服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据 服务提供方 (Service Provider)是指提供可复用和可调用服务的应用方 服务消费方 (Service Consumer)是指会发起对某个服务调用的应用方 配置 (Configuration)在系统开发过程中通常会将一些需要变更的参数、变量等从代码中分离出来独立管理，以独立的配置文件的形式存在。目的是让静态的系统工件或者交付物（如 WAR，JAR 包等）更好地和实际的物理运行环境进行适配。配置管理一般包含在系统部署的过程中，由系统管理员或者运维人员完成这个步骤。配置变更是调整系统运行时的行为的有效手段之一 配置管理 (Configuration Management)在数据中心中，系统中所有配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等所有与配置相关的活动统称为配置管理 名字服务 (Naming Service)提供分布式系统中所有对象(Object)、实体(Entity)的“名字”到关联的元数据之间的映射管理服务，例如 ServiceName -&gt; Endpoints Info, Distributed Lock Name -&gt; Lock Owner/Status Info, DNS Domain Name -&gt; IP List, 服务发现和 DNS 就是名字服务的2大场景 配置服务 (Configuration Service)在服务或者应用运行过程中，提供动态配置或者元数据以及配置管理的服务提供者 下载安装准备环境Nacos 依赖 Java 环境来运行。如果您是从代码开始构建并运行 Nacos，还需要为此配置 Maven 环境，请确保是在以下版本环境中安装使用: 64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac。 64 bit JDK 1.8+ Maven 3.2.x+ 下载并安装123456# 下载源码git clone https://github.com/alibaba/nacos.git# 安装到本地仓库cd nacos/mvn -Prelease-nacos clean install -U 注：下载依赖时间较长，请耐心等待… 启动服务1234567cd distribution/target/nacos-server-0.7.0/nacos/bin# Linux./startup.sh -m standalone# Windowsstartup.cmd 访问服务打开浏览器访问：http://localhost:8848/nacos/index.html]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba服务提供者]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%E6%9C%8D%E5%8A%A1%E6%8F%90%E4%BE%9B%E8%80%85%2F</url>
    <content type="text"><![CDATA[概述通过一个简单的示例来感受一下如何将服务注册到 Nacos，其实和 Eureka 没有太大差别 POM创建一个工程名为 spring-cloud-alibaba-demo-nacos-provider 的服务提供者项目，pom.xml 配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml12345678910111213141516spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848server: port: 8081management: endpoints: web: exposure: include: "*" Application通过 @EnableDiscoveryClient 注解表明是一个 Nacos 客户端，该注解是 Spring Cloud 提供的原生注解 123456789101112131415161718192021222324252627282930package club.codeopen.spring.cloud.alibaba.nacos.provider;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;/** * @author by cheng * @Classname NacosProviderApplication * @Description * @Date 2019/1/13 9:24 */@SpringBootApplication@EnableDiscoveryClientpublic class NacosProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProviderApplication.class, args); &#125; @RestController public class EchoController &#123; @GetMapping(value = "/echo/&#123;message&#125;") public String echo(@PathVariable String message) &#123; return "Hello Nacos Discovery " + message; &#125; &#125;&#125; 启动工程通过浏览器访问 http://localhost:8848/nacos，即 Nacos Server 网址 你会发现一个服务已经注册在服务中了，服务名为 nacos-provider 这时打开 http://localhost:8081/echo/hi ，你会在浏览器上看到： 1Hello Nacos Discovery hi 服务的端点检查spring-cloud-starter-alibaba-nacos-discovery 在实现的时候提供了一个 EndPoint, EndPoint 的访问地址为 http://ip:port/actuator/nacos-discovery。 EndPoint 的信息主要提供了两类: 121、subscribe: 显示了当前有哪些服务订阅者2、NacosDiscoveryProperties: 显示了当前服务实例关于 Nacos 的基础配置 12 通过浏览器访问 http://localhost:8081/actuator/nacos-discovery 你会在浏览器上看到： 附：Nacos Starter 更多配置项信息 配置项 Key 默认值 说明 服务端地址 spring.cloud.nacos.discovery.server-addr 无 Nacos Server 启动监听的ip地址和端口 服务名 spring.cloud.nacos.discovery.service ${spring.application.name} 给当前的服务命名 权重 spring.cloud.nacos.discovery.weight 1 取值范围 1 到 100，数值越大，权重越大 网卡名 spring.cloud.nacos.discovery.network-interface 无 当IP未配置时，注册的IP为此网卡所对应的IP地址，如果此项也未配置，则默认取第一块网卡的地址 注册的IP地址 spring.cloud.nacos.discovery.ip 无 优先级最高 注册的端口 spring.cloud.nacos.discovery.port -1 默认情况下不用配置，会自动探测 命名空间 spring.cloud.nacos.discovery.namespace 无 常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。 AccessKey spring.cloud.nacos.discovery.access-key 无 当要上阿里云时，阿里云上面的一个云账号名 SecretKey spring.cloud.nacos.discovery.secret-key 无 当要上阿里云时，阿里云上面的一个云账号密码 Metadata spring.cloud.nacos.discovery.metadata 无 使用 Map 格式配置，用户可以根据自己的需要自定义一些和服务相关的元数据信息 日志文件名 spring.cloud.nacos.discovery.log-name 无 接入点 spring.cloud.nacos.discovery.enpoint UTF-8 地域的某个服务的入口域名，通过此域名可以动态地拿到服务端地址 是否集成 Ribbon ribbon.nacos.enabled true]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%2F</url>
    <content type="text"><![CDATA[Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。 参考文档 请查看 WIKI 主要功能 服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 更多功能请参考 Roadmap。 组件Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 更多组件请参考 Roadmap。 如何构建 master 分支对应的是 Spring Cloud Finchley，最低支持 JDK 1.8。 1.x 分支对应的是 Spring Cloud Edgware，最低支持 JDK 1.7。 Spring Cloud 使用 Maven 来构建，最快的使用方式是将本项目clone到本地，然后执行以下命令： 1./mvnw install 执行完毕后，项目将被安装到本地 Maven 仓库。 如何使用如何引入依赖项目的最新版本是 0.2.1.RELEASE 和 0.1.1.RELEASE，版本 0.2.1.RELEASE 对应的是 Spring Cloud Finchley 版本，版本 0.1.1.RELEASE 对应的是 Spring Cloud Edgware 版本。 如果需要使用已发布的版本，在 dependencyManagement 中添加如下配置。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 然后再 dependencies 中添加自己所需使用的依赖即可使用。 如果您想体验最新的 BUILD-SNAPSHOT 的新功能，则可以将版本换成最新的版本，但是需要在 pom.xml 中配置 Spring BUILDSNAPSHOT 仓库，注意: SNAPSHOT 版本随时可能更新 12345678910&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshot&lt;/id&gt; &lt;name&gt;Spring Snapshot Repository&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 演示 Demo为了演示如何使用，Spring Cloud Alibaba 项目包含了一个子模块spring-cloud-alibaba-examples。此模块中提供了演示用的 example ，您可以阅读对应的 example 工程下的 readme 文档，根据里面的步骤来体验。 Example 列表： Sentinel Example Nacos Config Example Nacos Discovery Example RocketMQ Example Alibaba Cloud OSS Example Alibaba Cloud ANS Example Alibaba Cloud ACM Example Alibaba Cloud SchedulerX Example 版本管理规范项目的版本号格式为 x.x.x 的形式，其中 x 的数值类型为数字，从0开始取值，且不限于 0~9 这个范围。项目处于孵化器阶段时，第一位版本号固定使用0，即版本号为 0.x.x 的格式。 由于 Spring Boot 1 和 Spring Boot 2 在 Actuator 模块的接口和注解有很大的变更，且 spring-cloud-commons 从 1.x.x 版本升级到 2.0.0 版本也有较大的变更，因此我们使用了两个不同分支来分别支持 Spring Boot 1 和 Spring Boot 2: 0.1.x 版本适用于 Spring Boot 1 0.2.x 版本适用于 Spring Boot 2 项目孵化阶段，项目版本升级机制如下： 功能改动的升级会增加第三位版本号的数值，例如 0.1.0 的下一个版本为0.1.1。]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Alibaba 服务配置]]></title>
    <url>%2F2019%2F01%2F13%2Fspring-cloud-alibaba%2FSpring%20Cloud%20Alibaba%20%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nacos Config 服务端初始化分布式配置中心在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。 Nacos ConfigNacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。使用 Spring Cloud Alibaba Nacos Config，您可以在 Nacos Server 集中管理你 Spring Cloud 应用的外部属性配置。 Spring Cloud Alibaba Nacos Config 是 Spring Cloud Config Server 和 Client 的替代方案，客户端和服务器上的概念与 Spring Environment 和 PropertySource 有着一致的抽象，在特殊的 bootstrap 阶段，配置被加载到 Spring 环境中。当应用程序通过部署管道从开发到测试再到生产时，您可以管理这些环境之间的配置，并确保应用程序具有迁移时需要运行的所有内容 创建配置文件需要在 Nacos Server 中创建配置文件，我们依然采用 YAML 的方式部署配置文件，操作流程如下： 浏览器打开 http://localhost:8848/nacos ，访问 Nacos Server 新建配置文件，此处我们以之前创建的 服务提供者 项目为例 注意：Data ID 的默认扩展名为 .properties ，希望使用 YAML 配置，此处必须指明是 .yaml 发布成功后在 “配置列表” 一栏即可看到刚才创建的配置项 Nacos Config 客户端的使用POM此处我们以之前创建的 服务提供者 项目为例 在 pom.xml 中增加 org.springframework.cloud:spring-cloud-starter-alibaba-nacos-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 完整的 pom.xml 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;club.codeopen&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../spring-cloud-alibaba-demo-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;spring-cloud-alibaba-demo-nacos-provider&lt;/name&gt; &lt;url&gt;https://www.codeopen.club&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;club.codeopen.spring.cloud.alibaba.nacos.provider.NacosProviderApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; bootstrap.properties创建名为 bootstrap.properties 的配置文件并删除之前创建的 application.yml 配置文件，由于已经在服务端配置，此处不再赘述 123456# 这里的应用名对应 Nacos Config 中的 Data ID，实际应用名称以配置中心的配置为准spring.application.name=nacos-provider-config# 指定查找名为 nacos-provider-config.yaml 的配置文件spring.cloud.nacos.config.file-extension=yaml# Nacos Server 的地址spring.cloud.nacos.config.server-addr=127.0.0.1:8848 注意：在之前的 Spring Cloud Netflix 课程中有提到过 Spring Boot 配置文件的加载顺序，依次为 bootstrap.properties -&gt; bootstrap.yml -&gt; application.properties -&gt; application.yml ，其中 bootstrap.properties 配置为最高优先级 启动应用程序启动应用后我们可以通过日志看到，已经成功加载到了配置文件 配置的动态更新Nacos Config 也支持配置的动态更新，操作流程如下： 修改服务端配置，增加一个 user.name 的属性 修改 Controller ，增加一个请求方法，测试配置更新效果 123456789// 注入配置文件上下文@Autowiredprivate ConfigurableApplicationContext applicationContext;// 从上下文中读取配置@GetMapping(value = "/hi")public String sayHi() &#123; return "Hello " + applicationContext.getEnvironment().getProperty("user.name");&#125; 通过浏览器访问该接口，浏览器显示 1Hello cheng 修改服务端配置 此时观察控制台日志，你会发现我们已经成功刷新了配置 刷新浏览器，浏览器显示 1Hello chengChange 注意：你可以使用 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新 Nacos Config 多环境的配置Spring Boot Profile我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar spring-cloud-alibaba-demo-nacos-provider-1.0.0-SNAPSHOT.jar --spring.profiles.active=prod Nacos Config Profilespring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataid 为 ${spring.application.name}.${file-extension:properties} 为前缀的基础配置，还加载了 dataid 为 ${spring.application.name}-${profile}.${file-extension:properties} 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过 Spring 提供的 ${spring.profiles.active} 这个配置项来配置。 此处我们以之前创建的 服务提供者 项目为例 在 Nacos Server 中增加配置增加一个名为 nacos-provider-config-prod.yaml 的配置 注意：此时，我将配置文件中的端口由 8081 -&gt; 8082 在项目中增加配置增加一个名为 bootstrap-prod.properties 的配置文件，内容如下： 1234spring.profiles.active=prodspring.application.name=nacos-provider-configspring.cloud.nacos.config.file-extension=yamlspring.cloud.nacos.config.server-addr=127.0.0.1:8848 主要增加了 spring.profiles.active=prod 配置，用于指定访问 Nacos Server 中的 nacos-provider-config-prod.yaml 配置 启动应用程序此时我们有两个配置文件，分别为 bootstrap.properties 和 bootstrap-prod.properties ，我们需要指定启动时加载哪一个配置文件，操作流程如下： Run -&gt; Edit Configurations.. 设置需要激活的配置 观察日志，判断是否成功加载配置]]></content>
      <categories>
        <category>Spring Cloud Alibaba</category>
        <category>Nacos</category>
      </categories>
      <tags>
        <tag>Spring Cloud Alibaba</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自定义Banner]]></title>
    <url>%2F2019%2F01%2F09%2Fspring-boot%2FSpringBoot%E8%87%AA%E5%AE%9A%E4%B9%89Banner(%E4%BD%9B%E7%A5%96%E4%BF%9D%E4%BD%91)%2F</url>
    <content type="text"><![CDATA[在 Spring Boot 启动的时候会有一个默认的启动图案 1234567. ____ _ __ _ _ /\\ / ___&apos;_ __ _ _(_)_ __ __ _ \ \ \ \( ( )\___ | &apos;_ | &apos;_| | &apos;_ \/ _` | \ \ \ \ \\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.5.8.RELEASE) 我们在 src/main/resources 目录下新建一个 banner.txt 通过 http://patorjk.com/software/taag 网站生成字符串，将网站生成的字符复制到 banner.txt 中 再次运行这个程序 1234567891011121314151617181920212223$&#123;AnsiColor.BRIGHT_RED&#125;////////////////////////////////////////////////////////////////////// _ooOoo_ //// o8888888o //// 88&quot; . &quot;88 //// (| ^_^ |) //// O\ = /O //// ____/`---&apos;\____ //// .&apos; \\| |// `. //// / \\||| : |||// \ //// / _||||| -:- |||||- \ //// | | \\\ - /// | | //// | \_| &apos;&apos;\---/&apos;&apos; | | //// \ .-\__ `-` ___/-. / //// ___`. .&apos; /--.--\ `. . ___ //// .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. //// | | : `- \`.;`\ _ /`;.`/ - ` : | | //// \ \ `-. \_ __\ /__ _/ .-` / / //// ========`-.____`-.___\_____/___.-`____.-&apos;======== //// `=---=&apos; //// ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ //// 佛祖保佑 永不宕机 永无BUG ////////////////////////////////////////////////////////////////////// 常用属性设置： ${AnsiColor.BRIGHT_RED}：设置控制台中输出内容的颜色 ${application.version}：用来获取 MANIFEST.MF 文件中的版本号 ${application.formatted-version}：格式化后的 ${application.version} 版本信息 ${spring-boot.version}：Spring Boot 的版本号 ${spring-boot.formatted-version}：格式化后的 ${spring-boot.version} 版本信息]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Banner</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合tk.mybatis]]></title>
    <url>%2F2019%2F01%2F09%2Fspring-boot%2FSpringBoot%E6%95%B4%E5%90%88tk.mybatis%2F</url>
    <content type="text"><![CDATA[tk.mybatis 简介tk.mybatis 是在 MyBatis 框架的基础上提供了很多工具，让开发更加高效 引入依赖在 pom.xml 文件中引入 mapper-spring-boot-starter 依赖，该依赖会自动引入 MyBaits 相关依赖 12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 配置 application.yml配置 MyBatis 123mybatis: type-aliases-package: 实体类的存放路径，如：com.funtl.hello.spring.boot.entity mapper-locations: classpath:mapper/*.xml 创建一个通用的父级接口主要作用是让 DAO 层的接口继承该接口，以达到使用 tk.mybatis 的目的 1234567891011package tk.mybatis;import tk.mybatis.mapper.common.Mapper;import tk.mybatis.mapper.common.MySqlMapper;/** * 自己的 Mapper * 特别注意，该接口不能被扫描到，否则会出错 * 不能放在主启动类所在包及其子包下 */public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; &#123;&#125;]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>tk.mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Druid]]></title>
    <url>%2F2019%2F01%2F09%2Fspring-boot%2FSpringBoot%E6%95%B4%E5%90%88Druid%2F</url>
    <content type="text"><![CDATA[引入依赖在 pom.xml 文件中引入 druid-spring-boot-starter 依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 引入数据库连接依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 配置 application.yml在 application.yml 中配置数据库连接 1234567891011spring: datasource: druid: url: jdbc:mysql://ip:port/dbname?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true driver-class-name: com.mysql.jdbc.Driver]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云短信服务工具类]]></title>
    <url>%2F2019%2F01%2F09%2FdevNote%2F%E9%98%BF%E9%87%8C%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[短信服务（Short Message Service）是阿里云为用户提供的一种通信服务的能力。支持国内和国际快速发送验证码、短信通知和推广短信，服务范围覆盖全球200多个国家和地区。国内短信支持三网合一专属通道，与工信部携号转网平台实时互联。电信级运维保障，实时监控自动切换，到达率高达99%。完美支撑双11期间20亿短信发送，6亿用户触达。 工具内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import com.aliyuncs.DefaultAcsClient;import com.aliyuncs.IAcsClient;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsRequest;import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsResponse;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsRequest;import com.aliyuncs.dysmsapi.model.v20170525.SendSmsResponse;import com.aliyuncs.exceptions.ClientException;import com.aliyuncs.profile.DefaultProfile;import com.aliyuncs.profile.IClientProfile;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.core.env.Environment;import org.springframework.stereotype.Component;import java.text.SimpleDateFormat;import java.util.Date;/** * 短信工具类 * @author Administrator * */@Componentpublic class SmsUtil &#123; //产品名称:云通信短信API产品,开发者无需替换 static final String product = "Dysmsapi"; //产品域名,开发者无需替换 static final String domain = "dysmsapi.aliyuncs.com"; @Autowired private Environment env; // TODO 此处需要替换成开发者自己的AK(在阿里云访问控制台寻找) /** * 发送短信 * @param mobile 手机号 * @param template_code 模板号 * @param sign_name 签名 * @param param 参数 * @return * @throws ClientException */ public SendSmsResponse sendSms(String mobile,String template_code,String sign_name,String param) throws ClientException &#123; String accessKeyId =env.getProperty("aliyun.sms.accessKeyId"); String accessKeySecret = env.getProperty("aliyun.sms.accessKeySecret"); //可自助调整超时时间 System.setProperty("sun.net.client.defaultConnectTimeout", "10000"); System.setProperty("sun.net.client.defaultReadTimeout", "10000"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessKeySecret); DefaultProfile.addEndpoint("cn-hangzhou", "cn-hangzhou", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象-具体描述见控制台-文档部分内容 SendSmsRequest request = new SendSmsRequest(); //必填:待发送手机号 request.setPhoneNumbers(mobile); //必填:短信签名-可在短信控制台中找到 request.setSignName(sign_name); //必填:短信模板-可在短信控制台中找到 request.setTemplateCode(template_code); //可选:模板中的变量替换JSON串,如模板内容为"亲爱的$&#123;name&#125;,您的验证码为$&#123;code&#125;"时,此处的值为 request.setTemplateParam(param); //选填-上行短信扩展码(无特殊需求用户请忽略此字段) //request.setSmsUpExtendCode("90997"); //可选:outId为提供给业务方扩展字段,最终在短信回执消息中将此值带回给调用者 request.setOutId("yourOutId"); //hint 此处可能会抛出异常，注意catch SendSmsResponse sendSmsResponse = acsClient.getAcsResponse(request); return sendSmsResponse; &#125; public QuerySendDetailsResponse querySendDetails(String mobile,String bizId) throws ClientException &#123; String accessKeyId =env.getProperty("accessKeyId"); String accessKeySecret = env.getProperty("accessKeySecret"); //可自助调整超时时间 System.setProperty("sun.net.client.defaultConnectTimeout", "10000"); System.setProperty("sun.net.client.defaultReadTimeout", "10000"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessKeySecret); DefaultProfile.addEndpoint("cn-hangzhou", "cn-hangzhou", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象 QuerySendDetailsRequest request = new QuerySendDetailsRequest(); //必填-号码 request.setPhoneNumber(mobile); //可选-流水号 request.setBizId(bizId); //必填-发送日期 支持30天内记录查询，格式yyyyMMdd SimpleDateFormat ft = new SimpleDateFormat("yyyyMMdd"); request.setSendDate(ft.format(new Date())); //必填-页大小 request.setPageSize(10L); //必填-当前页码从1开始计数 request.setCurrentPage(1L); //hint 此处可能会抛出异常，注意catch QuerySendDetailsResponse querySendDetailsResponse = acsClient.getAcsResponse(request); return querySendDetailsResponse; &#125;&#125;]]></content>
      <categories>
        <category>JavaUtils</category>
      </categories>
      <tags>
        <tag>JavaUtils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7 搭建FTP]]></title>
    <url>%2F2019%2F01%2F09%2FLinux%2FCentOS7%E6%90%AD%E5%BB%BAFTP%2F</url>
    <content type="text"><![CDATA[查看是否安装了FTP：rpm -qa |grep vsftpd 如果没有任何输出，表示没有安装。 如果出现如下版本信息，则表示已经安装。 如果没有安装，可以使用如下命令直接安装1yum -y install vsftpd 默认安装目录：/etc/vsftpd 添加FTP账号1useradd admin -s /sbin/nologin 该账户路径默认指向/home/admin目录 设置密码：passwd admin 一些常用设置 设置匿名用户可以下载上传将文件/etc/vsftpd/vsftpd.conf 中下面两句的注释删除 12anon_upload_enable=YESanon_mkdir_write_enable=YES 根据个人需要设置默认目录修改/etc/passwd文件，找到你的用户名的那一行修改路径，然后保存即可，无需重启 将admin:x:500:500::/home/admin:/sbin/nologin 改成admin:x:500:500::/自定义文件夹:/sbin/nologin 启动 启动：systemctl start vsftpd 重启：systemctl restart vsftpd 开机自启：systemctl enable vsftpd]]></content>
      <categories>
        <category>FTP</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo安装]]></title>
    <url>%2F2019%2F01%2F08%2Fhexo-next-blog%E6%90%AD%E5%BB%BA%2FHexo%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装安装前提安装 Hexo 相当简单。然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.js(傻瓜式安装) 安装完成Node应该自带了NPM，但却龟速，站内搜索npm切换镜像到淘宝镜像,修改npm镜像 Git(傻瓜式安装) 如果您的电脑中已经安装上述必备程序，那么恭喜您！接下来只需要使用 npm 即可完成 Hexo 的安装。 1$ npm install -g hexo-cli 如果您的电脑中尚未安装所需要的程序，请根据以下安装指示完成安装。 Mac 用户 您在编译时可能会遇到问题，请先到 App Store 安装 Xcode，Xcode 完成后，启动并进入 Preferences -&gt; Download -&gt; Command Line Tools -&gt; Install 安装命令行工具。 安装 Git Windows：下载并安装 git. Mac：使用 Homebrew, MacPorts ：brew install git;或下载 安装程序 安装。 Linux (Ubuntu, Debian)：sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS)：sudo yum install git-core Windows 用户 由于众所周知的原因，从上面的链接下载git for windows最好挂上一个代理，否则下载速度十分缓慢。也可以参考这个页面，收录了存储于百度云的下载地址。 安装 Node.js安装 Node.js 的最佳方式是使用 nvm。 cURL: 1$ curl https://raw.github.com/creationix/nvm/v0.33.11/install.sh | sh Wget: 1$ wget -qO- https://raw.github.com/creationix/nvm/v0.33.11/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js。 1$ nvm install stable 或者您也可以下载 安装程序 来安装。 Windows 用户 对于windows用户来说，建议使用安装程序进行安装。安装时，请勾选Add to PATH选项。另外，您也可以使用Git Bash，这是git for windows自带的一组程序，提供了Linux风格的shell，在该环境下，您可以直接用上面提到的命令来安装Node.js。打开它的方法很简单，在任意位置单击右键，选择“Git Bash Here”即可。由于Hexo的很多操作都涉及到命令行，您可以考虑始终使用Git Bash来进行操作。 安装 Hexo所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 Zookeeper安装]]></title>
    <url>%2F2019%2F01%2F08%2FZookeeper%2FZookeeper%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Zookeeper 部署有三种方式，单机模式、集群模式、伪集群模式，以下采用手动安装的方式部署 注意： 集群为大于等于3个奇数，如 3、5、7,不宜太多，集群机器多了选举和数据同步耗时长，不稳定。 单机模式下载进入要下载的版本的目录，选择 .tar.gz 文件下载，下载链接：http://archive.apache.org/dist/zookeeper/ 安装注意： 需要先安装 Java 使用 tar 解压要安装的目录即可，以 3.4.13 版本为例，解压到 /usr/local/zookeeper-3.4.13 1tar -zxvf zookeeper-3.4.13.tar.gz -C /usr/local 配置在根目录下创建 data 和 logs 两个目录用于存储数据和日志 123cd /usr/local/zookeeper-3.4.13mkdir datamkdir logs 在 conf 目录下新建 zoo.cfg 文件，写入以下内容保存 1234tickTime=2000dataDir=/usr/local/zookeeper-3.4.13/datadataLogDir=/usr/local/zookeeper-3.4.13/logsclientPort=2181 启动和停止进入 bin 目录，启动、停止、重启和查看当前节点状态 1234./zkServer.sh start./zkServer.sh stop./zkServer.sh restart./zkServer.sh status 伪集群模式伪集群模式就是在同一主机启动多个 zookeeper 并组成集群，下边以在 192.168.10.134 主机上创 3 个 zookeeper 组集群为例。 将通过单机模式安装的 zookeeper，复制成 zookeeper1/zookeeper2/zookeeper3 三份 zookeeper1 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper1/datadataLogDir=/usr/local/zookeeper1/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID 1echo '1' &gt; data/myid zookeeper2 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper2/datadataLogDir=/usr/local/zookeeper2/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID1echo '2' &gt; data/myid zookeeper3 修改配置文件 123456789tickTime=2000dataDir=/usr/local/zookeeper3/datadataLogDir=/usr/local/zookeeper3/logsclientPort=2181initLimit=5syncLimit=2server.1=192.168.10.134:2888:3888server.2=192.168.10.134:4888:5888server.3=192.168.10.134:6888:7888 设置服务器 ID 1echo '3' &gt; data/myid 启动和停止分别启动服务器，顺序无所谓 1234./zkServer.sh start./zkServer.sh stop./zkServer.sh restart./zkServer.sh status 集群模式集群模式就是在不同主机上安装 zookeeper 然后组成集群的模式，操作步骤同上，此处不再赘述。]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 Jenkins安装]]></title>
    <url>%2F2019%2F01%2F08%2FJenkins%2FJenkins%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载jenkins 1wget https://pkg.jenkins.io/redhat/jenkins‐2.83‐1.1.noarch.rpm 安装jenkins 1rpm ‐ivh jenkins‐2.83‐1.1.noarch.rpm 配置jenkins 修改用户和端口vi /etc/sysconfig/jenkins 12JENKINS_USER=&quot;root&quot;JENKINS_PORT=&quot;8888&quot; 配置java环境变量vi /etc/rc.d/init.d/jenkins 1234567891011# see http://www.nabble.com/guinea-pigs-wanted-----Hudson-RPM-for-RedHat-Linux-td25673707.htmlcandidates=&quot;/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java#在下面加入java环境变量/usr/java/jdk1.8.0_161/bin/java&quot; 启动服务 1systemctl start jenkins 访问链接 http://IP:8888 从/var/lib/jenkins/secrets/initialAdminPassword中获取初始密码串]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载均衡]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%2FNginx%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[Nginx 实现负载均衡 nginx 作为负载均衡服务器，用户请求先到达 nginx，再由 nginx 根据负载配置将请求转发至 tomcat 服务器 nginx 负载均衡服务器：192.168.75.145:80 tomcat1 服务器：192.168.75.145:9090 tomcat2 服务器：192.168.75.145:9091Nginx 配置负载均衡修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 1234567891011121314151617181920212223242526272829user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; upstream myapp1 &#123; server 192.168.75.145:9090 weight=10; server 192.168.75.145:9091 weight=10; &#125; server &#123; listen 80; server_name nginx.funtl.com; location / &#123; proxy_pass http://myapp1; index index.jsp index.html index.htm; &#125; &#125;&#125; 相关配置说明1234567# 定义负载均衡设备的 Ip及设备状态 upstream myServer &#123; server 127.0.0.1:9090 down; server 127.0.0.1:8080 weight=2; server 127.0.0.1:6060; server 127.0.0.1:7070 backup;&#125; 在需要使用负载的 Server 节点下添加 1proxy_pass http://myServer; upstream：每个设备的状态: down：表示当前的 server 暂时不参与负载 weight：默认为 1 weight 越大，负载的权重就越大。 max_fails：允许请求失败的次数默认为 1 当超过最大次数时，返回 proxy_next_upstream 模块定义的错误 fail_timeout:max_fails 次失败后，暂停的时间。 backup：其它所有的非 backup 机器 down 或者忙的时候，请求 backup 机器。所以这台机器压力会最轻]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 反向代理]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%2FNginx%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[使用 Nginx 反向代理 Tomcat 需求 两个 tomcat 服务通过 nginx 反向代理 nginx 服务器：192.168.75.145:80 tomcat1 服务器：192.168.75.145:9090 tomcat2 服务器：192.168.75.145:9091 启动 Tomcat 容器启动两个 Tomcat 容器，映射端口为 9090 和 9091，docker-compose.yml 如下： 12345678910111213version: &apos;3&apos;services: tomcat1: image: tomcat container_name: tomcat1 ports: - 9090:8080 tomcat2: image: tomcat container_name: tomcat2 ports: - 9091:8080 配置 Nginx 反向代理修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 配置一个代理即 tomcat1 服务器 upstream tomcat_server1 &#123; server 192.168.75.145:9090; &#125; # 配置一个代理即 tomcat2 服务器 upstream tomcat_server2 &#123; server 192.168.75.145:9091; &#125; # 配置一个虚拟主机 server &#123; listen 80; server_name admin.service.itoken.funtl.com; location / &#123; # 域名 admin.service.itoken.funtl.com 的请求全部转发到 tomcat_server1 即 tomcat1 服务上 proxy_pass http://tomcat_server1; # 欢迎页面，按照从左到右的顺序查找页面 index index.jsp index.html index.htm; &#125; &#125; server &#123; listen 80; server_name admin.web.itoken.funtl.com; location / &#123; # 域名 admin.web.itoken.funtl.com 的请求全部转发到 tomcat_server2 即 tomcat2 服务上 proxy_pass http://tomcat_server2; index index.jsp index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 虚拟主机]]></title>
    <url>%2F2019%2F01%2F08%2FNginx%2FNginx%20%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[使用 Docker 来安装和运行 Nginx，docker-compose.yml 配置如下：1234567891011version: '3.1'services: nginx: restart: always image: nginx container_name: nginx ports: - 81:80 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./wwwroot:/usr/share/nginx/wwwroot 基于端口的虚拟主机配置需求 Nginx 对外提供 80 和 8080 两个端口监听服务 请求 80 端口则请求 html80 目录下的 html 请求 8080 端口则请求 html8080 目录下的 html创建目录及文件在/usr/local/docker/nginx/wwwroot 目录下创建 html80 和 html8080 两个目录，并分辨创建两个 index.html 文件 配置虚拟主机修改 /usr/local/docker/nginx/conf 目录下的 nginx.conf 配置文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 启动进程,通常设置成和 CPU 的数量相等worker_processes 1;events &#123; # epoll 是多路复用 IO(I/O Multiplexing) 中的一种方式 # 但是仅用于 linux2.6 以上内核,可以大大提高 nginx 的性能 use epoll; # 单个后台 worker process 进程的最大并发链接数 worker_connections 1024;&#125;http &#123; # 设定 mime 类型,类型由 mime.type 文件定义 include mime.types; default_type application/octet-stream; # sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用， # 必须设为 on，如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平衡磁盘与网络 I/O 处理速度，降低系统的 uptime. sendfile on; # 连接超时时间 keepalive_timeout 65; # 设定请求缓冲 client_header_buffer_size 2k; # 配置虚拟主机 192.168.75.145 server &#123; # 监听的ip和端口，配置 192.168.75.145:80 listen 80; # 虚拟主机名称这里配置ip地址 server_name 192.168.75.145; # 所有的请求都以 / 开始，所有的请求都可以匹配此 location location / &#123; # 使用 root 指令指定虚拟主机目录即网页存放目录 # 比如访问 http://ip/index.html 将找到 /usr/local/docker/nginx/wwwroot/html80/index.html # 比如访问 http://ip/item/index.html 将找到 /usr/local/docker/nginx/wwwroot/html80/item/index.html root /usr/share/nginx/wwwroot/html80; # 指定欢迎页面，按从左到右顺序查找 index index.html index.htm; &#125; &#125; # 配置虚拟主机 192.168.75.245 server &#123; listen 8080; server_name 192.168.75.145; location / &#123; root /usr/share/nginx/wwwroot/html8080; index index.html index.htm; &#125; &#125;&#125; 基于域名的虚拟主机配置需求 两个域名指向同一台 Nginx 服务器，用户访问不同的域名显示不同的网页内容 两个域名是 admin.service.com 和 admin.web..com Nginx 服务器使用虚拟机 192.168.75.145配置 Windows Hosts 文件 通过 host 文件指定 admin.service.com 和 admin.web.com 对应 192.168.75.145 虚拟机： 修改 window 的 hosts 文件：（C:\Windows\System32\drivers\etc） 创建目录及文件在 /usr/local/docker/nginx/wwwroot 目录下创建 htmlservice 和 htmlweb 两个目录，并分辨创建两个 index.html 文件 配置虚拟主机12345678910111213141516171819202122232425262728293031323334user nginx;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name admin.service.com; location / &#123; root /usr/share/nginx/wwwroot/htmlservice; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name admin.web.com; location / &#123; root /usr/share/nginx/wwwroot/htmlweb; index index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose]]></title>
    <url>%2F2019%2F01%2F08%2Fdocker%2FDocker%20Compose%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 123456789version: "3"services: webapp: image: examples/web ports: - "80:80" volumes: - "/data" 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 12345version: '3'services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 123456789version: '3'services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 12345build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： 12cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： 12cap_drop: - NET_ADMIN command覆盖容器启动后默认执行的命令。 1command: echo "hello world" configs仅用于 Swarm mode cgroup_parent指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 1cgroup_parent: cgroups_1 container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 1container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy仅用于 Swarm mode devices指定设备映射关系。 12devices: - "/dev/ttyUSB1:/dev/ttyUSB0" depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 1234567891011121314version: '3'services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns自定义 DNS 服务器。可以是一个值，也可以是一个列表。 12345dns: 8.8.8.8dns: - 8.8.8.8 - 114.114.114.114 dns_search配置 DNS 搜索域。可以是一个值，也可以是一个列表。 12345dns_search: example.comdns_search: - domain1.example.com - domain2.example.com tmpfs挂载一个 tmpfs 文件系统到容器。 1234tmpfs: /runtmpfs: - /run - /tmp env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 123456env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 12# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 1y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 123expose: - "3000" - "8000" external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 123extra_hosts: - "googledns:8.8.8.8" - "dockerhub:52.1.157.61" 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 128.8.8.8 googledns52.1.157.61 dockerhub healthcheck通过命令检查容器是否健康运行。 12345healthcheck: test: ["CMD", "curl", "-f", "http://localhost"] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 123image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd labels为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 1234labels: com.startupteam.description: "webapp for a startup team" com.startupteam.department: "devops department" com.startupteam.release: "rc3 for v1.0" links 注意：不推荐使用该指令。 logging配置日志选项。 1234logging: driver: syslog options: syslog-address: "tcp://192.168.0.42:123" 目前支持三种日志驱动类型。 123driver: "json-file"driver: "syslog"driver: "none" options 配置日志驱动的相关参数。 123options: max-size: "200k" max-file: "10" network_mode设置网络模式。使用和 docker run 的 --network 参数一样的值。 12345network_mode: "bridge"network_mode: "host"network_mode: "none"network_mode: "service:[service name]"network_mode: "container:[container name/id]" networks配置容器连接的网络。 1234567891011version: "3"services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: pid跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 1pid: &quot;host&quot; ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 12345ports: - "3000" - "8000:8000" - "49100:22" - "127.0.0.1:8001:8001" 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets存储敏感数据，例如 mysql 服务密码。 12345678910111213141516version: "3.1"services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secretsecrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 123security_opt: - label:user:USER - label:role:ROLE stop_signal设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 1stop_signal: SIGUSR1 sysctls配置容器内核参数。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 其它指令此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 1entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名。 1user: nginx 指定容器中工作目录。 1working_dir: /code 指定容器中搜索域名、主机名、mac 地址等。 123domainname: your_website.comhostname: testmac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 1privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 1restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 1yamlread_only: true 打开标准输入，可以接受外部输入。 1stdin_open: true 模拟一个伪终端。 1tty: true 读取变量Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 12345version: "3"services:db: image: "mongo:$&#123;MONGO_VERSION&#125;" 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 12# 支持 # 号注释MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose命令]]></title>
    <url>%2F2019%2F01%2F08%2Fdocker%2FDocker%20Compose%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 1docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 build格式为 docker-compose build [options] [SERVICE...]。 构建（重新构建）项目中的服务容器。 服务容器一旦构建后，将会带上一个标记名，例如对于 web 项目中的一个 db 容器，可能是 web_db。 可以随时在项目目录下运行 docker-compose build 来重新构建服务。 选项包括： --force-rm 删除构建过程中的临时容器。 --no-cache 构建镜像过程中不使用 cache（这将加长构建过程）。 --pull 始终尝试通过 pull 来获取更新版本的镜像。 config验证 Compose 文件格式是否正确，若正确则显示配置，若格式错误显示错误原因。 down此命令将会停止 up 命令所启动的容器，并移除网络 exec进入指定的容器。 help获得一个命令的帮助。 images列出 Compose 文件中包含的镜像。 kill格式为 docker-compose kill [options] [SERVICE...]。 通过发送 SIGKILL 信号来强制停止服务容器。 支持通过 -s 参数来指定发送的信号，例如通过如下指令发送 SIGINT 信号。 1$ docker-compose kill -s SIGINT logs格式为 docker-compose logs [options] [SERVICE...]。 查看服务容器的输出。默认情况下，docker-compose 将对不同的服务输出使用不同的颜色来区分。可以通过 --no-color 来关闭颜色。 该命令在调试问题的时候十分有用。 pause格式为 docker-compose pause [SERVICE...]。 暂停一个服务容器。 port格式为 docker-compose port [options] SERVICE PRIVATE_PORT。 打印某个容器端口所映射的公共端口。 选项： --protocol=proto 指定端口协议，tcp（默认值）或者 udp。 --index=index 如果同一服务存在多个容器，指定命令对象容器的序号（默认为 1）。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： pull 格式为 docker-compose pull [options] [SERVICE...]。 拉取服务依赖的镜像。 选项： --ignore-pull-failures 忽略拉取镜像过程中的错误。 pushrestart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 run格式为 docker-compose run [options] [-p PORT...] [-e KEY=VAL...] SERVICE [COMMAND] [ARGS...]。 在指定服务上执行一个命令。 例如： 1$ docker-compose run ubuntu ping docker.com 将会启动一个 ubuntu 服务容器，并执行 ping docker.com 命令。 默认情况下，如果存在关联，则所有关联的服务将会自动被启动，除非这些服务已经在运行中。 该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照配置自动创建。 两个不同点： 给定命令将会覆盖原有的自动运行命令； 不会自动创建端口，以避免冲突。 如果不希望自动启动关联的容器，可以使用 --no-deps 选项，例如 1$ docker-compose run --no-deps web python manage.py shell 将不会启动 web 容器所关联的其它容器。 选项： -d 后台运行容器。 --name NAME 为容器指定一个名字。 --entrypoint CMD 覆盖默认的容器启动指令。 -e KEY=VAL 设置环境变量值，可多次使用选项来设置多个环境变量。 -u, --user=&quot;&quot; 指定运行容器的用户名或者 uid。 --no-deps 不自动启动关联的服务容器。 --rm 运行命令后自动删除容器，d 模式下将忽略。 -p, --publish=[] 映射容器端口到本地主机。 --service-ports 配置服务端口并映射到本地主机。 -T 不分配伪 tty，意味着依赖 tty 的指令将无法运行。 scale格式为 docker-compose scale [options] [SERVICE=NUM...]。 设置指定服务运行的容器个数。 通过 service=num 的参数来设置数量。例如： 1$ docker-compose scale web=3 db=2 将启动 3 个容器运行 web 服务，2 个容器运行 db 服务。 一般的，当指定数目多于该服务当前实际运行容器，将新创建并启动容器；反之，将停止容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 start格式为 docker-compose start [SERVICE...]。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容。如果用户不希望容器被停止并重新创建，可以使用 docker-compose up --no-recreate。这样将只会启动处于停止状态的容器，而忽略已经运行的服务。如果用户只想重新部署某个服务，可以使用 docker-compose up --no-deps -d &lt;SERVICE_NAME&gt; 来重新创建服务并后台停止旧服务，启动新服务，并不会影响到其所依赖的服务。 选项： -d 在后台运行服务容器。 --no-color 不使用颜色来区分不同的服务的控制台输出。 --no-deps 不启动服务所链接的容器。 --force-recreate 强制重新创建容器，不能与 --no-recreate 同时使用。 --no-recreate 如果容器已经存在了，则不重新创建，不能与 --force-recreate 同时使用。 --no-build 不自动构建缺失的服务镜像。 -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 version格式为 docker-compose version。 打印版本信息。]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose]]></title>
    <url>%2F2019%2F01%2F08%2Fdocker%2FDocker%20Compose%2F</url>
    <content type="text"><![CDATA[什么是 Docker ComposeDocker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用。 概述Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 Docker Compose安装与卸载Compose 支持 Linux、macOS、Windows 10 三大平台。 Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。 前两种方式是传统方式，适合本地环境下安装使用；最后一种方式则不破坏系统环境，更适合云计算场景。 Docker for Mac 、Docker for Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 123$ docker-compose --versiondocker-compose version 1.17.1, build 6d101fb Linux 系统请使用以下介绍的方法安装。在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 12$ sudo curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose 卸载1$ sudo rm /usr/local/bin/docker-compose]]></content>
      <categories>
        <category>Docker Compose</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS Docker 安装]]></title>
    <url>%2F2019%2F01%2F08%2Fdocker%2FCentOS%20Docker%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Docker支持以下的CentOS版本： CentOS 7 (64-bit) CentOS 6.5 (64-bit) 或更高的版本 前提条件目前，CentOS 仅发行版本中的内核支持 Docker。 Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。 Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。 使用 yum 安装（CentOS 7下）Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。 通过 uname -r 命令查看你当前的内核版本 [root@runoob ~]# uname -r 3.10.0-327.el7.x86_64 安装Docker CE版 移除旧的版本 12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ ocker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安装一些必要的系统工具： 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 添加软件源信息： 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum缓存 1sudo yum makecache fast 安装Docker-ce 1sudo yum -y install docker-ce 启动Docker服务 1sudo systemctl start docker 设置Docker开机自启 1sudo systemctl enable docker 关闭Docker服务 1sudo systemctl stop docker 镜像加速 在 /etc/docker/daemon.json中写入如下内容（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 删除Docker CE12$ sudo yum remove docker-ce$ sudo rm -rf /var/lib/docker]]></content>
      <categories>
        <category>Docker</category>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS单机版安装]]></title>
    <url>%2F2019%2F01%2F07%2FFastDFS%2FFastDFS%E5%8D%95%E6%9C%BA%E7%89%88%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[配置镜像加速器:修改daemon配置文件/etc/docker/daemon.json12sudo mkdir -p /etc/dockersudo vi /etc/docker/daemon.json 在key为registry-mirrors追加&quot;https://1031vuk0.mirror.aliyuncs.com&quot; 1234# 若没有直接cv大法&#123; "registry-mirrors": ["https://1031vuk0.mirror.aliyuncs.com"]&#125; 重启docker刷新配置12sudo systemctl daemon-reloadsudo systemctl restart docker 编写docker-compose.yml123456789version: '3.1'services: fastdfs: image: registry.cn-shenzhen.aliyuncs.com/dev_docker_resp/fastdfs restart: always container_name: fastdfs volumes: - ./storage:/fastdfs/storage network_mode: host 运行docker-compose up -d]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>FastDFS</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息中间件RabbitMQ]]></title>
    <url>%2F2019%2F01%2F07%2FRabbitMQ%2F%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6RabbitMQ%2F</url>
    <content type="text"><![CDATA[消息中间件RabbitMQ 消息队列中间件简介 消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题实现高性能，高可用，可伸缩和最终一致性[架构] 使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 以下介绍消息队列在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋和消息通讯四个场景 RabbitMQ 简介 RabbitMQ 是一个由 Erlang语言开发的AMQP的开源实现。 AMQP：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。 主要概念 RabbitMQ Server： 也叫broker server，它是一种传输服务。 他的角色就是维护一条从Producer到Consumer的路线，保证数据能够按照指定的方式进行传输。 Producer： 消息生产者，如图A、B、C，数据的发送方。消息生产者连接RabbitMQ服务器然后将消息投递到Exchange。 Consumer：消息消费者，如图1、2、3，数据的接收方。消息消费者订阅队列，RabbitMQ将Queue中的消息发送到消息消费者。 Exchange：生产者将消息发送到Exchange（交换器），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。Exchange并不存储消息。RabbitMQ中的Exchange有direct、fanout、topic、headers四种类型，每种类型对应不同的路由规则。 Queue：（队列）是RabbitMQ的内部对象，用于存储消息。消息消费者就是通过订阅队列来获取消息的，RabbitMQ中的消息都只能存储在Queue中，生产者生产消息并最终投递到Queue中，消费者可以从Queue中获取消息并消费。多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 RoutingKey：生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则，而这个routing key需要与Exchange Type binding key联合使用才能最终生效。在Exchange Type与binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定routing key来决定消息流向哪里。RabbitMQ为routing key设定的长度限制为255bytes。 Connection： （连接）：Producer和Consumer都是通过TCP连接到RabbitMQ Server的。以后我们可以看到，程序的起始处就是建立这个TCP连接。 Channels： （信道）：它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 VirtualHost：权限控制的基本单位，一个VirtualHost里面有若干Exchange和MessageQueue，以及指定被哪些user使用 RabbitMQ安装与启动 编写docker-compose.yml文件 1234567891011121314151617181920version: '3.1'services: rabbitmq: restart: always image: rabbitmq:management container_name: rabbitmq ports: - 5672:5672 - 15672:15672 - 5671:5617 - 15671:15671 - 25672:25672 environment: TZ: Asia/Shanghai RABBITMQ_DEFAULT_USER: rabbit RABBITMQ_DEFAULT_PASS: 123456 volumes: - data:/var/lib/rabbitmqvolumes: data: rabbitmq需要有映射以下端口: 5671、5672、4369、15671、15672、25672 15672 (if management plugin is enabled) 15671 management监听端口 5672, 5671 (AMQP 0-9-1 without and with TLS) 4369 (epmd) epmd 代表 Erlang 端口映射守护进程 25672 (Erlang distribution) 启动容器docker-compose up -d 访问地址：http://IP:15672,即可看到管理界面的登陆页]]></content>
      <categories>
        <category>Docker Compose</category>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Docker Compose</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
</search>
